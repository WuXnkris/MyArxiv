<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-06T00:00:00Z">2025-03-06</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">131</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ L$^2$M: Mutual Information Scaling Law for Long-Context Language
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuo Chen, Oriol Mayné i Comas, Zhuotao Jin, Di Luo, Marin Soljačić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We rigorously establish a bipartite mutual information scaling law in natural
language that governs long-range dependencies. This scaling law, which we show
is distinct from and scales independently of the conventional two-point mutual
information, is the key to understanding long-context language modeling. Using
this scaling law, we formulate the Long-context Language Modeling (L$^2$M)
condition, which relates a model's capacity for effective long context length
modeling to the scaling of its latent state size for storing past information.
Our results are validated through experiments on both transformers and state
space models. This work establishes a theoretical foundation that guides the
development of large language models toward longer context lengths.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 12 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04724v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04724v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sambal Shikhar, Mohammed Irfan Kurpath, Sahal Shaji Mullappilly, Jean Lahoud, Fahad Khan, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in speech-to-speech dialogue systems leverage LLMs for
multimodal interactions, yet they remain hindered by fine-tuning requirements,
high computational overhead, and text-speech misalignment. Existing
speech-enabled LLMs often degrade conversational quality by modifying the LLM,
thereby compromising its linguistic capabilities. In contrast, we propose
LLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS
system that generates high-quality speech with low latency, while fully
preserving the capabilities of the base LLM. Our approach achieves a
significantly lower Word Error Rate compared to speech-enabled LLMs, while
operating at comparable latency and UTMOS score. By decoupling speech synthesis
from LLM processing via a multi-queue token streaming system, LLMVoX supports
seamless, infinite-length dialogues. Its plug-and-play design also facilitates
extension to various tasks with different backbones. Furthermore, LLMVoX
generalizes to new languages with only dataset adaptation, attaining a low
Character Error Rate on an Arabic speech task. Additionally, we have integrated
LLMVoX with a Vision-Language Model to create an omni-model with speech, text,
and vision capabilities, without requiring additional multimodal training. Our
code base and project page is available at https://mbzuai-oryx.github.io/LLMVoX .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shifting Long-Context LLMs Research from Input to Output 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04723v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04723v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Wu, Yushi Bai, Zhiqing Hu, Shangqing Tu, Ming Shan Hee, Juanzi Li, Roy Ka-Wei Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in long-context Large Language Models (LLMs) have
primarily concentrated on processing extended input contexts, resulting in
significant strides in long-context comprehension. However, the equally
critical aspect of generating long-form outputs has received comparatively less
attention. This paper advocates for a paradigm shift in NLP research toward
addressing the challenges of long-output generation. Tasks such as novel
writing, long-term planning, and complex reasoning require models to understand
extensive contexts and produce coherent, contextually rich, and logically
consistent extended text. These demands highlight a critical gap in current LLM
capabilities. We underscore the importance of this under-explored domain and
call for focused efforts to develop foundational LLMs tailored for generating
high-quality, long-form outputs, which hold immense potential for real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enough Coin Flips Can Make LLMs Act Bayesian 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) exhibit the ability to generalize given few-shot
examples in their input prompt, an emergent capability known as in-context
learning (ICL). We investigate whether LLMs utilize ICL to perform structured
reasoning in ways that are consistent with a Bayesian framework or rely on
pattern matching. Using a controlled setting of biased coin flips, we find
that: (1) LLMs often possess biased priors, causing initial divergence in
zero-shot settings, (2) in-context evidence outweighs explicit bias
instructions, (3) LLMs broadly follow Bayesian posterior updates, with
deviations primarily due to miscalibrated priors rather than flawed updates,
and (4) attention magnitude has negligible effect on Bayesian inference. With
sufficient demonstrations of biased coin flips via ICL, LLMs update their
priors in a Bayesian manner.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue
  Models on Turn-taking Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04721v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04721v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guan-Ting Lin, Jiachen Lian, Tingle Li, Qirui Wang, Gopala Anumanchipalli, Alexander H. Liu, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spoken dialogue modeling introduces unique challenges beyond text-based
language modeling, demanding robust turn-taking, backchanneling, and real-time
interaction. Although most Spoken Dialogue Models (SDMs) rely on half-duplex
processing (handling speech one turn at a time), emerging full-duplex SDMs can
listen and speak simultaneously, enabling more natural and engaging
conversations. However, current evaluations of such models remain limited,
often focusing on turn-based metrics or high-level corpus analyses (e.g., turn
gaps, pauses). To address this gap, we present Full-Duplex-Bench, a new
benchmark that systematically evaluates key conversational behaviors: pause
handling, backchanneling, turn-taking, and interruption management. Our
framework uses automatic metrics for consistent and reproducible assessments of
SDMs' interactive performance. By offering an open and standardized evaluation
benchmark, we aim to advance spoken dialogue modeling and encourage the
development of more interactive and natural dialogue systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Rich Style-<span class="highlight-title">Prompt</span>ed Text-to-Speech <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anuj Diwan, Zhisheng Zheng, David Harwath, Eunsol Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale
dataset that annotates speech utterances with rich style captions. While rich
abstract tags (e.g. guttural, nasal, pained) have been explored in small-scale
human-annotated datasets, existing large-scale datasets only cover basic tags
(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech
embedders, classifiers and an audio language model to automatically scale rich
tag annotations for the first time. ParaSpeechCaps covers a total of 59 style
tags, including both speaker-level intrinsic tags and utterance-level
situational tags. It consists of 342 hours of human-labelled data (PSC-Base)
and 2427 hours of automatically annotated data (PSC-Scaled). We finetune
Parler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and
achieve improved style consistency (+7.9% Consistency MOS) and speech quality
(+15.5% Naturalness MOS) over the best performing baseline that combines
existing rich style tag datasets. We ablate several of our dataset design
choices to lay the foundation for future work in this space. Our dataset,
models and code are released at https://github.com/ajd12342/paraspeechcaps .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ L1: Controlling How Long A Reasoning Model Thinks With Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranjal Aggarwal, Sean Welleck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reasoning language models have shown an uncanny ability to improve
performance at test-time by ``thinking longer''-that is, by generating longer
chain-of-thought sequences and hence using more compute. However, the length of
their chain-of-thought reasoning is not controllable, making it impossible to
allocate test-time compute to achieve a desired level of performance. We
introduce Length Controlled Policy Optimization (LCPO), a simple reinforcement
learning method that optimizes for accuracy and adherence to user-specified
length constraints. We use LCPO to train L1, a reasoning language model that
produces outputs satisfying a length constraint given in its prompt. L1's
length control allows for smoothly trading off computational cost and accuracy
on a wide range of tasks, and outperforms the state-of-the-art S1 method for
length control. Furthermore, we uncover an unexpected short chain-of-thought
capability in models trained with LCPO. For instance, our 1.5B L1 model
surpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise
control over reasoning length, allowing for fine-grained allocation of
test-time compute and accuracy. We release code and models at
https://www.cmu-l3.github.io/l1
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UIPE: Enhancing LLM Unlearning by Removing Knowledge Related to
  Forgetting Targets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04693v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04693v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyu Wang, Mengqi Zhang, Xiaotian Ye, Zhaochun Ren, Zhumin Chen, Pengjie Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) inevitably acquire harmful information during
training on massive datasets. LLM unlearning aims to eliminate the influence of
such harmful information while maintaining the model's overall performance.
Existing unlearning methods, represented by gradient ascent-based approaches,
primarily focus on forgetting target data while overlooking the crucial impact
of logically related knowledge on the effectiveness of unlearning. In this
paper, through both theoretical and experimental analyses, we first demonstrate
that a key reason for the suboptimal unlearning performance is that models can
reconstruct the target content through reasoning with logically related
knowledge. To address this issue, we propose Unlearning Improvement via
Parameter Extrapolation (UIPE), a method that removes knowledge highly
correlated with the forgetting targets. Experimental results show that UIPE
significantly enhances the performance of various mainstream LLM unlearning
methods on the TOFU benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengcheng Qiu, Chaoyi Wu, Shuyu Liu, Weike Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The latest reasoning-enhanced large language models (reasoning LLMs), such as
DeepSeek-R1 and OpenAI-o3, have demonstrated remarkable success. However, the
application of such reasoning enhancements to the highly professional medical
domain has not been clearly evaluated, particularly regarding with not only
assessing the final generation but also examining the quality of their
reasoning processes. In this study, we present MedR-Bench, a reasoning-focused
medical evaluation benchmark comprising 1,453 structured patient cases with
reasoning references mined from case reports. Our benchmark spans 13 body
systems and 10 specialty disorders, encompassing both common and rare diseases.
In our evaluation, we introduce a versatile framework consisting of three
critical clinical stages: assessment recommendation, diagnostic
decision-making, and treatment planning, comprehensively capturing the LLMs'
performance across the entire patient journey in healthcare. For metrics, we
propose a novel agentic system, Reasoning Evaluator, designed to automate and
objectively quantify free-text reasoning responses in a scalable manner from
the perspectives of efficiency, factuality, and completeness by dynamically
searching and performing cross-referencing checks. As a result, we assess five
state-of-the-art reasoning LLMs, including DeepSeek-R1, OpenAI-o3-mini, and
others. Our results reveal that current LLMs can handle relatively simple
diagnostic tasks with sufficient critical assessment results, achieving
accuracy generally over 85%. However, they still struggle with more complex
tasks, such as assessment recommendation and treatment planning. In reasoning,
their reasoning processes are generally reliable, with factuality scores
exceeding 90%, though they often omit critical reasoning steps. Our study
clearly reveals further development directions for current clinical LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DIMSUM: Discourse in Mathematical Reasoning as a Supervision Module 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04685v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04685v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krish Sharma, Niyar R Barman, Nicholas Asher, Akshay Chaturvedi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We look at reasoning on GSM8k, a dataset of short texts presenting primary
school, math problems. We find, with Mirzadeh et al. (2024), that current LLM
progress on the data set may not be explained by better reasoning but by
exposure to a broader pretraining data distribution. We then introduce a novel
information source for helping models with less data or inferior training
reason better: discourse structure. We show that discourse structure improves
performance for models like Llama2 13b by up to 160%. Even for models that have
most likely memorized the data set, adding discourse structural information to
the model still improves predictions and dramatically improves large model
performance on out of distribution examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-guided Plan and Retrieval: A Strategic Alignment for Interpretable
  User Satisfaction Estimation in Dialogue <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sangyeop Kim, Sohhyung Park, Jaewon Jung, Jinseok Kim, Sungzoon Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding user satisfaction with conversational systems, known as User
Satisfaction Estimation (USE), is essential for assessing dialogue quality and
enhancing user experiences. However, existing methods for USE face challenges
due to limited understanding of underlying reasons for user dissatisfaction and
the high costs of annotating user intentions. To address these challenges, we
propose PRAISE (Plan and Retrieval Alignment for Interpretable Satisfaction
Estimation), an interpretable framework for effective user satisfaction
prediction. PRAISE operates through three key modules. The Strategy Planner
develops strategies, which are natural language criteria for classifying user
satisfaction. The Feature Retriever then incorporates knowledge on user
satisfaction from Large Language Models (LLMs) and retrieves relevance features
from utterances. Finally, the Score Analyzer evaluates strategy predictions and
classifies user satisfaction. Experimental results demonstrate that PRAISE
achieves state-of-the-art performance on three benchmarks for the USE task.
Beyond its superior performance, PRAISE offers additional benefits. It enhances
interpretability by providing instance-level explanations through effective
alignment of utterances with strategies. Moreover, PRAISE operates more
efficiently than existing approaches by eliminating the need for LLMs during
the inference phase.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Information-theoretic Multi-task Representation Learning Framework
  for Natural Language Understanding <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04667v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04667v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a new principled multi-task representation learning
framework (InfoMTL) to extract noise-invariant sufficient representations for
all tasks. It ensures sufficiency of shared representations for all tasks and
mitigates the negative effect of redundant features, which can enhance language
understanding of pre-trained language models (PLMs) under the multi-task
paradigm. Firstly, a shared information maximization principle is proposed to
learn more sufficient shared representations for all target tasks. It can avoid
the insufficiency issue arising from representation compression in the
multi-task paradigm. Secondly, a task-specific information minimization
principle is designed to mitigate the negative effect of potential redundant
features in the input for each task. It can compress task-irrelevant redundant
information and preserve necessary information relevant to the target for
multi-task prediction. Experiments on six classification benchmarks show that
our method outperforms 12 comparative multi-task methods under the same
multi-task settings, especially in data-constrained and noisy scenarios.
Extensive experiments demonstrate that the learned representations are more
sufficient, data-efficient, and robust.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, accepted to AAAI 2025 (main conference), the code is
  available at https://github.com/zerohd4869/InfoMTL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04647v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04647v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wen Yang, Junhong Wu, Chen Wang, Chengqing Zong, Jiajun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) has become a prominent method for
aligning Large Language Models (LLMs) with human preferences. While DPO has
enabled significant progress in aligning English LLMs, multilingual preference
alignment is hampered by data scarcity. To address this, we propose a novel
approach that $\textit{captures}$ learned preferences from well-aligned English
models by implicit rewards and $\textit{transfers}$ them to other languages
through iterative training. Specifically, we derive an implicit reward model
from the logits of an English DPO-aligned model and its corresponding reference
model. This reward model is then leveraged to annotate preference relations in
cross-lingual instruction-following pairs, using English instructions to
evaluate multilingual responses. The annotated data is subsequently used for
multilingual DPO fine-tuning, facilitating preference knowledge transfer from
English to other languages. Fine-tuning Llama3 for two iterations resulted in a
12.72% average improvement in Win Rate and a 5.97% increase in Length Control
Win Rate across all training languages on the X-AlpacaEval leaderboard. Our
findings demonstrate that leveraging existing English-aligned models can enable
efficient and effective multilingual preference alignment, significantly
reducing the need for extensive multilingual preference data. The code is
available at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in
  Expert-Domain Information Retrieval <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04644v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04644v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingyu Song, Guo Gan, Mingsheng Shang, Yilun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce IFIR, the first comprehensive benchmark designed to evaluate
instruction-following information retrieval (IR) in expert domains. IFIR
includes 2,426 high-quality examples and covers eight subsets across four
specialized domains: finance, law, healthcare, and science literature. Each
subset addresses one or more domain-specific retrieval tasks, replicating
real-world scenarios where customized instructions are critical. IFIR enables a
detailed analysis of instruction-following retrieval capabilities by
incorporating instructions at different levels of complexity. We also propose a
novel LLM-based evaluation method to provide a more precise and reliable
assessment of model performance in following instructions. Through extensive
experiments on 15 frontier retrieval models, including those based on LLMs, our
results reveal that current models face significant challenges in effectively
following complex, domain-specific instructions. We further provide in-depth
analyses to highlight these limitations, offering valuable insights to guide
future advancements in retriever development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models
  via Watermarking <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijie Xu, Aiwei Liu, Xuming Hu, Lijie Wen, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As open-source large language models (LLMs) like Llama3 become more capable,
it is crucial to develop watermarking techniques to detect their potential
misuse. Existing watermarking methods either add watermarks during LLM
inference, which is unsuitable for open-source LLMs, or primarily target
classification LLMs rather than recent generative LLMs. Adapting these
watermarks to open-source LLMs for misuse detection remains an open challenge.
This work defines two misuse scenarios for open-source LLMs: intellectual
property (IP) violation and LLM Usage Violation. Then, we explore the
application of inference-time watermark distillation and backdoor watermarking
in these contexts. We propose comprehensive evaluation methods to assess the
impact of various real-world further fine-tuning scenarios on watermarks and
the effect of these watermarks on LLM performance. Our experiments reveal that
backdoor watermarking could effectively detect IP Violation, while
inference-time watermark distillation is applicable in both scenarios but less
robust to further fine-tuning and has a more significant impact on LLM
performance compared to backdoor watermarking. Exploring more advanced
watermarking methods for open-source LLMs to detect their misuse should be an
important future direction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the 1st Workshop on GenAI Watermarking, collocated with
  ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Survey</span>Forge: On the Outline Heuristics, Memory-Driven Generation, and
  Multi-dimensional Evaluation for Automated <span class="highlight-title">Survey</span> Writing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, Bo Zhang, Lei Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Survey paper plays a crucial role in scientific research, especially given
the rapid growth of research publications. Recently, researchers have begun
using LLMs to automate survey generation for better efficiency. However, the
quality gap between LLM-generated surveys and those written by human remains
significant, particularly in terms of outline quality and citation accuracy. To
close these gaps, we introduce SurveyForge, which first generates the outline
by analyzing the logical structure of human-written outlines and referring to
the retrieved domain-related articles. Subsequently, leveraging high-quality
papers retrieved from memory by our scholar navigation agent, SurveyForge can
automatically generate and refine the content of the generated article.
Moreover, to achieve a comprehensive evaluation, we construct SurveyBench,
which includes 100 human-written survey papers for win-rate comparison and
assesses AI-generated survey papers across three dimensions: reference,
outline, and content quality. Experiments demonstrate that SurveyForge can
outperform previous works such as AutoSurvey.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and dataset are available for downloading at:
  https://github.com/Alpha-Innovator/SurveyForge 22 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ START: Self-taught Reasoner with Tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengpeng Li, Mingfeng Xue, Zhenru Zhang, Jiaxi Yang, Beichen Zhang, Xiang Wang, Bowen Yu, Binyuan Hui, Junyang Lin, Dayiheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have
demonstrated remarkable capabilities in complex reasoning tasks through the
utilization of long Chain-of-thought (CoT). However, these models often suffer
from hallucinations and inefficiencies due to their reliance solely on internal
reasoning processes. In this paper, we introduce START (Self-Taught Reasoner
with Tools), a novel tool-integrated long CoT reasoning LLM that significantly
enhances reasoning capabilities by leveraging external tools. Through code
execution, START is capable of performing complex computations, self-checking,
exploring diverse methods, and self-debugging, thereby addressing the
limitations of LRMs. The core innovation of START lies in its self-learning
framework, which comprises two key techniques: 1) Hint-infer: We demonstrate
that inserting artificially designed hints (e.g., ``Wait, maybe using Python
here is a good idea.'') during the inference process of a LRM effectively
stimulates its ability to utilize external tools without the need for any
demonstration data. Hint-infer can also serve as a simple and effective
sequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning
(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and
modifying the reasoning trajectories with tool invocation generated by a LRM
via Hint-infer, followed by fine-tuning the LRM. Through this framework, we
have fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA
(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the
competition-level code benchmark (LiveCodeBench), START achieves accuracy rates
of 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly
outperforms the base QwQ-32B and achieves performance comparable to the
state-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary
model o1-Preview.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 5 figures and 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SynGraph: A Dynamic Graph-LLM Synthesis Framework for Sparse Streaming
  User Sentiment Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Zhang, Qiyu Wei, Yingjie Zhu, Linhai Zhang, Deyu Zhou, Sophia Ananiadou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User reviews on e-commerce platforms exhibit dynamic sentiment patterns
driven by temporal and contextual factors. Traditional sentiment analysis
methods focus on static reviews, failing to capture the evolving temporal
relationship between user sentiment rating and textual content. Sentiment
analysis on streaming reviews addresses this limitation by modeling and
predicting the temporal evolution of user sentiments. However, it suffers from
data sparsity, manifesting in temporal, spatial, and combined forms. In this
paper, we introduce SynGraph, a novel framework designed to address data
sparsity in sentiment analysis on streaming reviews. SynGraph alleviates data
sparsity by categorizing users into mid-tail, long-tail, and extreme scenarios
and incorporating LLM-augmented enhancements within a dynamic graph-based
structure. Experiments on real-world datasets demonstrate its effectiveness in
addressing sparsity and improving sentiment modeling in streaming reviews.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Better Process Supervision with Bi-directional Rewarding Signals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenxiang Chen, Wei He, Zhiheng Xi, Honglin Guo, Boyang Hong, Jiazheng Zhang, Rui Zheng, Nijun Li, Tao Gui, Yun Li, Qi Zhang, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Process supervision, i.e., evaluating each step, is critical for complex
large language model (LLM) reasoning and test-time searching with increased
inference compute. Existing approaches, represented by process reward models
(PRMs), primarily focus on rewarding signals up to the current step, exhibiting
a one-directional nature and lacking a mechanism to model the distance to the
final target. To address this problem, we draw inspiration from the A*
algorithm, which states that an effective supervisory signal should
simultaneously consider the incurred cost and the estimated cost for reaching
the target. Building on this key insight, we introduce BiRM, a novel process
supervision model that not only evaluates the correctness of previous steps but
also models the probability of future success. We conduct extensive experiments
on mathematical reasoning tasks and demonstrate that BiRM provides more precise
evaluations of LLM reasoning steps, achieving an improvement of 3.1% on
Gaokao2023 over PRM under the Best-of-N sampling method. Besides, in
search-based strategies, BiRM provides more comprehensive guidance and
outperforms ORM by 5.0% and PRM by 3.8% respectively on MATH-500.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HalluCounter: Reference-free LLM Hallucination Detection in the Wild! 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashok Urlana, Gopichand Kanumolu, Charaka Vinayak Kumar, Bala Mallikarjunarao Garlapati, Rahul Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Response consistency-based, reference-free hallucination detection (RFHD)
methods do not depend on internal model states, such as generation
probabilities or gradients, which Grey-box models typically rely on but are
inaccessible in closed-source LLMs. However, their inability to capture
query-response alignment patterns often results in lower detection accuracy.
Additionally, the lack of large-scale benchmark datasets spanning diverse
domains remains a challenge, as most existing datasets are limited in size and
scope. To this end, we propose HalluCounter, a novel reference-free
hallucination detection method that utilizes both response-response and
query-response consistency and alignment patterns. This enables the training of
a classifier that detects hallucinations and provides a confidence score and an
optimal response for user queries. Furthermore, we introduce HalluCounterEval,
a benchmark dataset comprising both synthetically generated and human-curated
samples across multiple domains. Our method outperforms state-of-the-art
approaches by a significant margin, achieving over 90\% average confidence in
hallucination detection across datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Data-Efficient Language Models: A Child-Inspired Approach to
  Language Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Amin Ghanizadeh, Mohammad Javad Dousti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we explain our approach employed in the BabyLM Challenge, which
uses various methods of training language models (LMs) with significantly less
data compared to traditional large language models (LLMs) and are inspired by
how human children learn. While a human child is exposed to far less linguistic
input than an LLM, they still achieve remarkable language understanding and
generation abilities. To this end, we develop a model trained on a curated
dataset consisting of 10 million words, primarily sourced from child-directed
transcripts. The 2024 BabyLM Challenge initial dataset of 10M words is filtered
to 8.5M. Next, it is supplemented with a randomly selected subset of TVR
dataset consisting of 1.5M words of television dialogues. The latter dataset
ensures that similar to children, the model is also exposed to language through
media. Furthermore, we reduce the vocabulary size to 32,000 tokens, aligning it
with the limited vocabulary of children in the early stages of language
acquisition. We use curriculum learning and is able to match the baseline on
certain benchmarks while surpassing the baseline on others. Additionally,
incorporating common LLM training datasets, such as MADLAD-400, degrades
performance. These findings underscore the importance of dataset selection,
vocabulary scaling, and curriculum learning in creating more data-efficient
language models that better mimic human learning processes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Best of Both Worlds: Integrating Language Models and Diffusion
  Models for Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aoxiong Yin, Kai Shen, Yichong Leng, Xu Tan, Xinyu Zhou, Juncheng Li, Siliang Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-video (T2V) generation have been driven by two
competing paradigms: autoregressive language models and diffusion models.
However, each paradigm has intrinsic limitations: language models struggle with
visual quality and error accumulation, while diffusion models lack semantic
understanding and causal modeling. In this work, we propose LanDiff, a hybrid
framework that synergizes the strengths of both paradigms through
coarse-to-fine generation. Our architecture introduces three key innovations:
(1) a semantic tokenizer that compresses 3D visual features into compact 1D
discrete representations through efficient semantic compression, achieving a
$\sim$14,000$\times$ compression ratio; (2) a language model that generates
semantic tokens with high-level semantic relationships; (3) a streaming
diffusion model that refines coarse semantics into high-fidelity videos.
Experiments show that LanDiff, a 5B model, achieves a score of 85.43 on the
VBench T2V benchmark, surpassing the state-of-the-art open-source models
Hunyuan Video (13B) and other commercial models such as Sora, Keling, and
Hailuo. Furthermore, our model also achieves state-of-the-art performance in
long video generation, surpassing other open-source models in this field. Our
demo can be viewed at https://landiff.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HybridNorm: Towards Stable and Efficient <span class="highlight-title">Transformer</span> Training via Hybrid
  Normalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijian Zhuo, Yutao Zeng, Ya Wang, Sijun Zhang, Jian Yang, Xiaoqing Li, Xun Zhou, Jinwen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers have become the de facto architecture for a wide range of
machine learning tasks, particularly in large language models (LLMs). Despite
their remarkable performance, challenges remain in training deep transformer
networks, especially regarding the location of layer normalization. While
Pre-Norm structures facilitate easier training due to their more prominent
identity path, they often yield suboptimal performance compared to Post-Norm.
In this paper, we propose $\textbf{HybridNorm}$, a straightforward yet
effective hybrid normalization strategy that integrates the advantages of both
Pre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV
normalization within the attention mechanism and Post-Norm in the feed-forward
network (FFN) of each transformer block. This design not only stabilizes
training but also enhances performance, particularly in the context of LLMs.
Comprehensive experiments in both dense and sparse architectures show that
HybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,
achieving state-of-the-art results across various benchmarks. These findings
highlight the potential of HybridNorm as a more stable and effective technique
for improving the training and performance of deep transformer models. %Code
will be made publicly available. Code is available at
https://github.com/BryceZhuo/HybridNorm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compositional Causal Reasoning Evaluation in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacqueline R. M. A. Maasch, Alihan Hüyük, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal reasoning and compositional reasoning are two core aspirations in
generative AI. Measuring the extent of these behaviors requires principled
evaluation methods. We explore a unified perspective that considers both
behaviors simultaneously, termed compositional causal reasoning (CCR): the
ability to infer how causal measures compose and, equivalently, how causal
quantities propagate through graphs. We instantiate a framework for the
systematic evaluation of CCR for the average treatment effect and the
probability of necessity and sufficiency. As proof of concept, we demonstrate
the design of CCR tasks for language models in the LLama, Phi, and GPT
families. On a math word problem, our framework revealed a range of
taxonomically distinct error patterns. Additionally, CCR errors increased with
the complexity of causal paths for all models except o1.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compositional Translation: A Novel LLM-based Approach for Low-resource
  Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04554v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04554v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Armel Zebaze, Benoît Sagot, Rachel Bawden
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability of generative large language models (LLMs) to perform in-context
learning has given rise to a large body of research into how best to prompt
models for various natural language processing tasks. Machine Translation (MT)
has been shown to benefit from in-context examples, in particular when they are
semantically similar to the sentence to translate. In this paper, we propose a
new LLM-based translation paradigm, compositional translation, to replace naive
few-shot MT with similarity-based demonstrations. An LLM is used to decompose a
sentence into simpler phrases, and then to translate each phrase with the help
of retrieved demonstrations. Finally, the LLM is prompted to translate the
initial sentence with the help of the self-generated phrase-translation pairs.
Our intuition is that this approach should improve translation because these
shorter phrases should be intrinsically easier to translate and easier to match
with relevant examples. This is especially beneficial in low-resource
scenarios, and more generally whenever the selection pool is small or out of
domain. We show that compositional translation boosts LLM translation
performance on a wide range of popular MT benchmarks, including FLORES 200,
NTREX 128 and TICO-19. Code and outputs are available at
https://github.com/ArmelRandy/compositional-translation
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Empirical Study on Eliciting and Improving R1-like Reasoning Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhipeng Chen, Yingqian Min, Beichen Zhang, Jie Chen, Jinhao Jiang, Daixuan Cheng, Wayne Xin Zhao, Zheng Liu, Xu Miao, Yang Lu, Lei Fang, Zhongyuan Wang, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this report, we present the third technical report on the development of
slow-thinking models as part of the STILL project. As the technical pathway
becomes clearer, scaling RL training has become a central technique for
implementing such reasoning models. We systematically experiment with and
document the effects of various factors influencing RL training, conducting
experiments on both base models and fine-tuned models. Specifically, we
demonstrate that our RL training approach consistently improves the Qwen2.5-32B
base models, enhancing both response length and test accuracy. Furthermore, we
show that even when a model like DeepSeek-R1-Distill-Qwen-1.5B has already
achieved a high performance level, it can be further refined through RL
training, reaching an accuracy of 39.33% on AIME 2024. Beyond RL training, we
also explore the use of tool manipulation, finding that it significantly boosts
the reasoning performance of large reasoning models. This approach achieves a
remarkable accuracy of 86.67% with greedy search on AIME 2024, underscoring its
effectiveness in enhancing model capabilities. We release our resources at the
STILL project website: https://github.com/RUCAIBox/Slow_Thinking_with_LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report on Slow Thinking with LLMs: Part III</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Keeping Yourself is Important in Downstream Tuning Multimodal Large
  Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04543v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04543v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenke Huang, Jian Liang, Xianda Guo, Yiyang Fang, Guancheng Wan, Xuankun Rong, Chi Wen, Zekun Shi, Qingyun Li, Didi Zhu, Yanbiao Ma, Ke Liang, Bin Yang, He Li, Jiawei Shao, Mang Ye, Bo Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal Large Language Models (MLLMs) integrate visual and linguistic
reasoning to address complex tasks such as image captioning and visual question
answering. While MLLMs demonstrate remarkable versatility, MLLMs appears
limited performance on special applications. But tuning MLLMs for downstream
tasks encounters two key challenges: Task-Expert Specialization, where
distribution shifts between pre-training and target datasets constrain target
performance, and Open-World Stabilization, where catastrophic forgetting erases
the model general knowledge. In this work, we systematically review recent
advancements in MLLM tuning methodologies, classifying them into three
paradigms: (I) Selective Tuning, (II) Additive Tuning, and (III)
Reparameterization Tuning. Furthermore, we benchmark these tuning strategies
across popular MLLM architectures and diverse downstream tasks to establish
standardized evaluation analysis and systematic tuning principles. Finally, we
highlight several open challenges in this domain and propose future research
directions. To facilitate ongoing progress in this rapidly evolving field, we
provide a public repository that continuously tracks developments:
https://github.com/WenkeHuang/Awesome-MLLM-Tuning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Models in Bioinformatics: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenyu Wang, Zikang Wang, Jiyue Jiang, Pengan Chen, Xiangyu Shi, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are revolutionizing bioinformatics, enabling
advanced analysis of DNA, RNA, proteins, and single-cell data. This survey
provides a systematic review of recent advancements, focusing on genomic
sequence modeling, RNA structure prediction, protein function inference, and
single-cell transcriptomics. Meanwhile, we also discuss several key challenges,
including data scarcity, computational complexity, and cross-omics integration,
and explore future directions such as multimodal learning, hybrid AI models,
and clinical applications. By offering a comprehensive perspective, this paper
underscores the transformative potential of LLMs in driving innovations in
bioinformatics and precision medicine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generalized Interpolating Discrete Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitri von Rütte, Janis Fluri, Yuhui Ding, Antonio Orvieto, Bernhard Schölkopf, Thomas Hofmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While state-of-the-art language models achieve impressive results through
next-token prediction, they have inherent limitations such as the inability to
revise already generated tokens. This has prompted exploration of alternative
approaches such as discrete diffusion. However, masked diffusion, which has
emerged as a popular choice due to its simplicity and effectiveness,
reintroduces this inability to revise words. To overcome this, we generalize
masked diffusion and derive the theoretical backbone of a family of general
interpolating discrete diffusion (GIDD) processes offering greater flexibility
in the design of the noising processes. Leveraging a novel diffusion ELBO, we
achieve compute-matched state-of-the-art performance in diffusion language
modeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining
masking and uniform noise, leading to improved sample quality and unlocking the
ability for the model to correct its own mistakes, an area where autoregressive
models notoriously have struggled. Our code and models are open-source:
https://github.com/dvruette/gidd/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Guiding LLMs to Generate High-Fidelity and High-Quality Counterfactual
  Explanations for Text Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04463v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04463v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Van Bach Nguyen, Christin Seifert, Jörg Schlötterer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The need for interpretability in deep learning has driven interest in
counterfactual explanations, which identify minimal changes to an instance that
change a model's prediction. Current counterfactual (CF) generation methods
require task-specific fine-tuning and produce low-quality text. Large Language
Models (LLMs), though effective for high-quality text generation, struggle with
label-flipping counterfactuals (i.e., counterfactuals that change the
prediction) without fine-tuning. We introduce two simple classifier-guided
approaches to support counterfactual generation by LLMs, eliminating the need
for fine-tuning while preserving the strengths of LLMs. Despite their
simplicity, our methods outperform state-of-the-art counterfactual generation
methods and are effective across different LLMs, highlighting the benefits of
guiding counterfactual generation by LLMs with classifier information. We
further show that data augmentation by our generated CFs can improve a
classifier's robustness. Our analysis reveals a critical issue in
counterfactual generation by LLMs: LLMs rely on parametric knowledge rather
than faithfully following the classifier.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantifying patterns of punctuation in modern Chinese prose 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04449v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04449v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michał Dolina, Jakub Dec, Stanisław Drożdż, Jarosław Kwapień, Jin Liu, Tomasz Stanisz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research shows that punctuation patterns in texts exhibit universal
features across languages. Analysis of Western classical literature reveals
that the distribution of spaces between punctuation marks aligns with a
discrete Weibull distribution, typically used in survival analysis. By
extending this analysis to Chinese literature represented here by three notable
contemporary works, it is shown that Zipf's law applies to Chinese texts
similarly to Western texts, where punctuation patterns also improve adherence
to the law. Additionally, the distance distribution between punctuation marks
in Chinese texts follows the Weibull model, though larger spacing is less
frequent than in English translations. Sentence-ending punctuation,
representing sentence length, diverges more from this pattern, reflecting
greater flexibility in sentence length. This variability supports the formation
of complex, multifractal sentence structures, particularly evident in Gao
Xingjian's "Soul Mountain". These findings demonstrate that both Chinese and
Western texts share universal punctuation and word distribution patterns,
underscoring their broad applicability across languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Dataset</span> for Analysing News Framing in Chinese Media 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Owen Cook, Yida Mu, Xinye Yang, Xingyi Song, Kalina Bontcheva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Framing is an essential device in news reporting, allowing the writer to
influence public perceptions of current affairs. While there are existing
automatic news framing detection datasets in various languages, none of them
focus on news framing in the Chinese language which has complex character
meanings and unique linguistic features. This study introduces the first
Chinese News Framing dataset, to be used as either a stand-alone dataset or a
supplementary resource to the SemEval-2023 task 3 dataset. We detail its
creation and we run baseline experiments to highlight the need for such a
dataset and create benchmarks for future research, providing results obtained
through fine-tuning XLM-RoBERTa-Base and using GPT-4o in the zero-shot setting.
We find that GPT-4o performs significantly worse than fine-tuned XLM-RoBERTa
across all languages. For the Chinese language, we obtain an F1-micro (the
performance metric for SemEval task 3, subtask 2) score of 0.719 using only
samples from our Chinese News Framing dataset and a score of 0.753 when we
augment the SemEval dataset with Chinese news framing samples. With positive
news frame detection results, this dataset is a valuable resource for detecting
news frames in the Chinese language and is a valuable supplement to the
SemEval-2023 task 3 dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting the Othello World Model Hypothesis <span class="chip">ICLR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04421v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04421v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei Yuan, Anders Søgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Li et al. (2023) used the Othello board game as a test case for the ability
of GPT-2 to induce world models, and were followed up by Nanda et al. (2023b).
We briefly discuss the original experiments, expanding them to include more
language models with more comprehensive probing. Specifically, we analyze
sequences of Othello board states and train the model to predict the next move
based on previous moves. We evaluate seven language models (GPT-2, T5, Bart,
Flan-T5, Mistral, LLaMA-2, and Qwen2.5) on the Othello task and conclude that
these models not only learn to play Othello, but also induce the Othello board
layout. We find that all models achieve up to 99% accuracy in unsupervised
grounding and exhibit high similarity in the board features they learned. This
provides considerably stronger evidence for the Othello World Model Hypothesis
than previous works.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR World Models Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Large Language Models Predict Antimicrobial Resistance Gene? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04413v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04413v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyunwoo Yoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study demonstrates that generative large language models can be utilized
in a more flexible manner for DNA sequence analysis and classification tasks
compared to traditional transformer encoder-based models. While recent
encoder-based models such as DNABERT and Nucleotide Transformer have shown
significant performance in DNA sequence classification, transformer
decoder-based generative models have not yet been extensively explored in this
field. This study evaluates how effectively generative Large Language Models
handle DNA sequences with various labels and analyzes performance changes when
additional textual information is provided. Experiments were conducted on
antimicrobial resistance genes, and the results show that generative Large
Language Models can offer comparable or potentially better predictions,
demonstrating flexibility and accuracy when incorporating both sequence and
textual information. The code and data used in this work are available at the
following GitHub repository: https://github.com/biocomgit/llm4dna.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and
  NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sanjib Narzary, Bihung Brahma, Haradip Mahilary, Mahananda Brahma, Bidisha Som, Sukumar Nandi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical
tasks for Natural Language Processing (NLP), yet their availability for
low-resource languages (LRLs) like Bodo remains limited. This article presents
a comparative empirical study investigating the effectiveness of Google's
Gemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer
of POS and NER tagging to Bodo. We explore two distinct methodologies: (1)
direct translation of English sentences to Bodo followed by tag transfer, and
(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both
methods leverage the machine translation and cross-lingual understanding
capabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and
NER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the
capabilities and limitations of each approach, demonstrating that while both
methods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits
superior performance, particularly for NER. We provide a detailed analysis of
the results, highlighting the impact of translation quality, grammatical
divergences, and the inherent challenges of zero-shot cross-lingual transfer.
The article concludes by discussing future research directions, emphasizing the
need for hybrid approaches, few-shot fine-tuning, and the development of
dedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for
this low-resource language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to SpringerNature MTAP journal. This article has not been
  reviewed yet. Submitting for public review!</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TableLoRA: Low-rank Adaptation on Table Structure Understanding for
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04396v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04396v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi He, Yihao Liu, Mengyu Zhou, Yeye He, Haoyu Dong, Shi Han, Zejian Yuan, Dongmei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular data are crucial in many fields and their understanding by large
language models (LLMs) under high parameter efficiency paradigm is important.
However, directly applying parameter-efficient fine-tuning (PEFT) techniques to
tabular tasks presents significant challenges, particularly in terms of better
table serialization and the representation of two-dimensional structured
information within a one-dimensional sequence. To address this, we propose
TableLoRA, a module designed to improve LLMs' understanding of table structure
during PEFT. It incorporates special tokens for serializing tables with special
token encoder and uses 2D LoRA to encode low-rank information on cell
positions. Experiments on four tabular-related datasets demonstrate that
TableLoRA consistently outperforms vanilla LoRA and surpasses various table
encoding methods tested in control experiments. These findings reveal that
TableLoRA, as a table-specific LoRA, enhances the ability of LLMs to process
tabular data effectively, especially in low-parameter settings, demonstrating
its potential as a robust solution for handling table-related tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shaping Shared Languages: Human and Large Language Models' Inductive
  Biases in Emergent Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04395v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04395v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tom Kouwenhoven, Max Peeperkorn, Roy de Kleijn, Tessa Verhoef
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Languages are shaped by the inductive biases of their users. Using a
classical referential game, we investigate how artificial languages evolve when
optimised for inductive biases in humans and large language models (LLMs) via
Human-Human, LLM-LLM and Human-LLM experiments. We show that referentially
grounded vocabularies emerge that enable reliable communication in all
conditions, even when humans and LLMs collaborate. Comparisons between
conditions reveal that languages optimised for LLMs subtly differ from those
optimised for humans. Interestingly, interactions between humans and LLMs
alleviate these differences and result in vocabularies which are more
human-like than LLM-like. These findings advance our understanding of how
inductive biases in LLMs play a role in the dynamic nature of human language
and contribute to maintaining alignment in human and machine communication. In
particular, our work underscores the need to think of new methods that include
human interaction in the training processes of LLMs, and shows that using
communicative success as a reward signal can be a fruitful, novel direction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ More Documents, Same Length: Isolating the Challenge of Multiple
  Documents in RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04388v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04388v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahar Levy, Nir Mazor, Lihi Shalmon, Michael Hassid, Gabriel Stanovsky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) provides LLMs with relevant documents.
Although previous studies noted that retrieving many documents can degrade
performance, they did not isolate how the quantity of documents affects
performance while controlling for context length. We evaluate various language
models on custom datasets derived from a multi-hop QA task. We keep the context
length and position of relevant information constant while varying the number
of documents, and find that increasing the document count in RAG settings poses
significant challenges for LLMs. Additionally, our results indicate that
processing multiple documents is a separate challenge from handling long
contexts. We also make the datasets and code available:
https://github.com/shaharl6000/MoreDocsSameLen .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for
  LLM-as-a-Judge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng-Han Chiang, Hung-yi Lee, Michal Lukasik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The LLM-as-a-judge paradigm uses large language models (LLMs) for automated
text evaluation, where a numerical assessment is assigned by an LLM to the
input text following scoring rubrics. Existing methods for LLM-as-a-judge use
cross-entropy (CE) loss for fine-tuning, which neglects the numeric nature of
score prediction. Recent work addresses numerical prediction limitations of LLM
fine-tuning through regression-aware fine-tuning, which, however, does not
consider chain-of-thought (CoT) reasoning for score prediction. In this paper,
we introduce TRACT (Two-stage Regression-Aware fine-tuning with CoT), a method
combining CoT reasoning with regression-aware training. TRACT consists of two
stages: first, seed LLM is fine-tuned to generate CoTs, which serve as
supervision for the second stage fine-tuning. The training objective of TRACT
combines the CE loss for learning the CoT reasoning capabilities, and the
regression-aware loss for the score prediction. Experiments across four
LLM-as-a-judge datasets and two LLMs show that TRACT significantly outperforms
existing methods. Extensive ablation studies validate the importance of each
component in TRACT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes and models are available at https://github.com/d223302/TRACT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dedicated Feedback and Edit Models Empower Inference-Time Scaling for
  Open-Ended General-Domain Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04378v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04378v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inference-Time Scaling has been critical to the success of recent models such
as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for
inference-time scaling require tasks to have answers that can be verified,
limiting their application to domains such as math, coding and logical
reasoning. We take inspiration from how humans make first attempts, ask for
detailed feedback from others and make improvements based on such feedback
across a wide spectrum of open-ended endeavors. To this end, we collect data
for and train dedicated Feedback and Edit Models that are capable of performing
inference-time scaling for open-ended general-domain tasks. In our setup, one
model generates an initial response, which are given feedback by a second
model, that are then used by a third model to edit the response. We show that
performance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo
can be boosted by scaling the number of initial response drafts, effective
feedback and edited responses. When scaled optimally, our setup based on 70B
models from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7
as of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and
DeepSeek R1 with 92.3.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assumed Identities: Quantifying Gender Bias in Machine Translation of
  Ambiguous Occupational Terms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Orfeas Menis Mastromichalakis, Giorgos Filandrianos, Maria Symeonaki, Giorgos Stamou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine Translation (MT) systems frequently encounter ambiguous scenarios
where they must assign gender to certain occupations when translating without
explicit guidance or contextual cues. While individual translations in such
cases may not be inherently biased, systematic patterns-such as the repeated
association of certain professions with specific genders-can emerge, reflecting
and perpetuating societal stereotypes. This ambiguity challenges traditional
instance-level single-answer evaluation approaches, as no single gold standard
translation exists. To address this, we propose an approach that evaluates
gender bias through aggregated model responses. Specifically, we introduce a
methodology to detect gender imbalances between source texts and translations,
a benchmarking dataset with ambiguous English inputs, and probability-based
metrics to quantify a model's divergence from normative standards or reference
distributions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lost in Literalism: How Supervised Training Shapes Translationese in
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yafu Li, Ronghao Zhang, Zhilin Wang, Huajian Zhang, Leyang Cui, Yongjing Yin, Tong Xiao, Yue Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have achieved remarkable success in machine
translation, demonstrating impressive performance across diverse languages.
However, translationese, characterized by overly literal and unnatural
translations, remains a persistent challenge in LLM-based translation systems.
Despite their pre-training on vast corpora of natural utterances, LLMs exhibit
translationese errors and generate unexpected unnatural translations, stemming
from biases introduced during supervised fine-tuning (SFT). In this work, we
systematically evaluate the prevalence of translationese in LLM-generated
translations and investigate its roots during supervised training. We introduce
methods to mitigate these biases, including polishing golden references and
filtering unnatural training instances. Empirical evaluations demonstrate that
these approaches significantly reduce translationese while improving
translation naturalness, validated by human evaluations and automatic metrics.
Our findings highlight the need for training-aware adjustments to optimize LLM
translation outputs, paving the way for more fluent and
target-language-consistent translations. We release the data and code at
https://github.com/yafuly/LLM_Translationese.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages;</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring the Multilingual NLG Evaluation Abilities of LLM-Based
  Evaluators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04360v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04360v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Chang, Mingqi Gao, Xinyu Hu, Xiaojun Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous research has shown that LLMs have potential in multilingual NLG
evaluation tasks. However, existing research has not fully explored the
differences in the evaluation capabilities of LLMs across different languages.
To this end, this study provides a comprehensive analysis of the multilingual
evaluation performance of 10 recent LLMs, spanning high-resource and
low-resource languages through correlation analysis, perturbation attacks, and
fine-tuning. We found that 1) excluding the reference answer from the prompt
and using large-parameter LLM-based evaluators leads to better performance
across various languages; 2) most LLM-based evaluators show a higher
correlation with human judgments in high-resource languages than in
low-resource languages; 3) in the languages where they are most sensitive to
such attacks, they also tend to exhibit the highest correlation with human
judgments; and 4) fine-tuning with data from a particular language yields a
broadly consistent enhancement in the model's evaluation performance across
diverse languages. Our findings highlight the imbalance in LLMs'evaluation
capabilities across different languages and suggest that low-resource language
scenarios deserve more attention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Layer-Specific Scaling of Positional Encodings for Superior Long-Context
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04355v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04355v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenghua Wang, Yiran Ding, Changze Lv, Zhibo Xu, Tianlong Li, Tianyuan Shi, Xiaoqing Zheng, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although large language models (LLMs) have achieved significant progress in
handling long-context inputs, they still suffer from the ``lost-in-the-middle''
problem, where crucial information in the middle of the context is often
underrepresented or lost. Our extensive experiments reveal that this issue may
arise from the rapid long-term decay in Rotary Position Embedding (RoPE). To
address this problem, we propose a layer-specific positional encoding scaling
method that assigns distinct scaling factors to each layer, slowing down the
decay rate caused by RoPE to make the model pay more attention to the middle
context. A specially designed genetic algorithm is employed to efficiently
select the optimal scaling factors for each layer by incorporating Bezier
curves to reduce the search space. Through comprehensive experimentation, we
demonstrate that our method significantly alleviates the ``lost-in-the-middle''
problem. Our approach results in an average accuracy improvement of up to 20%
on the Key-Value Retrieval dataset. Furthermore, we show that layer-specific
interpolation, as opposed to uniform interpolation across all layers, enhances
the model's extrapolation capabilities when combined with PI and Dynamic-NTK
positional encoding schemes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adding Alignment Control to Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04346v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04346v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhong Zhu, Weinan Zhang, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-training alignment has increasingly become a crucial factor in enhancing
the usability of language models (LMs). However, the strength of alignment
varies depending on individual preferences. This paper proposes a method to
incorporate alignment control into a single model, referred to as CLM. This
approach adds one identity layer preceding the initial layers and performs
preference learning only on this layer to map unaligned input token embeddings
into the aligned space. Experimental results demonstrate that this efficient
fine-tuning method performs comparable to full fine-tuning. During inference,
the input embeddings are processed through the aligned and unaligned layers,
which are then merged through the interpolation coefficient. By controlling
this parameter, the alignment exhibits a clear interpolation and extrapolation
phenomenon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In-depth Analysis of Graph-based RAG in a Unified Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04338v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04338v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingli Zhou, Yaodong Su, Youran Sun, Shu Wang, Taotao Wang, Runyuan He, Yongwei Zhang, Sicong Liang, Xilin Liu, Yuchi Ma, Yixiang Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-based Retrieval-Augmented Generation (RAG) has proven effective in
integrating external knowledge into large language models (LLMs), improving
their factual accuracy, adaptability, interpretability, and trustworthiness. A
number of graph-based RAG methods have been proposed in the literature.
However, these methods have not been systematically and comprehensively
compared under the same experimental settings. In this paper, we first
summarize a unified framework to incorporate all graph-based RAG methods from a
high-level perspective. We then extensively compare representative graph-based
RAG methods over a range of questing-answering (QA) datasets -- from specific
questions to abstract questions -- and examine the effectiveness of all
methods, providing a thorough analysis of graph-based RAG approaches. As a
byproduct of our experimental analysis, we are also able to identify new
variants of the graph-based RAG methods over specific QA and abstract QA tasks
respectively, by combining existing techniques, which outperform the
state-of-the-art methods. Finally, based on these findings, we offer promising
research opportunities. We believe that a deeper understanding of the behavior
of existing methods can provide new valuable insights for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Solving Word-Sense Disambiguation and Word-Sense Induction with
  Dictionary Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tadej Škvorc, Marko Robnik-Šikonja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many less-resourced languages struggle with a lack of large, task-specific
datasets that are required for solving relevant tasks with modern
transformer-based large language models (LLMs). On the other hand, many
linguistic resources, such as dictionaries, are rarely used in this context
despite their large information contents. We show how LLMs can be used to
extend existing language resources in less-resourced languages for two
important tasks: word-sense disambiguation (WSD) and word-sense induction
(WSI). We approach the two tasks through the related but much more accessible
word-in-context (WiC) task where, given a pair of sentences and a target word,
a classification model is tasked with predicting whether the sense of a given
word differs between sentences. We demonstrate that a well-trained model for
this task can distinguish between different word senses and can be adapted to
solve the WSD and WSI tasks. The advantage of using the WiC task, instead of
directly predicting senses, is that the WiC task does not need pre-constructed
sense inventories with a sufficient number of examples for each sense, which
are rarely available in less-resourced languages. We show that sentence pairs
for the WiC task can be successfully generated from dictionary examples using
LLMs. The resulting prediction models outperform existing models on WiC, WSD,
and WSI tasks. We demonstrate our methodology on the Slovene language, where a
monolingual dictionary is available, but word-sense resources are tiny.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Computational Law: <span class="highlight-title">Dataset</span>s, Benchmarks, and Ontologies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04305v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04305v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dilek Küçük, Fazli Can
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent developments in computer science and artificial intelligence have also
contributed to the legal domain, as revealed by the number and range of related
publications and applications. Machine and deep learning models require
considerable amount of domain-specific data for training and comparison
purposes, in order to attain high-performance in the legal domain.
Additionally, semantic resources such as ontologies are valuable for building
large-scale computational legal systems, in addition to ensuring
interoperability of such systems. Considering these aspects, we present an
up-to-date review of the literature on datasets, benchmarks, and ontologies
proposed for computational law. We believe that this comprehensive and recent
review will help researchers and practitioners when developing and testing
approaches and systems for computational law.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual-Class <span class="highlight-title">Prompt</span> Generation: Enhancing Indonesian Gender-Based Hate
  Speech Detection through Data Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Amien Ibrahim,  Faisal, Tora Sangputra Yopie Winarto, Zefanya Delvin Sulistiya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting gender-based hate speech in Indonesian social media remains
challenging due to limited labeled datasets. While binary hate speech
classification has advanced, a more granular category like gender-targeted hate
speech is understudied because of class imbalance issues. This paper addresses
this gap by comparing three data augmentation techniques for Indonesian
gender-based hate speech detection. We evaluate backtranslation, single-class
prompt generation (using only hate speech examples), and our proposed
dual-class prompt generation (using both hate speech and non-hate speech
examples). Experiments show all augmentation methods improve classification
performance, with our dual-class approach achieving the best results (88.5%
accuracy, 88.1% F1-score using Random Forest). Semantic similarity analysis
reveals dual-class prompt generation produces the most novel content, while
T-SNE visualizations confirm these samples occupy distinct feature space
regions while maintaining class characteristics. Our findings suggest that
incorporating examples from both classes helps language models generate more
diverse yet representative samples, effectively addressing limited data
challenges in specialized hate speech detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 8th World Conference on Computing and Communication
  Technologies (WCCCT 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Fact and Frequency: LLM Responses to Misinformation Expressed with
  Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yana van de Sande, Gunes Açar, Thabo van Woudenberg, Martha Larson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study LLM judgments of misinformation expressed with uncertainty. Our
experiments study the response of three widely used LLMs (GPT-4o, LlaMA3,
DeepSeek-v2) to misinformation propositions that have been verified false and
then are transformed into uncertain statements according to an uncertainty
typology. Our results show that after transformation, LLMs change their
factchecking classification from false to not-false in 25% of the cases.
Analysis reveals that the change cannot be explained by predictors to which
humans are expected to be sensitive, i.e., modality, linguistic cues, or
argumentation strategy. The exception is doxastic transformations, which use
linguistic cue phrases such as "It is believed ...".To gain further insight, we
prompt the LLM to make another judgment about the transformed misinformation
statements that is not related to truth value. Specifically, we study LLM
estimates of the frequency with which people make the uncertain statement. We
find a small but significant correlation between judgment of fact and
estimation of frequency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 1 figure, 3 tables, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffPO: Diffusion-styled Preference Optimization for Efficient
  Inference-Time Alignment of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Joey Tianyi Zhou, Tony Quek, Soujanya Poria, Zuozhu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inference-time alignment provides an efficient alternative for aligning LLMs
with humans. However, these approaches still face challenges, such as limited
scalability due to policy-specific value functions and latency during the
inference phase. In this paper, we propose a novel approach, Diffusion-styled
Preference Optimization (\model), which provides an efficient and
policy-agnostic solution for aligning LLMs with humans. By directly performing
alignment at sentence level, \model~avoids the time latency associated with
token-level generation. Designed as a plug-and-play module, \model~can be
seamlessly integrated with various base models to enhance their alignment.
Extensive experiments on AlpacaEval 2, MT-bench, and HH-RLHF demonstrate that
\model~achieves superior alignment performance across various settings,
achieving a favorable trade-off between alignment quality and inference-time
latency. Furthermore, \model~demonstrates model-agnostic scalability,
significantly improving the performance of large models such as Llama-3-70B.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tgea: An error-annotated <span class="highlight-title">dataset</span> and benchmark tasks for text generation
  from <span class="highlight-title">pretrain</span>ed language models <span class="chip">ACL 2021</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04232v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04232v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie He, Bo Peng, Yi Liao, Qun Liu, Deyi Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In order to deeply understand the capability of pretrained language models in
text generation and conduct a diagnostic evaluation, we propose TGEA, an
error-annotated dataset with multiple benchmark tasks for text generation from
pretrained language models (PLMs). We use carefully selected prompt words to
guide GPT-2 to generate candidate sentences, from which we select 47K for error
annotation. Crowdsourced workers manually check each of these sentences and
detect 12k erroneous sentences. We create an error taxonomy to cover 24 types
of errors occurring in these erroneous sentences according to the nature of
errors with respect to linguistics and knowledge (eg, common sense). For each
erroneous span in PLM-generated sentences, we also detect another span that is
closely associated with it. Each error is hence manually labeled with
comprehensive annotations, including the span of the error, the associated
span, minimal correction to the error, the type of the error, and rationale
behind the error. Apart from the fully annotated dataset, we also present a
detailed description of the data collection procedure, statistics and analysis
of the dataset. This is the first dataset with comprehensive annotations for
PLM-generated texts, which facilitates the diagnostic evaluation of PLM-based
text generation. Furthermore, we use TGEA as a benchmark dataset and propose a
series of automatic diagnosis tasks, including error detection, error type
classification, associated span detection, error rationale generation, to
further promote future study on the automatic error detection and correction on
texts generated by pretrained language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2021</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyi Yang, Fanqi Wan, Longguang Zhong, Canbin Huang, Guosheng Liang, Xiaojun Quan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce FuseChat-3.0, a suite of large language models (LLMs) developed
by integrating the strengths of heterogeneous source LLMs into more compact
target LLMs. Our source models include the powerful Gemma-2-27B-it,
Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct.
For target models, we focus on three widely-used smaller
variants-Llama-3.1-8B-Instruct, Gemma-2-9B-it, and Qwen-2.5-7B-Instruct-along
with two ultra-compact options, Llama-3.2-3B-Instruct and
Llama-3.2-1B-Instruct. To leverage the diverse capabilities of these source
models, we develop a specialized data construction protocol tailored to various
tasks and domains. The FuseChat-3.0 training pipeline consists of two key
stages: (1) supervised fine-tuning (SFT) to align the target and source model
distributions, and (2) Direct Preference Optimization (DPO) to apply
preferences from multiple source LLMs to fine-tune the target model. The
resulting FuseChat-3.0 models exhibit significant performance gains across
tasks such as instruction following, general knowledge, mathematics, and
coding. As illustrated in Figure 1, using Llama-3.1-8B-Instruct as the target
model, our fusion approach achieves an average improvement of 6.8 points across
14 benchmarks. Moreover, it demonstrates remarkable gains of 37.1 points and
30.1 points on the instruction-following benchmarks AlpacaEval-2 and
Arena-Hard, respectively. Our code, models, and datasets are available at
https://github.com/SLIT-AI/FuseChat-3.0.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative
  Approach to Few-shot Multimodal Dialogue Intention Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04201v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04201v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Chen, Yu Zhang, Hongfei Ye, Ziyi Huang, Hongyang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Few-shot multimodal dialogue intention recognition is a critical challenge in
the e-commerce domainn. Previous methods have primarily enhanced model
classification capabilities through post-training techniques. However, our
analysis reveals that training for few-shot multimodal dialogue intention
recognition involves two interconnected tasks, leading to a seesaw effect in
multi-task learning. This phenomenon is attributed to knowledge interference
stemming from the superposition of weight matrix updates during the training
process. To address these challenges, we propose Knowledge-Decoupled Synergetic
Learning (KDSL), which mitigates these issues by utilizing smaller models to
transform knowledge into interpretable rules, while applying the post-training
of larger models. By facilitating collaboration between the large and small
multimodal large language models for prediction, our approach demonstrates
significant improvements. Notably, we achieve outstanding results on two real
Taobao datasets, with enhancements of 6.37\% and 6.28\% in online weighted F1
scores compared to the state-of-the-art method, thereby validating the efficacy
of our framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Measuring temporal effects of agent knowledge by date-controlled tool
  use 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04188v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04188v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R. Patrick Xian, Qiming Cui, Stefan Bauer, Reza Abbasi-Asl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal progression is an integral part of knowledge accumulation and
update. Web search is frequently adopted as grounding for agent knowledge, yet
its inappropriate configuration affects the quality of agent responses. Here,
we construct a tool-based out-of-sample testing framework to measure the
knowledge variability of large language model (LLM) agents from distinct
date-controlled tools (DCTs). We demonstrate the temporal effects of an LLM
agent as a writing assistant, which can use web search to help complete
scientific publication abstracts. We show that temporal effects of the search
engine translates into tool-dependent agent performance but can be alleviated
with base model choice and explicit reasoning instructions such as
chain-of-thought prompting. Our results indicate that agent evaluation should
take a dynamical view and account for the temporal influence of tools and the
updates of external resources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>comments welcome</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large-Scale AI in Telecom: Charting the Roadmap for Innovation,
  Scalability, and Enhanced Digital Experiences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04184v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04184v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adnan Shahid, Adrian Kliks, Ahmed Al-Tahmeesschi, Ahmed Elbakary, Alexandros Nikou, Ali Maatouk, Ali Mokh, Amirreza Kazemi, Antonio De Domenico, Athanasios Karapantelakis, Bo Cheng, Bo Yang, Bohao Wang, Carlo Fischione, Chao Zhang, Chaouki Ben Issaid, Chau Yuen, Chenghui Peng, Chongwen Huang, Christina Chaccour, Christo Kurisummoottil Thomas, Dheeraj Sharma, Dimitris Kalogiros, Dusit Niyato, Eli De Poorter, Elissa Mhanna, Emilio Calvanese Strinati, Faouzi Bader, Fathi Abdeldayem, Fei Wang, Fenghao Zhu, Gianluca Fontanesi, Giovanni Geraci, Haibo Zhou, Hakimeh Purmehdi, Hamed Ahmadi, Hang Zou, Hongyang Du, Hoon Lee, Howard H. Yang, Iacopo Poli, Igor Carron, Ilias Chatzistefanidis, Inkyu Lee, Ioannis Pitsiorlas, Jaron Fontaine, Jiajun Wu, Jie Zeng, Jinan Li, Jinane Karam, Johny Gemayel, Juan Deng, Julien Frison, Kaibin Huang, Kehai Qiu, Keith Ball, Kezhi Wang, Kun Guo, Leandros Tassiulas, Lecorve Gwenole, Liexiang Yue, Lina Bariah, Louis Powell, Marcin Dryjanski, Maria Amparo Canaveras Galdon, Marios Kountouris, Maryam Hafeez, Maxime Elkael, Mehdi Bennis, Mehdi Boudjelli, Meiling Dai, Merouane Debbah, Michele Polese, Mohamad Assaad, Mohamed Benzaghta, Mohammad Al Refai, Moussab Djerrab, Mubeen Syed, Muhammad Amir, Na Yan, Najla Alkaabi, Nan Li, Nassim Sehad, Navid Nikaein, Omar Hashash, Pawel Sroka, Qianqian Yang, Qiyang Zhao, Rasoul Nikbakht Silab, Rex Ying, Roberto Morabito, Rongpeng Li, Ryad Madi, Salah Eddine El Ayoubi, Salvatore D'Oro, Samson Lasaulce, Serveh Shalmashi, Sige Liu, Sihem Cherrared, Swarna Bindu Chetty, Swastika Dutta, Syed A. R. Zaidi, Tianjiao Chen, Timothy Murphy, Tommaso Melodia, Tony Q. S. Quek, Vishnu Ram, Walid Saad, Wassim Hamidouche, Weilong Chen, Xiaoou Liu, Xiaoxue Yu, Xijun Wang, Xingyu Shang, Xinquan Wang, Xuelin Cao, Yang Su, Yanping Liang, Yansha Deng, Yifan Yang, Yingping Cui, Yu Sun, Yuxuan Chen, Yvan Pointurier, Zeinab Nehme, Zeinab Nezami, Zhaohui Yang, Zhaoyang Zhang, Zhe Liu, Zhenyu Yang, Zhu Han, Zhuang Zhou, Zihan Chen, Zirui Chen, Zitao Shuai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This white paper discusses the role of large-scale AI in the
telecommunications industry, with a specific focus on the potential of
generative AI to revolutionize network functions and user experiences,
especially in the context of 6G systems. It highlights the development and
deployment of Large Telecom Models (LTMs), which are tailored AI models
designed to address the complex challenges faced by modern telecom networks.
The paper covers a wide range of topics, from the architecture and deployment
strategies of LTMs to their applications in network management, resource
allocation, and optimization. It also explores the regulatory, ethical, and
standardization considerations for LTMs, offering insights into their future
integration into telecom infrastructure. The goal is to provide a comprehensive
roadmap for the adoption of LTMs to enhance scalability, performance, and
user-centric innovation in telecom networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal
  Clinical Records 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04176v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04176v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hejie Cui, Alyssa Unell, Bowen Chen, Jason Alan Fries, Emily Alsentzer, Sanmi Koyejo, Nigam Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have emerged as promising tools for assisting in
medical tasks, yet processing Electronic Health Records (EHRs) presents unique
challenges due to their longitudinal nature. While LLMs' capabilities to
perform medical tasks continue to improve, their ability to reason over
temporal dependencies across multiple patient visits and time frames remains
unexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation
for Longitudinal Clinical Records), a framework that incorporate
instruction-response pairs grounding to different parts of a patient's record
as a critical dimension in both instruction evaluation and tuning for
longitudinal clinical records. We develop TIMER-Bench, the first time-aware
benchmark that evaluates temporal reasoning capabilities over longitudinal
EHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to
learn reasoning over time. We demonstrate that models fine-tuned with
TIMER-Instruct improve performance by 7.3% on human-generated benchmarks and
9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model
performance for reasoning over EHR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BPQA <span class="highlight-title">Dataset</span>: Evaluating How Well Language Models Leverage Blood
  Pressures to Answer Biomedical Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04155v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04155v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chi Hang, Ruiqi Deng, Lavender Yao Jiang, Zihao Yang, Anton Alyakin, Daniel Alber, Eric Karl Oermann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinical measurements such as blood pressures and respiration rates are
critical in diagnosing and monitoring patient outcomes. It is an important
component of biomedical data, which can be used to train transformer-based
language models (LMs) for improving healthcare delivery. It is, however,
unclear whether LMs can effectively interpret and use clinical measurements. We
investigate two questions: First, can LMs effectively leverage clinical
measurements to answer related medical questions? Second, how to enhance an
LM's performance on medical question-answering (QA) tasks that involve
measurements? We performed a case study on blood pressure readings (BPs), a
vital sign routinely monitored by medical professionals. We evaluated the
performance of four LMs: BERT, BioBERT, MedAlpaca, and GPT-3.5, on our newly
developed dataset, BPQA (Blood Pressure Question Answering). BPQA contains
$100$ medical QA pairs that were verified by medical students and designed to
rely on BPs . We found that GPT-3.5 and MedAlpaca (larger and medium sized LMs)
benefit more from the inclusion of BPs than BERT and BioBERT (small sized LMs).
Further, augmenting measurements with labels improves the performance of
BioBERT and Medalpaca (domain specific LMs), suggesting that retrieval may be
useful for improving domain-specific LMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ticktack : Long Span Temporal Alignment of Large Language Models
  Leveraging Sexagenary Cycle Time Expression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xue Han, Qian Hu, Yitong Wang, Wenchun Gao, Lianlian Zhang, Qing Wang, Lijun Mei, Chao Deng, Junlan Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) suffer from temporal misalignment issues
especially across long span of time. The issue arises from knowing that LLMs
are trained on large amounts of data where temporal information is rather
sparse over long times, such as thousands of years, resulting in insufficient
learning or catastrophic forgetting by the LLMs. This paper proposes a
methodology named "Ticktack" for addressing the LLM's long-time span
misalignment in a yearly setting. Specifically, we first propose to utilize the
sexagenary year expression instead of the Gregorian year expression employed by
LLMs, achieving a more uniform distribution in yearly granularity. Then, we
employ polar coordinates to model the sexagenary cycle of 60 terms and the year
order within each term, with additional temporal encoding to ensure LLMs
understand them. Finally, we present a temporal representational alignment
approach for post-training LLMs that effectively distinguishes time points with
relevant knowledge, hence improving performance on time-related tasks,
particularly over a long period. We also create a long time span benchmark for
evaluation. Experimental results prove the effectiveness of our proposal.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Benchmarking of Reasoning Capabilities in Code Large Language
  Models Under Data Contamination 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04149v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04149v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simin Chen, Pranav Pusarla, Baishakhi Ray
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid evolution of code largelanguage models underscores the need for
effective and transparent benchmarking of their reasoning capabilities.
However, the current benchmarking approach heavily depends on publicly
available, human-created datasets. The widespread use of these fixed benchmark
datasets makes the benchmarking process to be static and thus particularly
susceptible to data contamination, an unavoidable consequence of the extensive
data collection processes used to train Code LLMs. Existing approaches that
address data contamination often suffer from human effort limitations and
imbalanced problem complexity. To tackle these challenges, we propose \tool, a
novel benchmarking suite for evaluating Code LLMs under potential data
contamination. Given a seed programming problem, \tool employs multiple agents
to extract and modify the context without altering the core logic, generating
semantically equivalent variations. We introduce a dynamic data generation
methods and conduct empirical studies on two seed datasets across 21 Code LLMs.
Results show that \tool effectively benchmarks reasoning capabilities under
contamination risks while generating diverse problem sets to ensure consistent
and reliable evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://codekaleidoscope.github.io/dycodeeval.html</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for
  Training-free Retrieval of Conversational Data using LLMs <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04141v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04141v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sangyeop Kim, Hangyeul Lee, Yohan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growth of conversational AI services has increased demand for effective
information retrieval from dialogue data. However, existing methods often face
challenges in capturing semantic intent or require extensive labeling and
fine-tuning. This paper introduces HEISIR (Hierarchical Expansion of Inverted
Semantic Indexing for Retrieval), a novel framework that enhances semantic
understanding in conversational data retrieval through optimized data
ingestion, eliminating the need for resource-intensive labeling or model
adaptation. HEISIR implements a two-step process: (1) Hierarchical Triplets
Formulation and (2) Adjunct Augmentation, creating semantic indices consisting
of Subject-Verb-Object-Adjunct (SVOA) quadruplets. This structured
representation effectively captures the underlying semantic information from
dialogue content. HEISIR achieves high retrieval performance while maintaining
low latency during the actual retrieval process. Our experimental results
demonstrate that HEISIR outperforms fine-tuned models across various embedding
types and language models. Beyond improving retrieval capabilities, HEISIR also
offers opportunities for intent and topic analysis in conversational data,
providing a versatile solution for dialogue systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NAACL 2025 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Biological Sequence with Language Model <span class="highlight-title">Prompt</span>ing: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyue Jiang, Zikang Wang, Yuheng Shan, Heyan Chai, Jiayi Li, Zixian Ma, Xinrui Zhang, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language models (LLMs) have emerged as powerful tools for addressing
challenges across diverse domains. Notably, recent studies have demonstrated
that large language models significantly enhance the efficiency of biomolecular
analysis and synthesis, attracting widespread attention from academics and
medicine. In this paper, we systematically investigate the application of
prompt-based methods with LLMs to biological sequences, including DNA, RNA,
proteins, and drug discovery tasks. Specifically, we focus on how prompt
engineering enables LLMs to tackle domain-specific problems, such as promoter
sequence prediction, protein structure modeling, and drug-target binding
affinity prediction, often with limited labeled data. Furthermore, our
discussion highlights the transformative potential of prompting in
bioinformatics while addressing key challenges such as data scarcity,
multimodal fusion, and computational resource limitations. Our aim is for this
paper to function both as a foundational primer for newcomers and a catalyst
for continued innovation within this dynamic field of study.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncovering Gaps in How Humans and LLMs Interpret Subjective Language <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04113v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04113v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erik Jones, Arjun Patrawala, Jacob Steinhardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans often rely on subjective natural language to direct language models
(LLMs); for example, users might instruct the LLM to write an enthusiastic
blogpost, while developers might train models to be helpful and harmless using
LLM-based edits. The LLM's operational semantics of such subjective phrases --
how it adjusts its behavior when each phrase is included in the prompt -- thus
dictates how aligned it is with human intent. In this work, we uncover
instances of misalignment between LLMs' actual operational semantics and what
humans expect. Our method, TED (thesaurus error detector), first constructs a
thesaurus that captures whether two phrases have similar operational semantics
according to the LLM. It then elicits failures by unearthing disagreements
between this thesaurus and a human-constructed reference. TED routinely
produces surprising instances of misalignment; for example, Mistral 7B Instruct
produces more harassing outputs when it edits text to be witty, and Llama 3 8B
Instruct produces dishonest articles when instructed to make the articles
enthusiastic. Our results demonstrate that humans can uncover unexpected LLM
behavior by scrutinizing relationships between abstract concepts, without
supervising outputs directly.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMs Can Generate a Better Answer by Aggregating Their Own Responses 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04104v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04104v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zichong Li, Xinyu Feng, Yuheng Cai, Zixuan Zhang, Tianyi Liu, Chen Liang, Weizhu Chen, Haoyu Wang, Tuo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown remarkable capabilities across tasks,
yet they often require additional prompting techniques when facing complex
problems. While approaches like self-correction and response selection have
emerged as popular solutions, recent studies have shown these methods perform
poorly when relying on the LLM itself to provide feedback or selection
criteria. We argue this limitation stems from the fact that common LLM
post-training procedures lack explicit supervision for discriminative judgment
tasks. In this paper, we propose Generative Self-Aggregation (GSA), a novel
prompting method that improves answer quality without requiring the model's
discriminative capabilities. GSA first samples multiple diverse responses from
the LLM, then aggregates them to obtain an improved solution. Unlike previous
approaches, our method does not require the LLM to correct errors or compare
response quality; instead, it leverages the model's generative abilities to
synthesize a new response based on the context of multiple samples. While GSA
shares similarities with the self-consistency (SC) approach for response
aggregation, SC requires specific verifiable tokens to enable majority voting.
In contrast, our approach is more general and can be applied to open-ended
tasks. Empirical evaluation demonstrates that GSA effectively improves response
quality across various tasks, including mathematical reasoning, knowledge-based
problems, and open-ended generation tasks such as code synthesis and
conversational responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on
  African American English 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04099v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04099v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runtao Zhou, Guangya Wan, Saadia Gabriel, Sheng Li, Alexander J Gates, Maarten Sap, Thomas Hartvigsen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable capabilities in
reasoning tasks, leading to their widespread deployment. However, recent
studies have highlighted concerning biases in these models, particularly in
their handling of dialectal variations like African American English (AAE). In
this work, we systematically investigate dialectal disparities in LLM reasoning
tasks. We develop an experimental framework comparing LLM performance given
Standard American English (SAE) and AAE prompts, combining LLM-based dialect
conversion with established linguistic analyses. We find that LLMs consistently
produce less accurate responses and simpler reasoning chains and explanations
for AAE inputs compared to equivalent SAE questions, with disparities most
pronounced in social science and humanities domains. These findings highlight
systematic differences in how LLMs process and reason about different language
varieties, raising important questions about the development and deployment of
these systems in our multilingual and multidialectal world. Our code repository
is publicly available at https://github.com/Runtaozhou/dialect_bias_eval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ARR Under Review, First two authors contribute equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangnan Chen, Yuancheng Fang, Qian Xiao, Juncheng Li, Jun Lin, Siliang Tang, Yi Yang, Yueting Zhuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have garnered significant attention
for their strong visual-semantic understanding. Most existing chart benchmarks
evaluate MLLMs' ability to parse information from charts to answer
questions.However, they overlook the inherent output biases of MLLMs, where
models rely on their parametric memory to answer questions rather than
genuinely understanding the chart content. To address this limitation, we
introduce a novel Chart Hypothetical Question Answering (HQA) task, which
imposes assumptions on the same question to compel models to engage in
counterfactual reasoning based on the chart content. Furthermore, we introduce
HAI, a human-AI interactive data synthesis approach that leverages the
efficient text-editing capabilities of LLMs alongside human expert knowledge to
generate diverse and high-quality HQA data at a low cost. Using HAI, we
construct Chart-HQA, a challenging benchmark synthesized from publicly
available data sources. Evaluation results on 18 MLLMs of varying model sizes
reveal that current models face significant generalization challenges and
exhibit imbalanced reasoning performance on the HQA task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PP-DocBee: Improving Multimodal Document Understanding Through a Bag of
  Tricks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feng Ni, Kui Huang, Yao Lu, Wenyu Lv, Guanzhong Wang, Zeyu Chen, Yi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of digitalization, various document images are
being applied more extensively in production and daily life, and there is an
increasingly urgent need for fast and accurate parsing of the content in
document images. Therefore, this report presents PP-DocBee, a novel multimodal
large language model designed for end-to-end document image understanding.
First, we develop a data synthesis strategy tailored to document scenarios in
which we build a diverse dataset to improve the model generalization. Then, we
apply a few training techniques, including dynamic proportional sampling, data
preprocessing, and OCR postprocessing strategies. Extensive evaluations
demonstrate the superior performance of PP-DocBee, achieving state-of-the-art
results on English document understanding benchmarks and even outperforming
existing open source and commercial models in Chinese document understanding.
The source code and pre-trained models are publicly available at
\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncovering inequalities in new knowledge learning by large language
  models across different languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04064v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04064v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenglong Wang, Haoyu Tang, Xiyuan Yang, Yueqi Xie, Jina Suh, Sunayana Sitaram, Junming Huang, Yu Xie, Zhaoya Gong, Xing Xie, Fangzhao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) gradually become integral tools for problem
solving in daily life worldwide, understanding linguistic inequality is
becoming increasingly important. Existing research has primarily focused on
static analyses that assess the disparities in the existing knowledge and
capabilities of LLMs across languages. However, LLMs are continuously evolving,
acquiring new knowledge to generate up-to-date, domain-specific responses.
Investigating linguistic inequalities within this dynamic process is,
therefore, also essential. In this paper, we explore inequalities in new
knowledge learning by LLMs across different languages and four key dimensions:
effectiveness, transferability, prioritization, and robustness. Through
extensive experiments under two settings (in-context learning and fine-tuning)
using both proprietary and open-source models, we demonstrate that low-resource
languages consistently face disadvantages across all four dimensions. By
shedding light on these disparities, we aim to raise awareness of linguistic
inequalities in LLMs' new knowledge learning, fostering the development of more
inclusive and equitable future LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Data Watermarking in Language Models by Injecting Fictitious
  Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04036v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04036v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyue Cui, Johnny Tian-Zheng Wei, Swabha Swayamdipta, Robin Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data watermarking in language models injects traceable signals, such as
specific token sequences or stylistic patterns, into copyrighted text, allowing
copyright holders to track and verify training data ownership. Previous data
watermarking techniques primarily focus on effective memorization after
pretraining, while overlooking challenges that arise in other stages of the LLM
pipeline, such as the risk of watermark filtering during data preprocessing, or
potential forgetting through post-training, or verification difficulties due to
API-only access. We propose a novel data watermarking approach that injects
coherent and plausible yet fictitious knowledge into training data using
generated passages describing a fictitious entity and its associated
attributes. Our watermarks are designed to be memorized by the LLM through
seamlessly integrating in its training data, making them harder to detect
lexically during preprocessing.We demonstrate that our watermarks can be
effectively memorized by LLMs, and that increasing our watermarks' density,
length, and diversity of attributes strengthens their memorization. We further
show that our watermarks remain robust throughout LLM development, maintaining
their effectiveness after continual pretraining and supervised finetuning.
Finally, we show that our data watermarks can be evaluated even under API-only
access via question answering.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Large Language Models on Multiple Tasks in Bioinformatics
  NLP with <span class="highlight-title">Prompt</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyue Jiang, Pengan Chen, Jiuming Wang, Dongchen He, Ziqin Wei, Liang Hong, Licheng Zong, Sheng Wang, Qinze Yu, Zixian Ma, Yanyu Chen, Yimin Fan, Xiangyu Shi, Jiawei Sun, Chuan Wu, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become important tools in solving
biological problems, offering improvements in accuracy and adaptability over
conventional methods. Several benchmarks have been proposed to evaluate the
performance of these LLMs. However, current benchmarks can hardly evaluate the
performance of these models across diverse tasks effectively. In this paper, we
introduce a comprehensive prompting-based benchmarking framework, termed
Bio-benchmark, which includes 30 key bioinformatics tasks covering areas such
as proteins, RNA, drugs, electronic health records, and traditional Chinese
medicine. Using this benchmark, we evaluate six mainstream LLMs, including
GPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought
(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To
improve the efficiency of our evaluations, we demonstrate BioFinder, a new tool
for extracting answers from LLM responses, which increases extraction accuracy
by round 30% compared to existing methods. Our benchmark results show the
biological tasks suitable for current LLMs and identify specific areas
requiring enhancement. Furthermore, we propose targeted prompt engineering
strategies for optimizing LLM performance in these contexts. Based on these
findings, we provide recommendations for the development of more robust LLMs
tailored for various biological applications. This work offers a comprehensive
evaluation framework and robust tools to support the application of LLMs in
bioinformatics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retinal<span class="highlight-title">GPT</span>: A Retinal Clinical Preference Conversational Assistant
  Powered by Large Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03987v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03987v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhui Zhu, Xin Li, Xiwen Chen, Peijie Qiu, Vamsi Krishna Vasa, Xuanzhao Dong, Yanxi Chen, Natasha Lepore, Oana Dumitrascu, Yi Su, Yalin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Multimodal Large Language Models (MLLMs) have gained significant
attention for their remarkable ability to process and analyze non-textual data,
such as images, videos, and audio. Notably, several adaptations of
general-domain MLLMs to the medical field have been explored, including
LLaVA-Med. However, these medical adaptations remain insufficiently advanced in
understanding and interpreting retinal images. In contrast, medical experts
emphasize the importance of quantitative analyses for disease detection and
interpretation. This underscores a gap between general-domain and
medical-domain MLLMs: while general-domain MLLMs excel in broad applications,
they lack the specialized knowledge necessary for precise diagnostic and
interpretative tasks in the medical field. To address these challenges, we
introduce \textit{RetinalGPT}, a multimodal conversational assistant for
clinically preferred quantitative analysis of retinal images. Specifically, we
achieve this by compiling a large retinal image dataset, developing a novel
data pipeline, and employing customized visual instruction tuning to enhance
both retinal analysis and enrich medical knowledge. In particular, RetinalGPT
outperforms MLLM in the generic domain by a large margin in the diagnosis of
retinal diseases in 8 benchmark retinal datasets. Beyond disease diagnosis,
RetinalGPT features quantitative analyses and lesion localization, representing
a pioneering step in leveraging LLMs for an interpretable and end-to-end
clinical research framework. The code is available at
https://github.com/Retinal-Research/RetinalGPT
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding
  and Expert Reasoning Abilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03983v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03983v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sreyan Ghosh, Zhifeng Kong, Sonal Kumar, S Sakshi, Jaehyeon Kim, Wei Ping, Rafael Valle, Dinesh Manocha, Bryan Catanzaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and reasoning over non-speech sounds and music are crucial for
both humans and AI agents to interact effectively with their environments. In
this paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM)
with advanced audio understanding and reasoning capabilities. AF2 leverages (i)
a custom CLAP model, (ii) synthetic Audio QA data for fine-grained audio
reasoning, and (iii) a multi-stage curriculum learning strategy. AF2 achieves
state-of-the-art performance with only a 3B parameter small language model,
surpassing large open-source and proprietary models across over 20 benchmarks.
Next, for the first time, we extend audio understanding to long audio segments
(30 secs to 5 mins) and propose LongAudio, a large and novel dataset for
training ALMs on long audio captioning and question-answering tasks.
Fine-tuning AF2 on LongAudio leads to exceptional performance on our proposed
LongAudioBench, an expert annotated benchmark for evaluating ALMs on long audio
understanding capabilities. We conduct extensive ablation studies to confirm
the efficacy of our approach. Project Website:
https://research.nvidia.com/labs/adlr/AF2/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReasonGraph: Visualisation of Reasoning Paths 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03979v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03979v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongqian Li, Ehsan Shareghi, Nigel Collier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) reasoning processes are challenging to analyze
due to their complexity and the lack of organized visualization tools. We
present ReasonGraph, a web-based platform for visualizing and analyzing LLM
reasoning processes. It supports both sequential and tree-based reasoning
methods while integrating with major LLM providers and over fifty
state-of-the-art models. ReasonGraph incorporates an intuitive UI with meta
reasoning method selection, configurable visualization parameters, and a
modular framework that facilitates efficient extension. Our evaluation shows
high parsing reliability, efficient processing, and strong usability across
various downstream applications. By providing a unified visualization
framework, ReasonGraph reduces cognitive load in analyzing complex reasoning
paths, improves error detection in logical processes, and enables more
effective development of LLM-based applications. The platform is open-source,
promoting accessibility and reproducibility in LLM reasoning analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming
  Ability in Multi-Agent Environments <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11807v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11807v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael R. Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decision-making is a complex process requiring diverse abilities, making it
an excellent framework for evaluating Large Language Models (LLMs). Researchers
have examined LLMs' decision-making through the lens of Game Theory. However,
existing evaluation mainly focus on two-player scenarios where an LLM competes
against another. Additionally, previous benchmarks suffer from test set leakage
due to their static design. We introduce GAMA($\gamma$)-Bench, a new framework
for evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes
eight classical game theory scenarios and a dynamic scoring scheme specially
designed to quantitatively assess LLMs' performance. $\gamma$-Bench allows
flexible game settings and adapts the scoring system to different game
parameters, enabling comprehensive evaluation of robustness, generalizability,
and strategies for improvement. Our results indicate that GPT-3.5 demonstrates
strong robustness but limited generalizability, which can be enhanced using
methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families,
including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2.
Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by
LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental
results are publicly available at https://github.com/CUHK-ARISE/GAMABench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;
  Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,
  Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,
  Qwen-2-72B</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HELMET: How to Evaluate Long-Context Language Models Effectively and
  Thoroughly <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02694v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02694v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Howard Yen, Tianyu Gao, Minmin Hou, Ke Ding, Daniel Fleischer, Peter Izsak, Moshe Wasserblat, Danqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many benchmarks exist for evaluating long-context language models (LCLMs),
yet developers often rely on synthetic tasks such as needle-in-a-haystack
(NIAH) or an arbitrary subset of tasks. However, it remains unclear whether
these benchmarks reflect the diverse downstream applications of LCLMs, and such
inconsistencies further complicate model comparison. We investigate the
underlying reasons behind these practices and find that existing benchmarks
often provide noisy signals due to limited coverage of applications,
insufficient context lengths, unreliable metrics, and incompatibility with base
models. In this work, we introduce HELMET (How to Evaluate Long-context Models
Effectively and Thoroughly), a comprehensive benchmark encompassing seven
diverse, application-centric categories. We also address several issues in
previous benchmarks by adding controllable lengths up to 128K tokens,
model-based evaluation for reliable metrics, and few-shot prompting for
robustly evaluating base models. Consequently, we demonstrate that HELMET
offers more reliable and consistent rankings of frontier LCLMs. Through a
comprehensive study of 59 LCLMs, we find that (1) synthetic tasks like NIAH do
not reliably predict downstream performance; (2) the diverse categories in
HELMET exhibit distinct trends and low correlations with each other; and (3)
while most LCLMs achieve perfect NIAH scores, open-source models significantly
lag behind closed ones when tasks require full-context reasoning or following
complex instructions -- the gap widens as length increases. Finally, we
recommend using our RAG tasks for fast model development, as they are easy to
run and better predict other downstream performance; ultimately, we advocate
for a holistic evaluation across diverse tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025. Project page: https://princeton-nlp.github.io/HELMET/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AdaptBot: Combining LLM with Knowledge Graphs and Human Input for
  Generic-to-Specific Task Decomposition and Knowledge Refinement <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02067v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02067v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An embodied agent assisting humans is often asked to complete new tasks, and
there may not be sufficient time or labeled examples to train the agent to
perform these new tasks. Large Language Models (LLMs) trained on considerable
knowledge across many domains can be used to predict a sequence of abstract
actions for completing such tasks, although the agent may not be able to
execute this sequence due to task-, agent-, or domain-specific constraints. Our
framework addresses these challenges by leveraging the generic predictions
provided by LLM and the prior domain knowledge encoded in a Knowledge Graph
(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits
and uses human input as needed to refine its existing knowledge. Based on
experimental evaluation in the context of cooking and cleaning tasks in
simulation domains, we demonstrate that the interplay between LLM, KG, and
human input leads to substantial performance gains compared with just using the
LLM. Project website{\S}: https://sssshivvvv.github.io/adaptbot/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE International Conference on Robotics and Automation
  (ICRA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics
  and Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16600v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16600v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangliang Liu, Lei Jiang, Xitong Zhang, Kristen Marie Johnson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring that Large Language Models (LLMs) return just responses which adhere
to societal values is crucial for their broader application. Prior research has
shown that LLMs often fail to perform satisfactorily on tasks requiring moral
cognizance, such as ethics-based judgments. While current approaches have
focused on fine-tuning LLMs with curated datasets to improve their capabilities
on such tasks, choosing the optimal learning paradigm to enhance the ethical
responses of LLMs remains an open research debate. In this work, we aim to
address this fundamental question: can current learning paradigms enable LLMs
to acquire sufficient moral reasoning capabilities? Drawing from distributional
semantics theory and the pragmatic nature of moral discourse, our analysis
indicates that performance improvements follow a mechanism similar to that of
semantic-level tasks, and therefore remain affected by the pragmatic nature of
morals latent in discourse, a phenomenon we name the pragmatic dilemma. We
conclude that this pragmatic dilemma imposes significant limitations on the
generalization ability of current learning paradigms, making it the primary
bottleneck for moral reasoning acquisition in LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Get my drift? Catching LLM Task Drift with Activation Deltas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00799v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00799v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sahar Abdelnabi, Aideen Fay, Giovanni Cherubin, Ahmed Salem, Mario Fritz, Andrew Paverd
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs are commonly used in retrieval-augmented applications to execute user
instructions based on data from external sources. For example, modern search
engines use LLMs to answer queries based on relevant search results; email
plugins summarize emails by processing their content through an LLM. However,
the potentially untrusted provenance of these data sources can lead to prompt
injection attacks, where the LLM is manipulated by natural language
instructions embedded in the external data, causing it to deviate from the
user's original instruction(s). We define this deviation as task drift. Task
drift is a significant concern as it allows attackers to exfiltrate data or
influence the LLM's output for other users. We study LLM activations as a
solution to detect task drift, showing that activation deltas - the difference
in activations before and after processing external data - are strongly
correlated with this phenomenon. Through two probing methods, we demonstrate
that a simple linear classifier can detect drift with near-perfect ROC AUC on
an out-of-distribution test set. We evaluate these methods by making minimal
assumptions about how users' tasks, system prompts, and attacks can be phrased.
We observe that this approach generalizes surprisingly well to unseen task
domains, such as prompt injections, jailbreaks, and malicious instructions,
without being trained on any of these attacks. Interestingly, the fact that
this solution does not require any modifications to the LLM (e.g.,
fine-tuning), as well as its compatibility with existing meta-prompting
solutions, makes it cost-efficient and easy to deploy. To encourage further
research on activation-based task inspection, decoding, and interpretability,
we release our large-scale TaskTracker toolkit, featuring a dataset of over
500K instances, representations from six SoTA language models, and a suite of
inspection tools.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SaTML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.00053v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.00053v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Estornell, Jean-Francois Ton, Yuanshun Yao, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated a remarkable ability to serve
as general-purpose tools for various language-based tasks. Recent works have
demonstrated that the efficacy of such models can be improved through iterative
dialog between multiple models. While these paradigms show promise in improving
model efficacy, most works in this area treat collaboration as an emergent
behavior, rather than a learned behavior. In doing so, current multi-agent
frameworks rely on collaborative behaviors to have been sufficiently trained
into off-the-shelf models. To address this limitation, we propose ACC-Collab,
an Actor-Critic based learning framework to produce a two-agent team (an
actor-agent and a critic-agent) specialized in collaboration. We demonstrate
that ACC-Collab outperforms SotA multi-agent techniques on a wide array of
benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic
  Templatisation and Orthographic Obfuscation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02972v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02972v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jude Khouja, Karolina Korgul, Simi Hellsten, Lingyi Yang, Vlad Neacs, Harry Mayne, Ryan Kearns, Andrew Bean, Adam Mahdi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Assessing the reasoning capabilities of large language models (LLMs) is
susceptible to overestimation due to data exposure of evaluation benchmarks. We
introduce a framework for producing linguistic reasoning problems that reduces
the effect of memorisation in model performance estimates and apply this
framework to develop LINGOLY-TOO, a challenging benchmark for linguistic
reasoning. By developing orthographic templates, we dynamically obfuscate the
writing systems of real languages to generate numerousquestion variations.
These variations preserve the reasoning steps required for each solution while
reducing the likelihood of specific problem instances appearing in model
training data. Our experiments demonstrate that frontier models, including
Claud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning.
Our analysis also shows that LLMs exhibit noticeable variance in accuracy
across permutations of the same problem, and on average perform better on
questions appearing in their original orthography. Our findings highlight the
opaque nature of response generation in LLMs and provide evidence that prior
data exposure contributes to over estimating the reasoning capabilities of
frontier models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Protein Large Language Models: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17504v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17504v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijia Xiao, Wanjia Zhao, Junkai Zhang, Yiqiao Jin, Han Zhang, Zhicheng Ren, Renliang Sun, Haixin Wang, Guancheng Wan, Pan Lu, Xiao Luo, Yu Zhang, James Zou, Yizhou Sun, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protein-specific large language models (Protein LLMs) are revolutionizing
protein science by enabling more efficient protein structure prediction,
function annotation, and design. While existing surveys focus on specific
aspects or applications, this work provides the first comprehensive overview of
Protein LLMs, covering their architectures, training datasets, evaluation
metrics, and diverse applications. Through a systematic analysis of over 100
articles, we propose a structured taxonomy of state-of-the-art Protein LLMs,
analyze how they leverage large-scale protein sequence data for improved
accuracy, and explore their potential in advancing protein engineering and
biomedical research. Additionally, we discuss key challenges and future
directions, positioning Protein LLMs as essential tools for scientific
discovery in protein science. Resources are maintained at
https://github.com/Yijia-Xiao/Protein-LLM-Survey.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 4 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NormAd: A Framework for Measuring the Cultural Adaptability of Large
  Language Models <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12464v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12464v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, Maarten Sap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To be effectively and safely deployed to global user populations, large
language models (LLMs) may need to adapt outputs to user values and cultures,
not just know about them. We introduce NormAd, an evaluation framework to
assess LLMs' cultural adaptability, specifically measuring their ability to
judge social acceptability across varying levels of cultural norm specificity,
from abstract values to explicit social norms. As an instantiation of our
framework, we create NormAd-Eti, a benchmark of 2.6k situational descriptions
representing social-etiquette related cultural norms from 75 countries. Through
comprehensive experiments on NormAd-Eti, we find that LLMs struggle to
accurately judge social acceptability across these varying degrees of cultural
contexts and show stronger adaptability to English-centric cultures over those
from the Global South. Even in the simplest setting where the relevant social
norms are provided, the best LLMs' performance (< 82\%) lags behind humans (>
95\%). In settings with abstract values and country information, model
performance drops substantially (< 60\%), while human accuracy remains high (>
90\%). Furthermore, we find that models are better at recognizing socially
acceptable versus unacceptable situations. Our findings showcase the current
pitfalls in socio-cultural reasoning of LLMs which hinder their adaptability
for global audiences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $\texttt{SEM-CTRL}$: Semantically Controlled Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Albinhassan, Pranava Madhyastha, Alessandra Russo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring both syntactic and semantic correctness in Large Language Model
(LLM) outputs remains a significant challenge, despite being critical for
real-world deployment. In this paper, we introduce $\texttt{SEM-CTRL}$, a
unified approach that enforces rich context-sensitive constraints and task- and
instance-specific semantics directly on an LLM decoder. Our approach integrates
token-level MCTS, which is guided by specific syntactic and semantic
constraints. The constraints over the desired outputs are expressed using
Answer Set Grammars -- a logic-based formalism that generalizes
context-sensitive grammars while incorporating background knowledge to
represent task-specific semantics. We show that our approach guarantees correct
completions for any off-the-shelf LLM without the need for fine-tuning. We
evaluate $\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar
synthesis, combinatorial reasoning, and planning. Our results demonstrate that
$\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform
larger variants and state-of-the-art reasoning models (e.g., o1-preview) while
simultaneously guaranteeing solution correctness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with
  Gaussian Distribution <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00153v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00153v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Probing learned concepts in large language models (LLMs) is crucial for
understanding how semantic knowledge is encoded internally. Training linear
classifiers on probing tasks is a principle approach to denote the vector of a
certain concept in the representation space. However, the single vector
identified for a concept varies with both data and training, making it less
robust and weakening its effectiveness in real-world applications. To address
this challenge, we propose an approach to approximate the subspace representing
a specific concept. Built on linear probing classifiers, we extend the concept
vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's
effectiveness through measuring its faithfulness and plausibility across
multiple LLMs with different sizes and architectures. Additionally, we use
representation intervention tasks to showcase its efficacy in real-world
applications such as emotion steering. Experimental results indicate that GCS
concept vectors have the potential to balance steering performance and
maintaining the fluency in natural language generation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from
  Multi-Turn Jailbreaks without Compromising Usability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09990v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09990v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the rapid development of safety alignment techniques for LLMs,
defending against multi-turn jailbreaks is still a challenging task. In this
paper, we conduct a comprehensive comparison, revealing that some existing
defense methods can improve the robustness of LLMs against multi-turn
jailbreaks but compromise usability, i.e., reducing general capabilities or
causing the over-refusal problem. From the perspective of mechanism
interpretability of LLMs, we discover that these methods fail to establish a
boundary that exactly distinguishes safe and harmful feature representations.
Therefore, boundary-safe representations close to harmful representations are
inevitably disrupted, leading to a decline in usability. To address this issue,
we propose X-Boundary to push harmful representations away from boundary-safe
representations and obtain an exact distinction boundary. In this way, harmful
representations can be precisely erased without disrupting safe ones.
Experimental results show that X-Boundary achieves state-of-the-art defense
performance against multi-turn jailbreaks, while reducing the over-refusal rate
by about 20% and maintaining nearly complete general capability. Furthermore,
we theoretically prove and empirically verify that X-Boundary can accelerate
the convergence process during training. Please see our code at:
https://github.com/AI45Lab/X-Boundary.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models
  for Multilingual Multimodal Idiomaticity Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20984v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20984v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thanet Markchom, Tong Wu, Liting Huang, Huizhi Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SemEval-2025 Task 1 focuses on ranking images based on their alignment with a
given nominal compound that may carry idiomatic meaning in both English and
Brazilian Portuguese. To address this challenge, this work uses generative
large language models (LLMs) and multilingual CLIP models to enhance idiomatic
compound representations. LLMs generate idiomatic meanings for potentially
idiomatic compounds, enriching their semantic interpretation. These meanings
are then encoded using multilingual CLIP models, serving as representations for
image ranking. Contrastive learning and data augmentation techniques are
applied to fine-tune these embeddings for improved performance. Experimental
results show that multimodal representations extracted through this method
outperformed those based solely on the original nominal compounds. The
fine-tuning approach shows promising outcomes but is less effective than using
embeddings without fine-tuning. The source code used in this paper is available
at https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gumbel Counterfactual Generation From Language Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.07180v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.07180v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shauli Ravfogel, Anej Svete, Vésteinn Snæbjarnarson, Ryan Cotterell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and manipulating the causal generation mechanisms in language
models is essential for controlling their behavior. Previous work has primarily
relied on techniques such as representation surgery -- e.g., model ablations or
manipulation of linear subspaces tied to specific concepts -- to
\emph{intervene} on these models. To understand the impact of interventions
precisely, it is useful to examine \emph{counterfactuals} -- e.g., how a given
sentence would have appeared had it been generated by the model following a
specific intervention. We highlight that counterfactual reasoning is
conceptually distinct from interventions, as articulated in Pearl's causal
hierarchy. Based on this observation, we propose a framework for generating
true string counterfactuals by reformulating language models as a structural
equation model using the Gumbel-max trick, which we called Gumbel
counterfactual generation. This reformulation allows us to model the joint
distribution over original strings and their counterfactuals resulting from the
same instantiation of the sampling noise. We develop an algorithm based on
hindsight Gumbel sampling that allows us to infer the latent noise variables
and generate counterfactuals of observed strings. Our experiments demonstrate
that the approach produces meaningful counterfactuals while at the same time
showing that commonly used intervention techniques have considerable undesired
side effects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Procedural Knowledge in <span class="highlight-title">Pretrain</span>ing Drives Reasoning in Large Language
  Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12580v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12580v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The capabilities and limitations of Large Language Models have been sketched
out in great detail in recent years, providing an intriguing yet conflicting
picture. On the one hand, LLMs demonstrate a general ability to solve problems.
On the other hand, they show surprising reasoning gaps when compared to humans,
casting doubt on the robustness of their generalisation strategies. The sheer
volume of data used in the design of LLMs has precluded us from applying the
method traditionally used to measure generalisation: train-test set separation.
To overcome this, we study what kind of generalisation strategies LLMs employ
when performing reasoning tasks by investigating the pretraining data they rely
on. For two models of different sizes (7B and 35B) and 2.5B of their
pretraining tokens, we identify what documents influence the model outputs for
three simple mathematical reasoning tasks and contrast this to the data that
are influential for answering factual questions. We find that, while the models
rely on mostly distinct sets of data for each factual question, a document
often has a similar influence across different reasoning questions within the
same task, indicating the presence of procedural knowledge. We further find
that the answers to factual questions often show up in the most influential
data. However, for reasoning questions the answers usually do not show up as
highly influential, nor do the answers to the intermediate reasoning steps.
When we characterise the top ranked documents for the reasoning questions
qualitatively, we confirm that the influential documents often contain
procedural knowledge, like demonstrating how to obtain a solution using
formulae or code. Our findings indicate that the approach to reasoning the
models use is unlike retrieval, and more like a generalisable strategy that
synthesises procedural knowledge from documents doing a similar form of
reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Approaching the Limits to EFL Writing Enhancement with AI-generated Text
  and Diverse Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00367v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00367v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David James Woo, Hengky Susanto, Chi Ho Yeung, Kai Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative artificial intelligence (AI) chatbots, such as ChatGPT, are
reshaping how English as a foreign language (EFL) students write since students
can compose texts by integrating their own words with AI-generated text. This
study investigated how 59 Hong Kong secondary school students with varying
levels of academic achievement interacted with AI-generated text to compose a
feature article, exploring whether any interaction patterns benefited the
overall quality of the article. Through content analysis, multiple linear
regression and cluster analysis, we found the overall number of words --
whether AI- or human-generated -- is the main predictor of writing quality.
However, the impact varies by students' competence to write independently, for
instance, by using their own words accurately and coherently to compose a text,
and to follow specific interaction patterns with AI-generated text. Therefore,
although composing texts with human words and AI-generated text may become
prevalent in EFL writing classrooms, without educators' careful attention to
EFL writing pedagogy and AI literacy, high-achieving students stand to benefit
more from using AI-generated text than low-achieving students.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assisting Mathematical Formalization with A Learning-based Premise
  Retriever 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.13959v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.13959v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yicheng Tao, Haotian Liu, Shanwen Wang, Hongteng Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Premise selection is a crucial yet challenging step in mathematical
formalization, especially for users with limited experience. Due to the lack of
available formalization projects, existing approaches that leverage language
models often suffer from data scarcity. In this work, we introduce an
innovative method for training a premise retriever to support the formalization
of mathematics. Our approach employs a BERT model to embed proof states and
premises into a shared latent space. The retrieval model is trained within a
contrastive learning framework and incorporates a domain-specific tokenizer
along with a fine-grained similarity computation method. Experimental results
show that our model is highly competitive compared to existing baselines,
achieving strong performance while requiring fewer computational resources.
Performance is further enhanced through the integration of a re-ranking module.
To streamline the formalization process, we will release a search engine that
enables users to query Mathlib theorems directly using proof states,
significantly improving accessibility and efficiency. Codes are available at
https://github.com/ruc-ai4math/Premise-Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AfroBench: How Good are Large Language Models on African Languages? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07978v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07978v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo, Kelechi Ogueji, Jimmy Lin, Pontus Stenetorp, David Ifeoluwa Adelani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large-scale multilingual evaluations, such as MEGA, often include only a
handful of African languages due to the scarcity of high-quality evaluation
data and the limited discoverability of existing African datasets. This lack of
representation hinders comprehensive LLM evaluation across a diverse range of
languages and tasks. To address these challenges, we introduce AfroBench -- a
multi-task benchmark for evaluating the performance of LLMs across 64 African
languages, 15 tasks and 22 datasets. AfroBench consists of nine natural
language understanding datasets, six text generation datasets, six knowledge
and question answering tasks, and one mathematical reasoning task. We present
results comparing the performance of prompting LLMs to fine-tuned baselines
based on BERT and T5-style models. Our results suggest large gaps in
performance between high-resource languages, such as English, and African
languages across most tasks; but performance also varies based on the
availability of monolingual data resources. Our findings confirm that
performance on African languages continues to remain a hurdle for current LLMs,
underscoring the need for additional efforts to close this gap.
  https://mcgill-nlp.github.io/AfroBench/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for
  Superintelligent AI <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12753v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12753v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Huang, Zengzhi Wang, Shijie Xia, Xuefeng Li, Haoyang Zou, Ruijie Xu, Run-Ze Fan, Lyumanshan Ye, Ethan Chern, Yixin Ye, Yikai Zhang, Yuqing Yang, Ting Wu, Binjie Wang, Shichao Sun, Yang Xiao, Yiyuan Li, Fan Zhou, Steffi Chern, Yiwei Qin, Yan Ma, Jiadi Su, Yixiu Liu, Yuxiang Zheng, Shaoting Zhang, Dahua Lin, Yu Qiao, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The evolution of Artificial Intelligence (AI) has been significantly
accelerated by advancements in Large Language Models (LLMs) and Large
Multimodal Models (LMMs), gradually showcasing potential cognitive reasoning
abilities in problem-solving and scientific discovery (i.e., AI4Science) once
exclusive to human intellect. To comprehensively evaluate current models'
performance in cognitive reasoning abilities, we introduce OlympicArena, which
includes 11,163 bilingual problems across both text-only and interleaved
text-image modalities. These challenges encompass a wide range of disciplines
spanning seven fields and 62 international Olympic competitions, rigorously
examined for data leakage. We argue that the challenges in Olympic competition
problems are ideal for evaluating AI's cognitive reasoning due to their
complexity and interdisciplinary nature, which are essential for tackling
complex scientific challenges and facilitating discoveries. Beyond evaluating
performance across various disciplines using answer-only criteria, we conduct
detailed experiments and analyses from multiple perspectives. We delve into the
models' cognitive reasoning abilities, their performance across different
modalities, and their outcomes in process-level evaluations, which are vital
for tasks requiring complex reasoning with lengthy solutions. Our extensive
evaluations reveal that even advanced models like GPT-4o only achieve a 39.97%
overall accuracy, illustrating current AI limitations in complex reasoning and
multimodal integration. Through the OlympicArena, we aim to advance AI towards
superintelligence, equipping it to address more complex challenges in science
and beyond. We also provide a comprehensive set of resources to support AI
research, including a benchmark dataset, an open-source annotation platform, a
detailed evaluation tool, and a leaderboard with automatic submission features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 360$^\circ$REA: Towards A Reusable Experience Accumulation with
  360° Assessment for Multi-Agent System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.05569v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.05569v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shen Gao, Hao Li, Chengrui Huang, Quan Tu, Zhiliang Tian, Minlie Huang, Shuo Shang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model agents have demonstrated remarkable advancements across
various complex tasks. Recent works focus on optimizing the agent team or
employing self-reflection to iteratively solve complex tasks. Since these
agents are all based on the same LLM, only conducting self-evaluation or
removing underperforming agents does not substantively enhance the capability
of the agents. We argue that a comprehensive evaluation and accumulating
experience from evaluation feedback is an effective approach to improving
system performance. In this paper, we propose Reusable Experience Accumulation
with 360$^\circ$ Assessment (360$^\circ$REA), a hierarchical multi-agent
framework inspired by corporate organizational practices. The framework employs
a novel 360$^\circ$ performance assessment method for multi-perspective
performance evaluation with fine-grained assessment. To enhance the capability
of agents in addressing complex tasks, we introduce dual-level experience pool
for agents to accumulate experience through fine-grained assessment. Extensive
experiments on complex task datasets demonstrate the effectiveness of
360$^\circ$REA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Structured Preference Optimization for Vision-Language Long-Horizon Task
  Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20742v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20742v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiwen Liang, Min Lin, Weiqi Ruan, Rongtao Xu, Yuecheng Liu, Jiaqi Chen, Bingqian Lin, Yuzheng Zhuang, Xiaodan Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods for vision-language task planning excel in short-horizon
tasks but often fall short in complex, long-horizon planning within dynamic
environments. These challenges primarily arise from the difficulty of
effectively training models to produce high-quality reasoning processes for
long-horizon tasks. To address this, we propose Structured Preference
Optimization (SPO), which aims to enhance reasoning and action selection in
long-horizon task planning through structured preference evaluation and
optimized training strategies. Specifically, SPO introduces: 1)
Preference-Based Scoring and Optimization, which systematically evaluates
reasoning chains based on task relevance, visual grounding, and historical
consistency; and 2) Curriculum-Guided Training, where the model progressively
adapts from simple to complex tasks, improving its generalization ability in
long-horizon scenarios and enhancing reasoning robustness. To advance research
in vision-language long-horizon task planning, we introduce ExtendaBench, a
comprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat
2.0, categorized into ultra-short, short, medium, and long tasks. Experimental
results demonstrate that SPO significantly improves reasoning quality and final
decision accuracy, outperforming prior methods on long-horizon tasks and
underscoring the effectiveness of preference-driven optimization in
vision-language task planning. Specifically, SPO achieves a +5.98% GCR and
+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement
in Habitat over the best-performing baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stealthy Jailbreak Attacks on Large Language Models via Benign Data
  Mirroring <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21083v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21083v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Honglin Mu, Han He, Yuxin Zhou, Yunlong Feng, Yang Xu, Libo Qin, Xiaoming Shi, Zeming Liu, Xudong Han, Qi Shi, Qingfu Zhu, Wanxiang Che
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model (LLM) safety is a critical issue, with numerous studies
employing red team testing to enhance model security. Among these, jailbreak
methods explore potential vulnerabilities by crafting malicious prompts that
induce model outputs contrary to safety alignments. Existing black-box
jailbreak methods often rely on model feedback, repeatedly submitting queries
with detectable malicious instructions during the attack search process.
Although these approaches are effective, the attacks may be intercepted by
content moderators during the search process. We propose an improved transfer
attack method that guides malicious prompt construction by locally training a
mirror model of the target black-box model through benign data distillation.
This method offers enhanced stealth, as it does not involve submitting
identifiable malicious instructions to the target model during the search
phase. Our approach achieved a maximum attack success rate of 92%, or a
balanced value of 80% with an average of 1.5 detectable jailbreak queries per
sample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore
the need for more robust defense mechanisms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SRAG: Structured Retrieval-Augmented Generation for Multi-Entity
  Question Answering over Wikipedia Graph 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teng Lin, Yizhang Zhu, Yuyu Luo, Nan Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-entity question answering (MEQA) poses significant challenges for large
language models (LLMs), which often struggle to consolidate scattered
information across multiple documents. An example question might be "What is
the distribution of IEEE Fellows among various fields of study?", which
requires retrieving information from diverse sources e.g., Wikipedia pages. The
effectiveness of current retrieval-augmented generation (RAG) methods is
limited by the LLMs' capacity to aggregate insights from numerous pages. To
address this gap, this paper introduces a structured RAG (SRAG) framework that
systematically organizes extracted entities into relational tables (e.g.,
tabulating entities with schema columns like "name" and "field of study") and
then apply table-based reasoning techniques. Our approach decouples retrieval
and reasoning, enabling LLMs to focus on structured data analysis rather than
raw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA
tasks demonstrate that SRAG significantly outperforms state-of-the-art
long-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.
The results underscore the efficacy of structuring unstructured data to enhance
LLMs' reasoning capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HelpSteer2-Preference: Complementing Ratings with Preferences <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01257v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01257v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhilin Wang, Alexander Bukharin, Olivier Delalleau, Daniel Egert, Gerald Shen, Jiaqi Zeng, Oleksii Kuchaiev, Yi Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward models are critical for aligning models to follow instructions, and
are typically trained following one of two popular paradigms: Bradley-Terry
style or Regression style. However, there is a lack of evidence that either
approach is better than the other, when adequately matched for data. This is
primarily because these approaches require data collected in different (but
incompatible) formats, meaning that adequately matched data is not available in
existing public datasets. To tackle this problem, we release preference
annotations (designed for Bradley-Terry training) to complement existing
ratings (designed for Regression style training) in the HelpSteer2 dataset. To
improve data interpretability, preference annotations are accompanied with
human-written justifications. Using this data, we conduct the first
head-to-head comparison of Bradley-Terry and Regression models when adequately
matched for data. Based on insights derived from such a comparison, we propose
a novel approach to combine Bradley-Terry and Regression reward modeling. A
Llama-3.1-70B-Instruct model tuned with this approach scores 94.1 on
RewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This
reward model can then be used with REINFORCE algorithm (RLHF) to align an
Instruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We
open-source this dataset (CC-BY-4.0 license) at
https://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024
and openly release the trained Reward and Instruct models at
https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and
https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025; 28 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Women, Infamous, and Exotic Beings: What Honorific Usages in Wikipedia
  Reveal about the Socio-Cultural Norms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.03479v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.03479v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sourabrata Mukherjee, Soumya Teotia, Sougata Saha, Monojit Choudhury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Honorifics serve as powerful linguistic markers that reflect social
hierarchies and cultural values. This paper presents a large-scale,
cross-linguistic exploration of usage of honorific pronouns in Bengali and
Hindi Wikipedia articles, shedding light on how socio-cultural factors shape
language. Using LLM (GPT-4o), we annotated 10, 000 articles of real and
fictional beings in each language for several sociodemographic features such as
gender, age, fame, and exoticness, and the use of honorifics. We find that
across all feature combinations, use of honorifics is consistently more common
in Bengali than Hindi. For both languages, the use non-honorific pronouns is
more commonly observed for infamous, juvenile, and exotic beings. Notably, we
observe a gender bias in use of honorifics in Hindi, with men being more
commonly referred to with honorifics than women.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Weak-to-Strong Preference Optimization: Stealing Reward from Weak
  Aligned Model <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.18640v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.18640v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhong Zhu, Zhiwei He, Xiaofeng Wang, Pengfei Liu, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aligning language models (LMs) with human preferences has become a key area
of research, enabling these models to meet diverse user needs better. Inspired
by weak-to-strong generalization, where a strong LM fine-tuned on labels
generated by a weaker model can consistently outperform its weak supervisor, we
extend this idea to model alignment. In this work, we observe that the
alignment behavior in weaker models can be effectively transferred to stronger
models and even exhibit an amplification effect. Based on this insight, we
propose a method called Weak-to-Strong Preference Optimization (WSPO), which
achieves strong model alignment by learning the distribution differences before
and after the alignment of the weak model. Experiments demonstrate that WSPO
delivers outstanding performance, improving the win rate of Qwen2-7B-Instruct
on Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04
length-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our
results suggest that using the weak model to elicit a strong model with a high
alignment ability is feasible.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025(Spotlight)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Social Genome: Grounded Social Reasoning Abilities of Multimodal Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15109v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15109v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leena Mathur, Marian Qian, Paul Pu Liang, Louis-Philippe Morency
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social reasoning abilities are crucial for AI systems to effectively
interpret and respond to multimodal human communication and interaction within
social contexts. We introduce Social Genome, the first benchmark for
fine-grained, grounded social reasoning abilities of multimodal models. Social
Genome contains 272 videos of interactions and 1,486 human-annotated reasoning
traces related to inferences about these interactions. These traces contain
5,777 reasoning steps that reference evidence from visual cues, verbal cues,
vocal cues, and external knowledge (contextual knowledge external to videos).
Social Genome is also the first modeling challenge to study external knowledge
in social reasoning. Social Genome computes metrics to holistically evaluate
semantic and structural qualities of model-generated social reasoning traces.
We demonstrate the utility of Social Genome through experiments with
state-of-the-art models, identifying performance gaps and opportunities for
future research to improve the grounded social reasoning abilities of
multimodal models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review, 22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding
  Models Against Misinformation Edits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03417v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03417v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jabez Magomere, Emanuele La Malfa, Manuel Tonneau, Ashkan Kazemi, Scott Hale
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online misinformation remains a critical challenge, and fact-checkers
increasingly rely on embedding-based methods to retrieve relevant fact-checks.
Yet, when debunked claims reappear in edited forms, the performance of these
methods is unclear. In this work, we introduce a taxonomy of six common
real-world misinformation edits and propose a perturbation framework that
generates valid, natural claim variations. Our multi-stage retrieval evaluation
reveals that standard embedding models struggle with user-introduced edits,
while LLM-distilled embeddings offer improved robustness at a higher
computational cost. Although a strong reranker helps mitigate some issues, it
cannot fully compensate for first-stage retrieval gaps. Addressing these
retrieval gaps, our train- and inference-time mitigation approaches enhance
in-domain robustness by up to 17 percentage points and boost out-of-domain
generalization by 10 percentage points over baseline models. Overall, our
findings provide practical improvements to claim-matching systems, enabling
more reliable fact-checking of evolving misinformation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semi-Parametric Retrieval via Binary Bag-of-Tokens Index 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawei Zhou, Li Dong, Furu Wei, Lei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval has transitioned from standalone systems into essential
components across broader applications, with indexing efficiency,
cost-effectiveness, and freshness becoming increasingly critical yet often
overlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval
(SiDR), a bi-encoder retrieval framework that decouples retrieval index from
neural parameters to enable efficient, low-cost, and parameter-agnostic
indexing for emerging use cases. Specifically, in addition to using embeddings
as indexes like existing neural retrieval methods, SiDR supports a
non-parametric tokenization index for search, achieving BM25-like indexing
complexity with significantly better effectiveness. Our comprehensive
evaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms
both neural and term-based retrieval baselines under the same indexing
workload: (i) When using an embedding-based index, SiDR exceeds the performance
of conventional neural retrievers while maintaining similar training
complexity; (ii) When using a tokenization-based index, SiDR drastically
reduces indexing cost and time, matching the complexity of traditional
term-based retrieval, while consistently outperforming BM25 on all in-domain
datasets; (iii) Additionally, we introduce a late parametric mechanism that
matches BM25 index preparation time while outperforming other neural retrieval
baselines in effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explaining Caption-Image Interactions in CLIP models with Second-Order
  Attributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14153v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14153v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Möller, Pascal Tilli, Ngoc Thang Vu, Sebastian Padó
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dual encoder architectures like CLIP models map two types of inputs into a
shared embedding space and predict similarities between them. Despite their
success, it is, however, not understood how these models compare their two
inputs. Common first-order feature-attribution methods can only provide limited
insights into dual-encoders since their predictions depend on
feature-interactions rather than on individual features. In this paper, we
first derive a second-order method enabling the attribution of predictions by
any differentiable dual encoder onto feature-interactions between its inputs.
Second, we apply our method to CLIP models and show that they learn
fine-grained correspondences between parts of captions and regions in images.
They match objects across input modes also account for mismatches. This
visual-linguistic grounding ability, however, varies heavily between object
classes and exhibits pronounced out-of-domain effects. We can identify
individual errors as well as systematic failure categories including object
coverage, unusual scenes and correlated contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Union of Experts: Adapting Hierarchical Routing to Equivalently
  Decomposed <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02495v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02495v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujiao Yang, Jing Lian, Linhui Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose Union-of-Experts (UoE), which decomposes transformer into an
equitant group of experts, and then implement selective routing on input data
and experts. Our approach advances MoE design with four key innovations: (1) We
conducted equitant expert decomposition on both MLP blocks and attention blocks
based on matrix partition in tensor parallelism. (2) We developed two routing
paradigms: patch-wise data selection and expert selection, to apply routing
across different levels. (3) We design the architecture of UoE model, including
Selective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We
develop parallel implementation of UoE's routing and computation operation, and
optimize efficiency based on the hardware processing analysis. The experiments
demonstrate that the UoE model surpass Full Attention, state-of-art MoEs and
efficient transformers (including the model architecture of recently proposed
DeepSeek-V3) in several tasks across image and natural language domains. In
language modeling tasks, we achieve an average reduction of 2.38 in perplexity
compared to the best-performed MoE method with an average of 76% FLOPs. In Long
Range Arena benchmark, we recorded an average score that is at least 0.68%
higher than all comparison models including Full Attention, MoEs, and
transformer variants, with only 50% FLOPs of the best MoE method. In image
classification, our model yielded an average accuracy improvement of 1.75% than
the best model while maintaining comparable FLOPs. The source codes are
available at https://github.com/YujiaoYang-work/UoE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pap2Pat: Benchmarking Outline-Guided Long-Text Patent Generation with
  Patent-Paper Pairs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07009v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07009v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Valentin Knappich, Simon Razniewski, Anna Hätty, Annemarie Friedrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dealing with long and highly complex technical text is a challenge for Large
Language Models (LLMs), which still have to unfold their potential in
supporting expensive and timeintensive processes like patent drafting. Within
patents, the description constitutes more than 90% of the document on average.
Yet, its automatic generation remains understudied. When drafting patent
applications, patent attorneys typically receive invention reports (IRs), which
are usually confidential, hindering research on LLM-supported patent drafting.
Often, prepublication research papers serve as IRs. We leverage this duality to
build PAP2PAT, an open and realistic benchmark for patent drafting consisting
of 1.8k patent-paper pairs describing the same inventions. To address the
complex longdocument patent generation task, we propose chunk-based
outline-guided generation using the research paper as invention specification.
Our extensive evaluation using PAP2PAT and a human case study show that LLMs
can effectively leverage information from the paper, but still struggle to
provide the necessary level of detail. Fine-tuning leads to more patent-style
language, but also to more hallucination. We release our data and code
https://github.com/boschresearch/Pap2Pat.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring Human and AI Values Based on Generative Psychometrics with
  Large Language Models <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12106v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12106v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Ye, Yuhang Xie, Yuanyi Ren, Hanjun Fang, Xin Zhang, Guojie Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human values and their measurement are long-standing interdisciplinary
inquiry. Recent advances in AI have sparked renewed interest in this area, with
large language models (LLMs) emerging as both tools and subjects of value
measurement. This work introduces Generative Psychometrics for Values (GPV), an
LLM-based, data-driven value measurement paradigm, theoretically grounded in
text-revealed selective perceptions. The core idea is to dynamically parse
unstructured texts into perceptions akin to static stimuli in traditional
psychometrics, measure the value orientations they reveal, and aggregate the
results. Applying GPV to human-authored blogs, we demonstrate its stability,
validity, and superiority over prior psychological tools. Then, extending GPV
to LLM value measurement, we advance the current art with 1) a psychometric
methodology that measures LLM values based on their scalable and free-form
outputs, enabling context-specific measurement; 2) a comparative analysis of
measurement paradigms, indicating response biases of prior methods; and 3) an
attempt to bridge LLM values and their safety, revealing the predictive power
of different value systems and the impacts of various values on LLM safety.
Through interdisciplinary efforts, we aim to leverage AI for next-generation
psychometrics and psychometrics for value-aligned AI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Autoformalizing Natural Language to First-Order Logic: A Case Study in
  Logical Fallacy Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02318v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02318v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhinav Lalwani, Tasha Kim, Lovish Chopra, Christopher Hahn, Zhijing Jin, Mrinmaya Sachan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Translating natural language into formal language such as First-Order Logic
(FOL) is a foundational challenge in NLP with wide-ranging applications in
automated reasoning, misinformation tracking, and knowledge validation. In this
paper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework
to autoformalize natural language to FOL step by step using Large Language
Models (LLMs). Our approach addresses key challenges in this translation
process, including the integration of implicit background knowledge. By
leveraging structured representations generated by NL2FOL, we use
Satisfiability Modulo Theory (SMT) solvers to reason about the logical validity
of natural language statements. We present logical fallacy detection as a case
study to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach
also provides interpretable insights into the reasoning process and
demonstrates robustness without requiring model fine-tuning or labeled training
data. Our framework achieves strong performance on multiple datasets. On the
LOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing
effectively to the LOGICCLIMATE dataset with an F1-score of 80%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An LLM-based Agent for Reliable Docker Environment Configuration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13681v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13681v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruida Hu, Chao Peng, Xinchen Wang, Cuiyun Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Environment configuration is a critical yet time-consuming step in software
development, especially when dealing with unfamiliar code repositories. While
Large Language Models (LLMs) demonstrate the potential to accomplish software
engineering tasks, existing methods for environment configuration often rely on
manual efforts or fragile scripts, leading to inefficiencies and unreliable
outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully
automate environment configuration and generate executable Dockerfiles for
arbitrary Python repositories. We address two major challenges: (1) enabling
the LLM agent to configure environments within isolated Docker containers, and
(2) ensuring the successful configuration process is recorded and accurately
transferred to a Dockerfile without error. To achieve this, we propose atomic
configuration synthesis, featuring a dual-environment architecture (internal
and external environment) with a rollback mechanism to prevent environment
"pollution" from failed commands, guaranteeing atomic execution (execute fully
or not at all) and a Dockerfile generator to transfer successful configuration
steps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark
of 420 recent Python repositories with unit tests, where it achieves an 86.0%
success rate, outperforming the best baseline by 63.9%. Repo2Run is available
at https://github.com/bytedance/Repo2Run.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning to Generate Structured Output with Schema Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18878v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18878v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaxi Lu, Haolun Li, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Zhiyuan Liu, Fangming Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study investigates the structured generation capabilities of large
language models (LLMs), focusing on producing valid JSON outputs against a
given schema. Despite the widespread use of JSON in integrating language models
with programs, there is a lack of comprehensive analysis and benchmarking of
these capabilities. We explore various aspects of JSON generation, such as
structure understanding, escaping, and natural language description, to
determine how to assess and enable LLMs to generate valid responses. Building
upon this, we propose SchemaBench features around 40K different JSON schemas to
obtain and assess models' abilities in generating valid JSON. We find that the
latest LLMs are still struggling to generate a valid JSON string. Moreover, we
demonstrate that incorporating reinforcement learning with a Fine-grained
Schema Validator can further enhance models' understanding of JSON schema,
leading to improved performance. Our models demonstrate significant improvement
in both generating JSON outputs and downstream tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gated Delta Networks: Improving Mamba2 with Delta Rule <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.06464v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.06464v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songlin Yang, Jan Kautz, Ali Hatamizadeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Linear Transformers have gained attention as efficient alternatives to
standard Transformers, but their performance in retrieval and long-context
tasks has been limited. To address these limitations, recent work has explored
two distinct mechanisms: gating for adaptive memory control and the delta
update rule for precise memory modifications. We observe that these mechanisms
are complementary: gating enables rapid memory erasure while the delta rule
facilitates targeted updates. Building on this insight, we introduce the gated
delta rule and develop a parallel training algorithm optimized for modern
hardware. Our proposed architecture, Gated DeltaNet, consistently surpasses
existing models like Mamba2 and DeltaNet across multiple benchmarks, including
language modeling, common-sense reasoning, in-context retrieval, length
extrapolation, and long-context understanding. We further enhance performance
by developing hybrid architectures that combine Gated DeltaNet layers with
sliding window attention or Mamba2 layers, achieving both improved training
efficiency and superior task performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 camera ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dual Reasoning: A GNN-LLM Collaborative Framework for Knowledge Graph
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01145v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01145v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangyi Liu, Yongqi Zhang, Yong Li, Quanming Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) excel at intuitive, implicit reasoning. Guiding
LLMs to construct thought chains can enhance their deliberate reasoning
abilities, but also faces challenges such as hallucination. Knowledge Graphs
(KGs) can provide explicit structured knowledge for LLMs to alleviate these
issues. However, existing KG-enhanced methods often overlook explicit graph
learning, making it challenging to efficiently provide precise reasoning chains
for LLMs. Following dual-process theory, we propose Dual-Reasoning (DualR), a
novel framework that integrates an external system based on Graph Neural
Network (GNN) for explicit reasoning on KGs, complementing the implicit
reasoning of LLMs through externalized reasoning chains. DualR designs an
LLM-empowered GNN module for explicit learning on KGs, efficiently extracting
high-quality reasoning chains. These reasoning chains are then refined to a
knowledge-enhanced multiple-choice prompt, guiding a frozen LLM to reason
thoughtfully for final answer determination. Extensive experiments on three
benchmark KGQA datasets demonstrate that DualR achieves state-of-the-art
performance while maintaining high efficiency and interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on
  Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12767v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12767v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have combined Large Language Models (LLMs) with Knowledge
Graphs (KGs) to enhance reasoning, improving inference accuracy without
additional training while mitigating hallucination. However, existing
frameworks are often rigid, struggling to adapt to KG or task changes. They
also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.
To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that
separates reasoning into two roles: an Operator (a low-capacity LLM) that
gathers evidence and a Supervisor (a high-capacity LLM) that makes final
judgments. This design is cost-efficient for LLM inference while still
maintaining strong reasoning accuracy. Additionally, R2-KG employs an
Abstention mechanism, generating answers only when sufficient evidence is
collected from KG, which significantly enhances reliability. Experiments across
multiple KG-based reasoning tasks show that R2-KG consistently outperforms
baselines in both accuracy and reliability, regardless of the inherent
capability of LLMs used as the Operator. Further experiments reveal that the
single-agent version of R2-KG, equipped with a strict self-consistency
strategy, achieves significantly higher-than-baseline reliability while
reducing inference cost. However, it also leads to a higher abstention rate in
complex KGs. Our findings establish R2-KG as a flexible and cost-effective
solution for KG-based reasoning. It reduces reliance on high-capacity LLMs
while ensuring trustworthy inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Markov Chain of Thought for Efficient Mathematical Reasoning <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.17635v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.17635v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wen Yang, Minpeng Liao, Kai Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chain of Thought (CoT) of multi-step benefits from the logical structure of
the reasoning steps and task-specific actions, significantly enhancing the
mathematical reasoning capabilities of large language models. As the prevalence
of long CoT, the number of reasoning steps exceeds manageable token limits and
leads to higher computational demands. Inspired by the fundamental logic of
human cognition, "derive, then reduce", we conceptualize the standard
multi-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we
consider the mathematical reasoning task, defining each reasoning step as text
accompanied by a Python code snippet. To facilitate a longer reasoning path,
self-correction is enabled through interactions with the code interpreter. Our
MCoT aims to compress previous reasoning steps into a simplified question,
enabling efficient next-step inference without relying on a lengthy KV cache.
In our experiments, we curate the $\texttt{MCoTInstruct}$ dataset, and the
empirical results indicate that MCoT not only significantly enhances efficiency
but also maintains comparable accuracy. While much remains to be explored, this
work paves the way for exploring the long CoT reasoning abilities of LLMs. The
code is available at https://github.com/james-yw/Markov-Chain-of-Thought
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera ready version for NAACL 2025 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Investigating Non-Transitivity in LLM-as-a-Judge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14074v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14074v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Xu, Laura Ruis, Tim Rocktäschel, Robert Kirk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic evaluation methods based on large language models (LLMs) are
emerging as the standard tool for assessing the instruction-following abilities
of LLM-based agents. The most common method in this paradigm, pairwise
comparisons with a baseline model, critically depends on the assumption of
transitive preferences. However, the validity of this assumption remains
largely unexplored. In this study, we investigate the presence of
non-transitivity within the AlpacaEval framework and analyze its effects on
model rankings. We find that LLM judges exhibit non-transitive preferences,
leading to rankings that are sensitive to the choice of the baseline model. To
mitigate this issue, we show that round-robin tournaments combined with
Bradley-Terry models of preference can produce more reliable rankings. Notably,
our method increases both the Spearman correlation and the Kendall correlation
with Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address
the computational cost of round-robin tournaments, we propose Swiss-Wise
Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to
capture the benefits of round-robin tournaments while maintaining computational
efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, 2 tables (30 pages, 11 figures, 8 tables
  including references and appendices)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training and Evaluating Language Models with Template-based Data
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.18104v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.18104v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,
and Llama has significantly transformed natural language processing, showcasing
remarkable capabilities in understanding and generating language. However,
these models often struggle with tasks requiring complex reasoning,
particularly in mathematical problem-solving, due in part to the scarcity of
large-scale, high-quality, domain-specific datasets necessary for training
sophisticated reasoning abilities. To address this limitation, we introduce
Template-based Data Generation (TDG), a novel approach that leverages LLMs
(GPT-4) to automatically generate parameterized meta-templates, which are then
used to synthesize a vast array of high-quality problems and solutions.
Leveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset
comprising over 7 million synthetically generated grade school math
problems--each accompanied by code-based and natural language solutions--with
the potential to generate an effectively unlimited number more. This dataset
alleviates the scarcity of large-scale mathematical datasets and serves as a
valuable resource for pre-training, fine-tuning, and evaluating LLMs in
mathematical reasoning. Our method not only enables the generation of virtually
infinite data but also elevates data augmentation to a new level by using GPT-4
for meta-template generation, ensuring diverse and high-quality problem
structures. The TemplateMath Part I: TemplateGSM dataset is publicly available
at https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available
at https://github.com/iiis-ai/TemplateMath.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07055v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07055v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junkai Liu, Yujie Tong, Hui Huang, Bowen Zheng, Yiran Hu, Peicheng Wu, Chuan Xiao, Makoto Onizuka, Muyun Yang, Shuyuan Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal judgment prediction (LJP), which enables litigants and their lawyers to
forecast judgment outcomes and refine litigation strategies, has emerged as a
crucial legal NLP task. Existing studies typically utilize legal facts, i.e.,
facts that have been established by evidence and determined by the judge, to
predict the judgment. However, legal facts are often difficult to obtain in the
early stages of litigation, significantly limiting the practical applicability
of fact-based LJP. To address this limitation, we propose a novel legal NLP
task: \textit{legal fact prediction} (LFP), which takes the evidence submitted
by litigants for trial as input to predict legal facts, thereby empowering
fact-based LJP technologies to perform prediction in the absence of
ground-truth legal facts. We also propose the first benchmark dataset,
LFPBench, for evaluating the LFP task. Our extensive experiments on LFPBench
demonstrate the effectiveness of LFP-empowered LJP and highlight promising
research directions for LFP. Our code and data are available at
https://github.com/HPRCEST/LFPBench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>ing with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin
  Script Languages <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.02398v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.02398v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hoang H Nguyen, Khyati Mahajan, Vikas Yadav, Julian Salazar, Philip S. Yu, Masoud Hashemi, Rishabh Maheshwary
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although multilingual LLMs have achieved remarkable performance across
benchmarks, we find they continue to underperform on non-Latin script languages
across contemporary LLM families. This discrepancy arises from the fact that
LLMs are pretrained with orthographic scripts, which are dominated by Latin
characters that obscure their shared phonology with non-Latin scripts. We
propose leveraging phonemic transcriptions as complementary signals to induce
script-invariant representations. Our study demonstrates that integrating
phonemic signals improves performance across both non-Latin and Latin script
languages, with a particularly significant impact on closing the performance
gap between the two. Through detailed experiments, we show that phonemic and
orthographic scripts retrieve distinct examples for in-context learning (ICL).
This motivates our proposed Mixed-ICL retrieval strategy, where further
aggregation from both leads to our significant performance improvements for
both Latin script languages (up to 12.6%) and non-Latin script languages (up to
15.1%) compared to randomized ICL retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for NAACL 2025 (Main Conference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GENERator: A Long-Context Generative Genomic Foundation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07272v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07272v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Wu, Qiuyi Li, Mingyang Li, Kun Fu, Fuli Feng, Jieping Ye, Hui Xiong, Zheng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in DNA sequencing technologies have significantly improved our
ability to decode genomic sequences. However, the prediction and interpretation
of these sequences remain challenging due to the intricate nature of genetic
material. Large language models (LLMs) have introduced new opportunities for
biological sequence analysis. Recent developments in genomic language models
have underscored the potential of LLMs in deciphering DNA sequences.
Nonetheless, existing models often face limitations in robustness and
application scope, primarily due to constraints in model structure and training
data scale. To address these limitations, we present GENERator, a generative
genomic foundation model featuring a context length of 98k base pairs (bp) and
1.2B parameters. Trained on an expansive dataset comprising 386B bp of
eukaryotic DNA, the GENERator demonstrates state-of-the-art performance across
both established and newly proposed benchmarks. The model adheres to the
central dogma of molecular biology, accurately generating protein-coding
sequences that translate into proteins structurally analogous to known
families. It also shows significant promise in sequence optimization,
particularly through the prompt-responsive generation of enhancer sequences
with specific activity profiles. These capabilities position the GENERator as a
pivotal tool for genomic research and biotechnological advancement, enhancing
our ability to interpret and predict complex biological systems and enabling
precise genomic interventions. Implementation details and supplementary
resources are available at https://github.com/GenerTeam/GENERator.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unraveling and Mitigating Retriever Inconsistencies in
  Retrieval-Augmented Large Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20680v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20680v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingda Li, Xinyu Li, Yifan Chen, Wenfeng Xuan, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their
superiority in terms of factuality, they do not consistently outperform the
original retrieval-free Language Models (LMs). Our experiments reveal that this
example-level performance inconsistency exists not only between
retrieval-augmented and retrieval-free LM but also among different retrievers.
To understand this phenomenon, we investigate the degeneration behavior of
RALMs and theoretically decompose it into four categories. Further analysis
based on our decomposition reveals that the innate difference in knowledge
sources and the unpredictable degeneration of the reader model contribute most
to the inconsistency. Drawing from our analysis, we introduce Ensemble of
Retrievers (EoR), a trainable framework that can adaptively retrieve from
different knowledge sources and effectively decrease unpredictable reader
errors. Our experiments on Open Domain Question Answering show that EoR
substantially improves performance over the RALM with a single retriever by
considerably reducing inconsistent behaviors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 (findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark
  Challenging to Frontier LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17399v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17399v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ved Sirdeshmukh, Kaustubh Deshpande, Johannes Mols, Lifeng Jin, Ed-Yeremai Cardona, Dean Lee, Jeremy Kritz, Willow Primack, Summer Yue, Chen Xing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present MultiChallenge, a pioneering benchmark evaluating large language
models (LLMs) on conducting multi-turn conversations with human users, a
crucial yet underexamined capability for their applications. MultiChallenge
identifies four categories of challenges in multi-turn conversations that are
not only common and realistic among current human-LLM interactions, but are
also challenging to all current frontier LLMs. All 4 challenges require
accurate instruction-following, context allocation, and in-context reasoning at
the same time. We also develop LLM as judge with instance-level rubrics to
facilitate an automatic evaluation method with fair agreement with experienced
human raters. Despite achieving near-perfect scores on existing multi-turn
evaluation benchmarks, all frontier models have less than 50% accuracy on
MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving
just a 41.4% average accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Visual Description Grounding Reduces Hallucinations and Boosts Reasoning
  in LVLMs <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15683v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15683v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, Oriol Nieto, Zeyu Jin, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) often produce responses that misalign
with factual information, a phenomenon known as hallucinations. While
hallucinations are well-studied, the exact causes behind them remain
underexplored. In this paper, we first investigate the root causes of
hallucinations in LVLMs. Our findings reveal that existing mitigation
techniques primarily reduce hallucinations for visual recognition prompts-those
that require simple descriptions of visual elements-but fail for cognitive
prompts that demand deliberate reasoning. We identify the core issue as a lack
of true visual perception in LVLMs: although they can accurately recognize
visual elements, they struggle to fully interpret these elements in the context
of the input prompt and effectively link this recognition to their internal
knowledge, which is critical for reasoning. To address this gap, we introduce
Visual Description Grounded Decoding (VDGD), a simple, robust, and
training-free method designed to enhance visual perception and improve
reasoning capabilities in LVLMs. VDGD works by first generating a detailed
description of the image and appending it as a prefix to the instruction.
During response generation, tokens are sampled based on their KL divergence to
the description, favoring candidates with lower divergence. Experimental
results on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD
consistently outperforms existing baselines 2% - 33%. Finally, we introduce
VaLLu, a benchmark designed for comprehensive evaluation of the cognitive
capabilities of LVLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unified Mind Model: Reimagining Autonomous Agents in the LLM Era 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03459v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03459v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengbo Hu, Xiang Ying
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have recently demonstrated remarkable
capabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),
reviving the research of general autonomous agents with human-like cognitive
abilities. Such human-level agents require semantic comprehension and
instruction-following capabilities, which exactly fall into the strengths of
LLMs. Although there have been several initial attempts to build human-level
agents based on LLMs, the theoretical foundation remains a challenging open
problem. In this paper, we propose a novel theoretical cognitive architecture,
the Unified Mind Model (UMM), which offers guidance to facilitate the rapid
creation of autonomous agents with human-level cognitive abilities.
Specifically, our UMM starts with the global workspace theory and further
leverage LLMs to enable the agent with various cognitive abilities, such as
multi-modal perception, planning, reasoning, tool use, learning, memory,
reflection and motivation. Building upon UMM, we then develop an agent-building
engine, MindOS, which allows users to quickly create domain-/task-specific
autonomous agents without any programming effort.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram
  Reports <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02365v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02365v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lama Moukheiber, Mira Moukheiber, Dana Moukheiiber, Jae-Woo Ju, Hyung-Chul Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel question-answering (QA) dataset using echocardiogram
reports sourced from the Medical Information Mart for Intensive Care database.
This dataset is specifically designed to enhance QA systems in cardiology,
consisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities
and their severity. We compare large language models (LLMs), including
open-source and biomedical-specific models for zero-shot evaluation, and
closed-source models for zero-shot and three-shot evaluation. Our results show
that fine-tuning LLMs improves performance across various QA metrics,
validating the value of our dataset. Clinicians also qualitatively evaluate the
best-performing model to assess the LLM responses for correctness. Further, we
conduct fine-grained fairness audits to assess the bias-performance trade-off
of LLMs across various social determinants of health. Our objective is to
propel the field forward by establishing a benchmark for LLM AI agents aimed at
supporting clinicians with cardiac differential diagnoses, thereby reducing the
documentation burden that contributes to clinician burnout and enabling
healthcare professionals to focus more on patient care.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS SafeGenAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Doraemon<span class="highlight-title">GPT</span>: Toward Understanding Dynamic Scenes with Large Language
  Models (Exemplified as A Video Agent) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.08392v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.08392v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongxin Yang, Guikun Chen, Xiaodi Li, Wenguan Wang, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent LLM-driven visual agents mainly focus on solving image-based tasks,
which limits their ability to understand dynamic scenes, making it far from
real-life applications like guiding students in laboratory experiments and
identifying their mistakes. Hence, this paper explores DoraemonGPT, a
comprehensive and conceptually elegant system driven by LLMs to understand
dynamic scenes. Considering the video modality better reflects the
ever-changing nature of real-world scenarios, we exemplify DoraemonGPT as a
video agent. Given a video with a question/task, DoraemonGPT begins by
converting the input video into a symbolic memory that stores task-related
attributes. This structured representation allows for spatial-temporal querying
and reasoning by well-designed sub-task tools, resulting in concise
intermediate results. Recognizing that LLMs have limited internal knowledge
when it comes to specialized domains (e.g., analyzing the scientific principles
underlying experiments), we incorporate plug-and-play tools to assess external
knowledge and address tasks across different domains. Moreover, a novel
LLM-driven planner based on Monte Carlo Tree Search is introduced to explore
the large planning space for scheduling various tools. The planner iteratively
finds feasible solutions by backpropagating the result's reward, and multiple
solutions can be summarized into an improved final answer. We extensively
evaluate DoraemonGPT's effectiveness on three benchmarks and several
in-the-wild scenarios. The code will be released at
https://github.com/z-x-yang/DoraemonGPT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SWIFT: On-the-Fly Self-Speculative Decoding for LLM Inference
  Acceleration <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06916v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06916v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heming Xia, Yongqi Li, Jun Zhang, Cunxiao Du, Wenjie Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speculative decoding (SD) has emerged as a widely used paradigm to accelerate
LLM inference without compromising quality. It works by first employing a
compact model to draft multiple tokens efficiently and then using the target
LLM to verify them in parallel. While this technique has achieved notable
speedups, most existing approaches necessitate either additional parameters or
extensive training to construct effective draft models, thereby restricting
their applicability across different LLMs and tasks. To address this
limitation, we explore a novel plug-and-play SD solution with layer-skipping,
which skips intermediate layers of the target LLM as the compact draft model.
Our analysis reveals that LLMs exhibit great potential for self-acceleration
through layer sparsity and the task-specific nature of this sparsity. Building
on these insights, we introduce SWIFT, an on-the-fly self-speculative decoding
algorithm that adaptively selects intermediate layers of LLMs to skip during
inference. SWIFT does not require auxiliary models or additional training,
making it a plug-and-play solution for accelerating LLM inference across
diverse input data streams. Our extensive experiments across a wide range of
models and downstream tasks demonstrate that SWIFT can achieve over a 1.3x-1.6x
speedup while preserving the original distribution of the generated text. We
release our code in https://github.com/hemingkx/SWIFT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025, camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unifying Multitrack Music Arrangement via Reconstruction Fine-Tuning and
  Efficient Tokenization <span class="chip">IJCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Ye Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic music arrangement streamlines the creation of musical variants for
composers and arrangers, reducing reliance on extensive music expertise.
However, existing methods suffer from inefficient tokenization,
underutilization of pre-trained music language models (LMs), and suboptimal
fidelity and coherence in generated arrangements. This paper introduces an
efficient multitrack music tokenizer for unconditional and conditional symbolic
music generation, along with a unified sequence-to-sequence reconstruction
fine-tuning objective for pre-trained music LMs that balances task-specific
needs with coherence constraints. Our approach achieves state-of-the-art
results on band arrangement, piano reduction, and drum arrangement, surpassing
task-specific models in both objective metrics and perceptual quality.
Additionally, we demonstrate that generative pretraining significantly
contributes to the performance across these arrangement tasks, especially when
handling long segments with complex alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IJCAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark
  for Drug Development 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10292v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10292v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chufan Gao, Jathurshan Pradeepkumar, Trisha Das, Shivashankar Thati, Jimeng Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background The cost of drug discovery and development is substantial, with
clinical trial outcomes playing a critical role in regulatory approval and
patient care. However, access to large-scale, high-quality clinical trial
outcome data remains limited, hindering advancements in predictive modeling and
evidence-based decision-making.
  Methods We present the Clinical Trial Outcome (CTO) benchmark, a fully
reproducible, large-scale repository encompassing approximately 125,000 drug
and biologics trials. CTO integrates large language model (LLM) interpretations
of publications, trial phase progression tracking, sentiment analysis from news
sources, stock price movements of trial sponsors, and additional trial-related
metrics. Furthermore, we manually annotated a dataset of clinical trials
conducted between 2020 and 2024 to enhance the quality and reliability of
outcome labels.
  Results The trial outcome labels in the CTO benchmark agree strongly with
expert annotations, achieving an F1 score of 94 for Phase 3 trials and 91
across all phases. Additionally, benchmarking standard machine learning models
on our manually annotated dataset revealed distribution shifts in recent
trials, underscoring the necessity of continuously updated labeling approaches.
  Conclusions By analyzing CTO's performance on recent clinical trials, we
demonstrate the ongoing need for high-quality, up-to-date trial outcome labels.
We publicly release the CTO knowledge base and annotated labels at
https://chufangao.github.io/CTOD, with regular updates to support research on
clinical trial outcomes and inform data-driven improvements in drug
development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EgoNormia: Benchmarking Physical Social Norm Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20490v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20490v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        MohammadHossein Rezaei, Yicheng Fu, Phil Cuvin, Caleb Ziems, Yanzhe Zhang, Hao Zhu, Diyi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human activity is moderated by norms. However, machines are often trained
without explicit supervision on norm understanding and reasoning, especially
when the norms are grounded in a physical and social context. To improve and
evaluate the normative reasoning capability of vision-language models (VLMs),
we present EgoNormia $\|\epsilon\|$, consisting of 1,853 ego-centric videos of
human interactions, each of which has two related questions evaluating both the
prediction and justification of normative actions. The normative actions
encompass seven categories: safety, privacy, proxemics, politeness,
cooperation, coordination/proactivity, and communication/legibility. To compile
this dataset at scale, we propose a novel pipeline leveraging video sampling,
automatic answer generation, filtering, and human validation. Our work
demonstrates that current state-of-the-art vision-language models lack robust
norm understanding, scoring a maximum of 45% on EgoNormia (versus a human bench
of 92%). Our analysis of performance in each dimension highlights the
significant risks of safety, privacy, and the lack of collaboration and
communication capability when applied to real-world agents. We additionally
show that through a retrieval-based generation method, it is possible to use
EgoNormia to enhance normative reasoning in VLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adversarial Decoding: Generating Readable Documents for Adversarial
  Objectives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02163v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02163v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Collin Zhang, Tingwei Zhang, Vitaly Shmatikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We design, implement, and evaluate adversarial decoding, a new, generic text
generation technique that produces readable documents for different adversarial
objectives. Prior methods either produce easily detectable gibberish, or cannot
handle objectives that include embedding similarity. In particular, they only
work for direct attacks (such as jailbreaking) and cannot produce adversarial
text for realistic indirect injection, e.g., documents that (1) are retrieved
in RAG systems in response to broad classes of queries, and also (2)
adversarially influence subsequent generation. We also show that fluency (low
perplexity) is not sufficient to evade filtering. We measure the effectiveness
of adversarial decoding for different objectives, including RAG poisoning,
jailbreaking, and evasion of defensive filters, and demonstrate that it
outperforms existing methods while producing readable adversarial documents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ METAL: A Multi-Agent Framework for Chart Generation with Test-Time
  Scaling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17651v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17651v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bingxuan Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, Nanyun Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chart generation aims to generate code to produce charts satisfying the
desired visual properties, e.g., texts, layout, color, and type. It has great
potential to empower the automatic professional report generation in financial
analysis, research presentation, education, and healthcare. In this work, we
build a vision-language model (VLM) based multi-agent framework for effective
automatic chart generation. Generating high-quality charts requires both strong
visual design skills and precise coding capabilities that embed the desired
visual properties into code. Such a complex multi-modal reasoning process is
difficult for direct prompting of VLMs. To resolve these challenges, we propose
METAL, a multi-agent framework that decomposes the task of chart generation
into the iterative collaboration among specialized agents. METAL achieves 5.2%
improvement over the current best result in the chart generation task. The
METAL framework exhibits the phenomenon of test-time scaling: its performance
increases monotonically as the logarithmic computational budget grows from 512
to 8192 tokens. In addition, we find that separating different modalities
during the critique process of METAL boosts the self-correction capability of
VLMs in the multimodal context.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Fully-Automated Materials Discovery via Large-Scale Synthesis
  <span class="highlight-title">Dataset</span> and Expert-Level LLM-as-a-Judge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16457v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16457v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seungtaek Choi, Ji Hoon Hong, Dong Won Jeon, Sung Beom Cho, Ga-Yeon Baek, Kyung-Won Kwak, Dong-Hee Lee, Sun-Jin Choi, Jisu Bae, Chihoon Lee, Yunseo Kim, Jinsung Park, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Materials synthesis is vital for innovations such as energy storage,
catalysis, electronics, and biomedical devices. Yet, the process relies heavily
on empirical, trial-and-error methods guided by expert intuition. Our work aims
to support the materials science community by providing a practical,
data-driven resource. We have curated a comprehensive dataset of 17K
expert-verified synthesis recipes from open-access literature, which forms the
basis of our newly developed benchmark, AlchemyBench. AlchemyBench offers an
end-to-end framework that supports research in large language models applied to
synthesis prediction. It encompasses key tasks, including raw materials and
equipment prediction, synthesis procedure generation, and characterization
outcome forecasting. We propose an LLM-as-a-Judge framework that leverages
large language models for automated evaluation, demonstrating strong
statistical agreement with expert assessments. Overall, our contributions offer
a supportive foundation for exploring the capabilities of LLMs in predicting
and guiding materials synthesis, ultimately paving the way for more efficient
experimental design and accelerated innovation in materials science.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04720v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04720v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Gao, Hong-Xing Yu, Bo Zhu, Jiajun Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study reconstructing and predicting 3D fluid appearance and velocity from
a single video. Current methods require multi-view videos for fluid
reconstruction. We present FluidNexus, a novel framework that bridges video
generation and physics simulation to tackle this task. Our key insight is to
synthesize multiple novel-view videos as references for reconstruction.
FluidNexus consists of two key components: (1) a novel-view video synthesizer
that combines frame-wise view synthesis with video diffusion refinement for
generating realistic videos, and (2) a physics-integrated particle
representation coupling differentiable simulation and rendering to
simultaneously facilitate 3D fluid reconstruction and prediction. To evaluate
our approach, we collect two new real-world fluid datasets featuring textured
backgrounds and object interactions. Our method enables dynamic novel view
synthesis, future prediction, and interaction simulation from a single fluid
video. Project website: https://yuegao.me/FluidNexus.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025. Project website: https://yuegao.me/FluidNexus</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04718v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04718v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David T. Hoffmann, Syed Haseeb Raza, Hanqiu Jiang, Denis Tananaev, Steffen Klingenhoefer, Martin Meinke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene flow estimation is a foundational task for many robotic applications,
including robust dynamic object detection, automatic labeling, and sensor
synchronization. Two types of approaches to the problem have evolved: 1)
Supervised and 2) optimization-based methods. Supervised methods are fast
during inference and achieve high-quality results, however, they are limited by
the need for large amounts of labeled training data and are susceptible to
domain gaps. In contrast, unsupervised test-time optimization methods do not
face the problem of domain gaps but usually suffer from substantial runtime,
exhibit artifacts, or fail to converge to the right solution. In this work, we
mitigate several limitations of existing optimization-based methods. To this
end, we 1) introduce a simple voxel grid-based model that improves over the
standard MLP-based formulation in multiple dimensions and 2) introduce a new
multiframe loss formulation. 3) We combine both contributions in our new
method, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only
by EulerFlow among unsupervised methods while achieving comparable performance
at a fraction of the computational cost. Floxels achieves a massive speedup of
more than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10
minutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels
achieves a speedup of ~14x.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Iris Style Transfer: Enhancing Iris Recognition with Style Features and
  Privacy Preservation through Neural Style Transfer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengdi Wang, Efe Bozkir, Enkelejda Kasneci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Iris texture is widely regarded as a gold standard biometric modality for
authentication and identification. The demand for robust iris recognition
methods, coupled with growing security and privacy concerns regarding iris
attacks, has escalated recently. Inspired by neural style transfer, an advanced
technique that leverages neural networks to separate content and style
features, we hypothesize that iris texture's style features provide a reliable
foundation for recognition and are more resilient to variations like rotation
and perspective shifts than traditional approaches. Our experimental results
support this hypothesis, showing a significantly higher classification accuracy
compared to conventional features. Further, we propose using neural style
transfer to mask identifiable iris style features, ensuring the protection of
sensitive biometric information while maintaining the utility of eye images for
tasks like eye segmentation and gaze estimation. This work opens new avenues
for iris-oriented, secure, and privacy-aware biometric systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages main paper, 4 pages appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DEAL-YOLO: Drone-based Efficient Animal Localization using YOLO <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04698v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04698v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aditya Prashant Naidu, Hem Gosalia, Ishaan Gakhar, Shaurya Singh Rathore, Krish Didwania, Ujjwal Verma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although advances in deep learning and aerial surveillance technology are
improving wildlife conservation efforts, complex and erratic environmental
conditions still pose a problem, requiring innovative solutions for
cost-effective small animal detection. This work introduces DEAL-YOLO, a novel
approach that improves small object detection in Unmanned Aerial Vehicle (UAV)
images by using multi-objective loss functions like Wise IoU (WIoU) and
Normalized Wasserstein Distance (NWD), which prioritize pixels near the centre
of the bounding box, ensuring smoother localization and reducing abrupt
deviations. Additionally, the model is optimized through efficient feature
extraction with Linear Deformable (LD) convolutions, enhancing accuracy while
maintaining computational efficiency. The Scaled Sequence Feature Fusion (SSFF)
module enhances object detection by effectively capturing inter-scale
relationships, improving feature representation, and boosting metrics through
optimized multiscale fusion. Comparison with baseline models reveals high
efficacy with up to 69.5\% fewer parameters compared to vanilla Yolov8-N,
highlighting the robustness of the proposed modifications. Through this
approach, our paper aims to facilitate the detection of endangered species,
animal population analysis, habitat monitoring, biodiversity research, and
various other applications that enrich wildlife conservation efforts. DEAL-YOLO
employs a two-stage inference paradigm for object detection, refining selected
regions to improve localization and confidence. This approach enhances
performance, especially for small instances with low objectness scores.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a Poster at the ML4RS Workshop at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Teach YOLO to Remember: A Self-Distillation Approach for Continual
  Object Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04688v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04688v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo De Monte, Davide Dalle Pezze, Gian Antonio Susto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-time object detectors like YOLO achieve exceptional performance when
trained on large datasets for multiple epochs. However, in real-world scenarios
where data arrives incrementally, neural networks suffer from catastrophic
forgetting, leading to a loss of previously learned knowledge. To address this,
prior research has explored strategies for Class Incremental Learning (CIL) in
Continual Learning for Object Detection (CLOD), with most approaches focusing
on two-stage object detectors. However, existing work suggests that Learning
without Forgetting (LwF) may be ineffective for one-stage anchor-free detectors
like YOLO due to noisy regression outputs, which risk transferring corrupted
knowledge. In this work, we introduce YOLO LwF, a self-distillation approach
tailored for YOLO-based continual object detection. We demonstrate that when
coupled with a replay memory, YOLO LwF significantly mitigates forgetting.
Compared to previous approaches, it achieves state-of-the-art performance,
improving mAP by +2.1% and +2.9% on the VOC and COCO benchmarks, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Are You Doing? A Closer Look at Controllable Human Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emanuele Bugliarello, Anurag Arnab, Roni Paiss, Pieter-Jan Kindermans, Cordelia Schmid
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality benchmarks are crucial for driving progress in machine learning
research. However, despite the growing interest in video generation, there is
no comprehensive dataset to evaluate human generation. Humans can perform a
wide variety of actions and interactions, but existing datasets, like TikTok
and TED-Talks, lack the diversity and complexity to fully capture the
capabilities of video generation models. We close this gap by introducing `What
Are You Doing?' (WYD): a new benchmark for fine-grained evaluation of
controllable image-to-video generation of humans. WYD consists of 1{,}544
captioned videos that have been meticulously collected and annotated with 56
fine-grained categories. These allow us to systematically measure performance
across 9 aspects of human generation, including actions, interactions and
motion. We also propose and validate automatic metrics that leverage our
annotations and better capture human evaluations. Equipped with our dataset and
metrics, we perform in-depth analyses of seven state-of-the-art models in
controllable image-to-video generation, showing how WYD provides novel insights
about the capabilities of these models. We release our data and code to drive
forward progress in human video generation modeling at
https://github.com/google-deepmind/wyd-benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Implicit Neural Representation for Video and Image Super-Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mary Aiyetigbo, Wanqi Yuan, Feng Luo, Nianyi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach for super-resolution that utilizes implicit
neural representation (INR) to effectively reconstruct and enhance
low-resolution videos and images. By leveraging the capacity of neural networks
to implicitly encode spatial and temporal features, our method facilitates
high-resolution reconstruction using only low-resolution inputs and a 3D
high-resolution grid. This results in an efficient solution for both image and
video super-resolution. Our proposed method, SR-INR, maintains consistent
details across frames and images, achieving impressive temporal stability
without relying on the computationally intensive optical flow or motion
estimation typically used in other video super-resolution techniques. The
simplicity of our approach contrasts with the complexity of many existing
methods, making it both effective and efficient. Experimental evaluations show
that SR-INR delivers results on par with or superior to state-of-the-art
super-resolution methods, while maintaining a more straightforward structure
and reduced computational demands. These findings highlight the potential of
implicit neural representations as a powerful tool for reconstructing
high-quality, temporally consistent video and image signals from low-resolution
data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval
  via Radiology Report Mining 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04653v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04653v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tengfei Zhang, Ziheng Zhao, Chaoyi Wu, Xiao Zhou, Ya Zhang, Yangfeng Wang, Weidi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing advanced medical imaging retrieval systems is challenging due to
the varying definitions of `similar images' across different medical contexts.
This challenge is compounded by the lack of large-scale, high-quality medical
imaging retrieval datasets and benchmarks. In this paper, we propose a novel
methodology that leverages dense radiology reports to define image-wise
similarity ordering at multiple granularities in a scalable and fully automatic
manner. Using this approach, we construct two comprehensive medical imaging
retrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans,
providing detailed image-image ranking annotations conditioned on diverse
anatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR
and model-ChestCT, which demonstrate superior performance in traditional
image-image and image-report retrieval tasks. These systems also enable
flexible, effective image retrieval conditioned on specific anatomical
structures described in text, achieving state-of-the-art results on 77 out of
78 metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transferable Foundation Models for Geometric Tasks on Point Cloud
  Representations: Geometric Neural Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Blaine Quackenbush, Paul J. Atzberger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce methods for obtaining pretrained Geometric Neural Operators
(GNPs) that can serve as basal foundation models for use in obtaining geometric
features. These can be used within data processing pipelines for machine
learning tasks and numerical methods. We show how our GNPs can be trained to
learn robust latent representations for the differential geometry of
point-clouds to provide estimates of metric, curvature, and other shape-related
features. We demonstrate how our pre-trained GNPs can be used (i) to estimate
the geometric properties of surfaces of arbitrary shape and topologies with
robustness in the presence of noise, (ii) to approximate solutions of geometric
partial differential equations (PDEs) on manifolds, and (iii) to solve
equations for shape deformations such as curvature driven flows. We also
release a package of the codes and weights for using our pre-trained GNPs for
processing point cloud representations. This allows for incorporating our
pre-trained GNPs as components for reuse within existing and new data
processing pipelines. The GNPs also can be used as part of numerical solvers
involving geometry or as part of methods for performing inference and other
geometric tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Prototype Learning for Multimodal Cancer Survival Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04643v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04643v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Liu, Haosen Yang, Federica Eduati, Josien P. W. Pluim, Mitko Veta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging multimodal data, particularly the integration of whole-slide
histology images (WSIs) and transcriptomic profiles, holds great promise for
improving cancer survival prediction. However, excessive redundancy in
multimodal data can degrade model performance. In this paper, we propose
Adaptive Prototype Learning (APL), a novel and effective approach for
multimodal cancer survival analysis. APL adaptively learns representative
prototypes in a data-driven manner, reducing redundancy while preserving
critical information. Our method employs two sets of learnable query vectors
that serve as a bridge between high-dimensional representations and survival
prediction, capturing task-relevant features. Additionally, we introduce a
multimodal mixed self-attention mechanism to enable cross-modal interactions,
further enhancing information fusion. Extensive experiments on five benchmark
cancer datasets demonstrate the superiority of our approach over existing
methods. The code is available at https://github.com/HongLiuuuuu/APL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulating the Real World: A Unified <span class="highlight-title">Survey</span> of Multimodal Generative
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04641v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04641v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuqi Hu, Longguang Wang, Xian Liu, Ling-Hao Chen, Yuwei Guo, Yukai Shi, Ce Liu, Anyi Rao, Zeyu Wang, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and replicating the real world is a critical challenge in
Artificial General Intelligence (AGI) research. To achieve this, many existing
approaches, such as world models, aim to capture the fundamental principles
governing the physical world, enabling more accurate simulations and meaningful
interactions. However, current methods often treat different modalities,
including 2D (images), videos, 3D, and 4D representations, as independent
domains, overlooking their interdependencies. Additionally, these methods
typically focus on isolated dimensions of reality without systematically
integrating their connections. In this survey, we present a unified survey for
multimodal generative models that investigate the progression of data
dimensionality in real-world simulation. Specifically, this survey starts from
2D generation (appearance), then moves to video (appearance+dynamics) and 3D
generation (appearance+geometry), and finally culminates in 4D generation that
integrate all dimensions. To the best of our knowledge, this is the first
attempt to systematically unify the study of 2D, video, 3D and 4D generation
within a single framework. To guide future research, we provide a comprehensive
review of datasets, evaluation metrics and future directions, and fostering
insights for newcomers. This survey serves as a bridge to advance the study of
multimodal generative models and real-world simulation within a unified
framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Repository for the related papers at
  https://github.com/ALEEEHU/World-Simulator</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing SAM with Efficient <span class="highlight-title">Prompt</span>ing and Preference Optimization for
  Semi-supervised Medical Image Segmentation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aishik Konwer, Zhijian Yang, Erhan Bas, Cao Xiao, Prateek Prasanna, Parminder Bhatia, Taha Kass-Hout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundational models such as the Segment Anything Model (SAM) are gaining
traction in medical imaging segmentation, supporting multiple downstream tasks.
However, such models are supervised in nature, still relying on large annotated
datasets or prompts supplied by experts. Conventional techniques such as active
learning to alleviate such limitations are limited in scope and still
necessitate continuous human involvement and complex domain knowledge for label
refinement or establishing reward ground truth. To address these challenges, we
propose an enhanced Segment Anything Model (SAM) framework that utilizes
annotation-efficient prompts generated in a fully unsupervised fashion, while
still capturing essential semantic, location, and shape information through
contrastive language-image pretraining and visual question answering. We adopt
the direct preference optimization technique to design an optimal policy that
enables the model to generate high-fidelity segmentations with simple ratings
or rankings provided by a virtual annotator simulating the human annotation
process. State-of-the-art performance of our framework in tasks such as lung
segmentation, breast tumor segmentation, and organ segmentation across various
modalities, including X-ray, ultrasound, and abdominal CT, justifies its
effectiveness in low-annotation data scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 3HANDS <span class="highlight-title">Dataset</span>: Learning from Humans for Generating Naturalistic
  Handovers with Supernumerary Robotic Limbs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artin Saberpour Abadian, Yi-Chi Liao, Ata Otaran, Rishabh Dabral, Marie Muehlhaus, Christian Theobalt, Martin Schmitz, Jürgen Steimle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Supernumerary robotic limbs (SRLs) are robotic structures integrated closely
with the user's body, which augment human physical capabilities and necessitate
seamless, naturalistic human-machine interaction. For effective assistance in
physical tasks, enabling SRLs to hand over objects to humans is crucial. Yet,
designing heuristic-based policies for robots is time-consuming, difficult to
generalize across tasks, and results in less human-like motion. When trained
with proper datasets, generative models are powerful alternatives for creating
naturalistic handover motions. We introduce 3HANDS, a novel dataset of object
handover interactions between a participant performing a daily activity and
another participant enacting a hip-mounted SRL in a naturalistic manner. 3HANDS
captures the unique characteristics of SRL interactions: operating in intimate
personal space with asymmetric object origins, implicit motion synchronization,
and the user's engagement in a primary task during the handover. To demonstrate
the effectiveness of our dataset, we present three models: one that generates
naturalistic handover trajectories, another that determines the appropriate
handover endpoints, and a third that predicts the moment to initiate a
handover. In a user study (N=10), we compare the handover interaction performed
with our method compared to a baseline. The findings show that our method was
perceived as significantly more natural, less physically demanding, and more
comfortable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CHI '25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PathoPainter: Augmenting Histopathology Segmentation via Tumor-aware
  Inpainting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04634v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04634v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Liu, Haosen Yang, Evi M. C. Huijben, Mark Schuiveling, Ruisheng Su, Josien P. W. Pluim, Mitko Veta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tumor segmentation plays a critical role in histopathology, but it requires
costly, fine-grained image-mask pairs annotated by pathologists. Thus,
synthesizing histopathology data to expand the dataset is highly desirable.
Previous works suffer from inaccuracies and limited diversity in image-mask
pairs, both of which affect training segmentation, particularly in small-scale
datasets and the inherently complex nature of histopathology images. To address
this challenge, we propose PathoPainter, which reformulates image-mask pair
generation as a tumor inpainting task. Specifically, our approach preserves the
background while inpainting the tumor region, ensuring precise alignment
between the generated image and its corresponding mask. To enhance dataset
diversity while maintaining biological plausibility, we incorporate a sampling
mechanism that conditions tumor inpainting on regional embeddings from a
different image. Additionally, we introduce a filtering strategy to exclude
uncertain synthetic regions, further improving the quality of the generated
data. Our comprehensive evaluation spans multiple datasets featuring diverse
tumor types and various training data scales. As a result, segmentation
improved significantly with our synthetic data, surpassing existing
segmentation data synthesis approaches, e.g., 75.69% -> 77.69% on CAMELYON16.
The code is available at https://github.com/HongLiuuuuu/PathoPainter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Best of Both Worlds: Integrating Language Models and Diffusion
  Models for Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aoxiong Yin, Kai Shen, Yichong Leng, Xu Tan, Xinyu Zhou, Juncheng Li, Siliang Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-video (T2V) generation have been driven by two
competing paradigms: autoregressive language models and diffusion models.
However, each paradigm has intrinsic limitations: language models struggle with
visual quality and error accumulation, while diffusion models lack semantic
understanding and causal modeling. In this work, we propose LanDiff, a hybrid
framework that synergizes the strengths of both paradigms through
coarse-to-fine generation. Our architecture introduces three key innovations:
(1) a semantic tokenizer that compresses 3D visual features into compact 1D
discrete representations through efficient semantic compression, achieving a
$\sim$14,000$\times$ compression ratio; (2) a language model that generates
semantic tokens with high-level semantic relationships; (3) a streaming
diffusion model that refines coarse semantics into high-fidelity videos.
Experiments show that LanDiff, a 5B model, achieves a score of 85.43 on the
VBench T2V benchmark, surpassing the state-of-the-art open-source models
Hunyuan Video (13B) and other commercial models such as Sora, Keling, and
Hailuo. Furthermore, our model also achieves state-of-the-art performance in
long video generation, surpassing other open-source models in this field. Our
demo can be viewed at https://landiff.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Benchmark for Multi-Lingual Vision-Language Learning in Remote Sensing
  Image Captioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qing Zhou, Tao Yang, Junyu Gao, Weiping Ni, Junzheng Wu, Qi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote Sensing Image Captioning (RSIC) is a cross-modal field bridging vision
and language, aimed at automatically generating natural language descriptions
of features and scenes in remote sensing imagery. Despite significant advances
in developing sophisticated methods and large-scale datasets for training
vision-language models (VLMs), two critical challenges persist: the scarcity of
non-English descriptive datasets and the lack of multilingual capability
evaluation for models. These limitations fundamentally impede the progress and
practical deployment of RSIC, particularly in the era of large VLMs. To address
these challenges, this paper presents several significant contributions to the
field. First, we introduce and analyze BRSIC (Bilingual Remote Sensing Image
Captioning), a comprehensive bilingual dataset that enriches three established
English RSIC datasets with Chinese descriptions, encompassing 13,634 images
paired with 68,170 bilingual captions. Building upon this foundation, we
develop a systematic evaluation framework that addresses the prevalent
inconsistency in evaluation protocols, enabling rigorous assessment of model
performance through standardized retraining procedures on BRSIC. Furthermore,
we present an extensive empirical study of eight state-of-the-art large
vision-language models (LVLMs), examining their capabilities across multiple
paradigms including zero-shot inference, supervised fine-tuning, and
multi-lingual training. This comprehensive evaluation provides crucial insights
into the strengths and limitations of current LVLMs in handling multilingual
remote sensing tasks. Additionally, our cross-dataset transfer experiments
reveal interesting findings. The code and data will be available at
https://github.com/mrazhou/BRSIC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Omnidirectional Multi-Object Tracking <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04565v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04565v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Luo, Hao Shi, Sheng Wu, Fei Teng, Mengfei Duan, Chang Huang, Yuhang Wang, Kaiwei Wang, Kailun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Panoramic imagery, with its 360{\deg} field of view, offers comprehensive
information to support Multi-Object Tracking (MOT) in capturing spatial and
temporal relationships of surrounding objects. However, most MOT algorithms are
tailored for pinhole images with limited views, impairing their effectiveness
in panoramic settings. Additionally, panoramic image distortions, such as
resolution loss, geometric deformation, and uneven lighting, hinder direct
adaptation of existing MOT methods, leading to significant performance
degradation. To address these challenges, we propose OmniTrack, an
omnidirectional MOT framework that incorporates Tracklet Management to
introduce temporal cues, FlexiTrack Instances for object localization and
association, and the CircularStatE Module to alleviate image and geometric
distortions. This integration enables tracking in large field-of-view
scenarios, even under rapid sensor motion. To mitigate the lack of panoramic
MOT datasets, we introduce the QuadTrack dataset--a comprehensive panoramic
dataset collected by a quadruped robot, featuring diverse challenges such as
wide fields of view, intense motion, and complex environments. Extensive
experiments on the public JRDB dataset and the newly introduced QuadTrack
benchmark demonstrate the state-of-the-art performance of the proposed
framework. OmniTrack achieves a HOTA score of 26.92% on JRDB, representing an
improvement of 3.43%, and further achieves 23.45% on QuadTrack, surpassing the
baseline by 6.81%. The dataset and code will be made publicly available at
https://github.com/xifen523/OmniTrack.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025. The dataset and code will be made publicly
  available at https://github.com/xifen523/OmniTrack</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViT-VS: On the Applicability of <span class="highlight-title">Pretrain</span>ed Vision <span class="highlight-title">Transformer</span> Features
  for Generalizable Visual Servoing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessandro Scherl, Stefan Thalhammer, Bernhard Neuberger, Wilfried Wöber, José Gracía-Rodríguez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual servoing enables robots to precisely position their end-effector
relative to a target object. While classical methods rely on hand-crafted
features and thus are universally applicable without task-specific training,
they often struggle with occlusions and environmental variations, whereas
learning-based approaches improve robustness but typically require extensive
training. We present a visual servoing approach that leverages pretrained
vision transformers for semantic feature extraction, combining the advantages
of both paradigms while also being able to generalize beyond the provided
sample. Our approach achieves full convergence in unperturbed scenarios and
surpasses classical image-based visual servoing by up to 31.2\% relative
improvement in perturbed scenarios. Even the convergence rates of
learning-based methods are matched despite requiring no task- or
object-specific training. Real-world evaluations confirm robust performance in
end-effector positioning, industrial box manipulation, and grasping of unseen
objects using only a reference from the same category. Our code and simulation
environment are available at: https://alessandroscherl.github.io/ViT-VS/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In-Context Reverse Classification Accuracy: Efficient Estimation of
  Segmentation Quality without Ground-Truth 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matias Cosarinsky, Ramiro Billot, Lucas Mansilla, Gabriel Gimenez, Nicolas Gaggión, Guanghui Fu, Enzo Ferrante
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Assessing the quality of automatic image segmentation is crucial in clinical
practice, but often very challenging due to the limited availability of ground
truth annotations. In this paper, we introduce In-Context Reverse
Classification Accuracy (In-Context RCA), a novel framework for automatically
estimating segmentation quality in the absence of ground-truth annotations. By
leveraging recent in-context learning segmentation models and incorporating
retrieval-augmentation techniques to select the most relevant reference images,
our approach enables efficient quality estimation with minimal reference data.
Validated across diverse medical imaging modalities, our method demonstrates
robust performance and computational efficiency, offering a promising solution
for automated quality control in clinical workflows, where fast and reliable
segmentation assessment is essential. The code is available at
https://github.com/mcosarinsky/In-Context-RCA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Solution for Drone Photogrammetry with Low-overlap Aerial Images
  using Monocular Depth Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04513v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04513v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiageng Zhong, Qi Zhou, Ming Li, Armin Gruen, Xuan Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-overlap aerial imagery poses significant challenges to traditional
photogrammetric methods, which rely heavily on high image overlap to produce
accurate and complete mapping products. In this study, we propose a novel
workflow based on monocular depth estimation to address the limitations of
conventional techniques. Our method leverages tie points obtained from aerial
triangulation to establish a relationship between monocular depth and metric
depth, thus transforming the original depth map into a metric depth map,
enabling the generation of dense depth information and the comprehensive
reconstruction of the scene. For the experiments, a high-overlap drone dataset
containing 296 images is processed using Metashape to generate depth maps and
DSMs as ground truth. Subsequently, we create a low-overlap dataset by
selecting 20 images for experimental evaluation. Results demonstrate that while
the recovered depth maps and resulting DSMs achieve meter-level accuracy, they
provide significantly better completeness compared to traditional methods,
particularly in regions covered by single images. This study showcases the
potential of monocular depth estimation in low-overlap aerial photogrammetry.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04504v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04504v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunghyun Ahn, Youngwan Jo, Kijung Lee, Sein Kwon, Inpyo Hong, Sanghyun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video anomaly detection (VAD) is crucial for video analysis and surveillance
in computer vision. However, existing VAD models rely on learned normal
patterns, which makes them difficult to apply to diverse environments.
Consequently, users should retrain models or develop separate AI models for new
environments, which requires expertise in machine learning, high-performance
hardware, and extensive data collection, limiting the practical usability of
VAD. To address these challenges, this study proposes customizable video
anomaly detection (C-VAD) technique and the AnyAnomaly model. C-VAD considers
user-defined text as an abnormal event and detects frames containing a
specified event in a video. We effectively implemented AnyAnomaly using a
context-aware visual question answering without fine-tuning the large vision
language model. To validate the effectiveness of the proposed model, we
constructed C-VAD datasets and demonstrated the superiority of AnyAnomaly.
Furthermore, our approach showed competitive performance on VAD benchmark
datasets, achieving state-of-the-art results on the UBnormal dataset and
outperforming other methods in generalization across all datasets. Our code is
available online at github.com/SkiddieAhn/Paper-AnyAnomaly.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IMFine: 3D Inpainting via Geometry-guided Multi-view Refinement <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04501v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04501v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Shi, Dong Huo, Yuhongze Zhou, Kejia Yin, Yan Min, Juwei Lu, Xinxin Zuo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current 3D inpainting and object removal methods are largely limited to
front-facing scenes, facing substantial challenges when applied to diverse,
"unconstrained" scenes where the camera orientation and trajectory are
unrestricted. To bridge this gap, we introduce a novel approach that produces
inpainted 3D scenes with consistent visual quality and coherent underlying
geometry across both front-facing and unconstrained scenes. Specifically, we
propose a robust 3D inpainting pipeline that incorporates geometric priors and
a multi-view refinement network trained via test-time adaptation, building on a
pre-trained image inpainting model. Additionally, we develop a novel inpainting
mask detection technique to derive targeted inpainting masks from object masks,
boosting the performance in handling unconstrained scenes. To validate the
efficacy of our approach, we create a challenging and diverse benchmark that
spans a wide range of scenes. Comprehensive experiments demonstrate that our
proposed method substantially outperforms existing state-of-the-art approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025,
  \href{https://xinxinzuo2353.github.io/imfine/}{Project Page}</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Hsi Chen, Chin-Tien Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optical flow is a fundamental technique for motion estimation, widely applied
in video stabilization, interpolation, and object tracking. Recent advancements
in artificial intelligence (AI) have enabled deep learning models to leverage
optical flow as an important feature for motion analysis. However, traditional
optical flow methods rely on restrictive assumptions, such as brightness
constancy and slow motion constraints, limiting their effectiveness in complex
scenes. Deep learning-based approaches require extensive training on large
domain-specific datasets, making them computationally demanding. Furthermore,
optical flow is typically visualized in the HSV color space, which introduces
nonlinear distortions when converted to RGB and is highly sensitive to noise,
degrading motion representation accuracy. These limitations inherently
constrain the performance of downstream models, potentially hindering object
tracking and motion analysis tasks. To address these challenges, we propose
Reynolds flow, a novel training-free flow estimation inspired by the Reynolds
transport theorem, offering a principled approach to modeling complex motion
dynamics. Beyond the conventional HSV-based visualization, denoted
ReynoldsFlow, we introduce an alternative representation, ReynoldsFlow+,
designed to improve flow visualization. We evaluate ReynoldsFlow and
ReynoldsFlow+ across three video-based benchmarks: tiny object detection on
UAVDB, infrared object detection on Anti-UAV, and pose estimation on GolfDB.
Experimental results demonstrate that networks trained with ReynoldsFlow+
achieve state-of-the-art (SOTA) performance, exhibiting improved robustness and
efficiency across all tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spatial regularisation for improved accuracy and interpretability in
  keypoint-based registration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04499v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04499v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Billot, Ramya Muthukrishnan, Esra Abaci-Turk, Ellen P. Grant, Nicholas Ayache, Hervé Delingette, Polina Golland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised registration strategies bypass requirements in ground truth
transforms or segmentations by optimising similarity metrics between fixed and
moved volumes. Among these methods, a recent subclass of approaches based on
unsupervised keypoint detection stand out as very promising for
interpretability. Specifically, these methods train a network to predict
feature maps for fixed and moving images, from which explainable centres of
mass are computed to obtain point clouds, that are then aligned in closed-form.
However, the features returned by the network often yield spatially diffuse
patterns that are hard to interpret, thus undermining the purpose of
keypoint-based registration. Here, we propose a three-fold loss to regularise
the spatial distribution of the features. First, we use the KL divergence to
model features as point spread functions that we interpret as probabilistic
keypoints. Then, we sharpen the spatial distributions of these features to
increase the precision of the detected landmarks. Finally, we introduce a new
repulsive loss across keypoints to encourage spatial diversity. Overall, our
loss considerably improves the interpretability of the features, which now
correspond to precise and anatomically meaningful landmarks. We demonstrate our
three-fold loss in foetal rigid motion tracking and brain MRI affine
registration tasks, where it not only outperforms state-of-the-art unsupervised
strategies, but also bridges the gap with state-of-the-art supervised methods.
Our code is available at https://github.com/BenBillot/spatial_regularisation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Object Placement Programs for Indoor Scene Synthesis with
  Iterative Self Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrian Chang, Kai Wang, Yuanbo Li, Manolis Savva, Angel X. Chang, Daniel Ritchie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data driven and autoregressive indoor scene synthesis systems generate indoor
scenes automatically by suggesting and then placing objects one at a time.
Empirical observations show that current systems tend to produce incomplete
next object location distributions. We introduce a system which addresses this
problem. We design a Domain Specific Language (DSL) that specifies functional
constraints. Programs from our language take as input a partial scene and
object to place. Upon execution they predict possible object placements. We
design a generative model which writes these programs automatically. Available
3D scene datasets do not contain programs to train on, so we build upon
previous work in unsupervised program induction to introduce a new program
bootstrapping algorithm. In order to quantify our empirical observations we
introduce a new evaluation procedure which captures how well a system models
per-object location distributions. We ask human annotators to label all the
possible places an object can go in a scene and show that our system produces
per-object location distributions more consistent with human annotators. Our
system also generates indoor scenes of comparable quality to previous systems
and while previous systems degrade in performance when training data is sparse,
our system does not degrade to the same degree.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 20 figures Subjects: Graphics (cs.GR), Computer Vision and
  Pattern Recognition (cs.CV), Machine Learning (cs.LG)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic Alignment of Unimodal Medical Text and Vision Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04478v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04478v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxime Di Folco, Emily Chan, Marta Hasny, Cosmin I. Bercea, Julia A. Schnabel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  General-purpose AI models, particularly those designed for text and vision,
demonstrate impressive versatility across a wide range of deep-learning tasks.
However, they often underperform in specialised domains like medical imaging,
where domain-specific solutions or alternative knowledge transfer approaches
are typically required. Recent studies have noted that general-purpose models
can exhibit similar latent spaces when processing semantically related data,
although this alignment does not occur naturally. Building on this insight, it
has been shown that applying a simple transformation - at most affine -
estimated from a subset of semantically corresponding samples, known as
anchors, enables model stitching across diverse training paradigms,
architectures, and modalities. In this paper, we explore how semantic alignment
- estimating transformations between anchors - can bridge general-purpose AI
with specialised medical knowledge. Using multiple public chest X-ray datasets,
we demonstrate that model stitching across model architectures allows general
models to integrate domain-specific knowledge without additional training,
leading to improved performance on medical tasks. Furthermore, we introduce a
novel zero-shot classification approach for unimodal vision encoders that
leverages semantic alignment across modalities. Our results show that our
method not only outperforms general multimodal models but also approaches the
performance levels of fully trained, medical-specific multimodal solutions
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ForestLPR: LiDAR Place Recognition in Forests Attentioning Multiple BEV
  Density Images <span class="chip">CVPR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanqing Shen, Turcan Tuna, Marco Hutter, Cesar Cadena, Nanning Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Place recognition is essential to maintain global consistency in large-scale
localization systems. While research in urban environments has progressed
significantly using LiDARs or cameras, applications in natural forest-like
environments remain largely under-explored. Furthermore, forests present
particular challenges due to high self-similarity and substantial variations in
vegetation growth over time. In this work, we propose a robust LiDAR-based
place recognition method for natural forests, ForestLPR. We hypothesize that a
set of cross-sectional images of the forest's geometry at different heights
contains the information needed to recognize revisiting a place. The
cross-sectional images are represented by \ac{bev} density images of horizontal
slices of the point cloud at different heights. Our approach utilizes a visual
transformer as the shared backbone to produce sets of local descriptors and
introduces a multi-BEV interaction module to attend to information at different
heights adaptively. It is followed by an aggregation layer that produces a
rotation-invariant place descriptor. We evaluated the efficacy of our method
extensively on real-world data from public benchmarks as well as robotic
datasets and compared it against the state-of-the-art (SOTA) methods. The
results indicate that ForestLPR has consistently good performance on all
evaluations and achieves an average increase of 7.38\% and 9.11\% on Recall@1
over the closest competitor on intra-sequence loop closure detection and
inter-sequence re-localization, respectively, validating our hypothesis
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by CVPR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Gate-Shift-Pose: Enhancing Action Recognition in Sports with Skeleton
  Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edoardo Bianchi, Oswald Lanz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Gate-Shift-Pose, an enhanced version of Gate-Shift-Fuse
networks, designed for athlete fall classification in figure skating by
integrating skeleton pose data alongside RGB frames. We evaluate two fusion
strategies: early-fusion, which combines RGB frames with Gaussian heatmaps of
pose keypoints at the input stage, and late-fusion, which employs a
multi-stream architecture with attention mechanisms to combine RGB and pose
features. Experiments on the FR-FS dataset demonstrate that Gate-Shift-Pose
significantly outperforms the RGB-only baseline, improving accuracy by up to
40% with ResNet18 and 20% with ResNet50. Early-fusion achieves the highest
accuracy (98.08%) with ResNet50, leveraging the model's capacity for effective
multimodal integration, while late-fusion is better suited for lighter
backbones like ResNet18. These results highlight the potential of multimodal
architectures for sports action recognition and the critical role of skeleton
pose information in capturing complex motion patterns.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Question-Aware Gaussian Experts for Audio-Visual Question Answering <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04459v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04459v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongyeob Kim, Inyoung Jung, Dayoon Suh, Youjia Zhang, Sangmin Lee, Sungeun Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio-Visual Question Answering (AVQA) requires not only question-based
multimodal reasoning but also precise temporal grounding to capture subtle
dynamics for accurate prediction. However, existing methods mainly use question
information implicitly, limiting focus on question-specific details.
Furthermore, most studies rely on uniform frame sampling, which can miss key
question-relevant frames. Although recent Top-K frame selection methods aim to
address this, their discrete nature still overlooks fine-grained temporal
details. This paper proposes \textbf{QA-TIGER}, a novel framework that
explicitly incorporates question information and models continuous temporal
dynamics. Our key idea is to use Gaussian-based modeling to adaptively focus on
both consecutive and non-consecutive frames based on the question, while
explicitly injecting question information and applying progressive refinement.
We leverage a Mixture of Experts (MoE) to flexibly implement multiple Gaussian
models, activating temporal experts specifically tailored to the question.
Extensive experiments on multiple AVQA benchmarks show that QA-TIGER
consistently achieves state-of-the-art performance. Code is available at
https://github.com/AIM-SKKU/QA-TIGER
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025. Project page at https://aim-skku.github.io/QA-TIGER/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TPC: Cross-Temporal Prediction Connection for Vision-Language Model
  Hallucination Reduction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chao Wang, Weiwei Fu, Yang Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have achieved remarkable advancements,
capitalizing on the impressive capabilities of large language models (LLMs)
across diverse tasks. Despite this, a critical challenge known as hallucination
occurs when models overconfidently describe objects or attributes absent from
the image, a problem exacerbated by the tendency of VLMs to rely on linguistic
priors. This limitation reduces model reliability in high-stakes applications.
In this work, we have observed the characteristic of logits' continuity
consistency enhancement and introduced a straightforward and efficient method,
Cross-Temporal Prediction Connection (TPC), designed to enhance the semantic
consistency of logits by connecting them temporally across timesteps. TPC
amplifies information flow and improves coherence, effectively reducing
hallucination. Extensive experiments show that TPC surpasses existing
representatives, delivering superior performance in both accuracy and
efficiency while maintaining robustness in open-ended text generation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A lightweight model FDM-YOLO for small target improvement based on
  YOLOv8 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuerui Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Small targets are particularly difficult to detect due to their low pixel
count, complex backgrounds, and varying shooting angles, which make it hard for
models to extract effective features. While some large-scale models offer high
accuracy, their long inference times make them unsuitable for real-time
deployment on edge devices. On the other hand, models designed for low
computational power often suffer from poor detection accuracy. This paper
focuses on small target detection and explores methods for object detection
under low computational constraints. Building on the YOLOv8 model, we propose a
new network architecture called FDM-YOLO. Our research includes the following
key contributions: We introduce FDM-YOLO by analyzing the output of the YOLOv8
detection head. We add a highresolution layer and remove the large target
detection layer to better handle small targets. Based on PConv, we propose a
lightweight network structure called Fast-C2f, which is integrated into the PAN
module of the model. To mitigate the accuracy loss caused by model
lightweighting, we employ dynamic upsampling (Dysample) and a lightweight EMA
attention mechanism.The FDM-YOLO model was validated on the Visdrone dataset,
achieving a 38% reduction in parameter count and improving the Map0.5 score
from 38.4% to 42.5%, all while maintaining nearly the same inference speed.
This demonstrates the effectiveness of our approach in balancing accuracy and
efficiency for edge device deployment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ToFu: Visual Tokens Reduction via Fusion for Multi-modal, Multi-patch,
  Multi-image Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04444v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04444v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vittorio Pippi, Matthieu Guillaumin, Silvia Cascianelli, Rita Cucchiara, Maximilian Jaritz, Loris Bazzani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Multimodal Models (LMMs) are powerful tools that are capable of
reasoning and understanding multimodal information beyond text and language.
Despite their entrenched impact, the development of LMMs is hindered by the
higher computational requirements compared to their unimodal counterparts. One
of the main causes of this is the large amount of tokens needed to encode the
visual input, which is especially evident for multi-image multimodal tasks.
Recent approaches to reduce visual tokens depend on the visual encoder
architecture, require fine-tuning the LLM to maintain the performance, and only
consider single-image scenarios. To address these limitations, we propose ToFu,
a visual encoder-agnostic, training-free Token Fusion strategy that combines
redundant visual tokens of LMMs for high-resolution, multi-image, tasks. The
core intuition behind our method is straightforward yet effective: preserve
distinctive tokens while combining similar ones. We achieve this by
sequentially examining visual tokens and deciding whether to merge them with
others or keep them as separate entities. We validate our approach on the
well-established LLaVA-Interleave Bench, which covers challenging multi-image
tasks. In addition, we push to the extreme our method by testing it on a
newly-created benchmark, ComPairs, focused on multi-image comparisons where a
larger amount of images and visual tokens are inputted to the LMMs. Our
extensive analysis, considering several LMM architectures, demonstrates the
benefits of our approach both in terms of efficiency and performance gain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EvidMTL: Evidential Multi-Task Learning for Uncertainty-Aware Semantic
  Surface Mapping from Monocular RGB Images <span class="chip">IROS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04441v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04441v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Menon, Nils Dengler, Sicong Pan, Gokul Krishna Chenchani, Maren Bennewitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For scene understanding in unstructured environments, an accurate and
uncertainty-aware metric-semantic mapping is required to enable informed action
selection by autonomous systems.Existing mapping methods often suffer from
overconfident semantic predictions, and sparse and noisy depth sensing, leading
to inconsistent map representations. In this paper, we therefore introduce
EvidMTL, a multi-task learning framework that uses evidential heads for depth
estimation and semantic segmentation, enabling uncertainty-aware inference from
monocular RGB images. To enable uncertainty-calibrated evidential multi-task
learning, we propose a novel evidential depth loss function that jointly
optimizes the belief strength of the depth prediction in conjunction with
evidential segmentation loss. Building on this, we present EvidKimera, an
uncertainty-aware semantic surface mapping framework, which uses evidential
depth and semantics prediction for improved 3D metric-semantic consistency. We
train and evaluate EvidMTL on the NYUDepthV2 and assess its zero-shot
performance on ScanNetV2, demonstrating superior uncertainty estimation
compared to conventional approaches while maintaining comparable depth
estimation and semantic segmentation. In zero-shot mapping tests on ScanNetV2,
EvidKimera outperforms Kimera in semantic surface mapping accuracy and
consistency, highlighting the benefits of uncertainty-aware mapping and
underscoring its potential for real-world robotic applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IROS 2025 Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PointsToWood: A deep learning framework for complete canopy leaf-wood
  segmentation of TLS data across diverse European forests 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04420v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04420v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harry J. F. Owen, Matthew J. A. Allen, Stuart W. D. Grieve, Phill Wilkes, Emily R. Lines
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Point clouds from Terrestrial Laser Scanning (TLS) are an increasingly
popular source of data for studying plant structure and function but typically
require extensive manual processing to extract ecologically important
information. One key task is the accurate semantic segmentation of different
plant material within point clouds, particularly wood and leaves, which is
required to understand plant productivity, architecture and physiology.
Existing automated semantic segmentation methods are primarily developed for
single ecosystem types, and whilst they show good accuracy for biomass
assessment from the trunk and large branches, often perform less well within
the crown. In this study, we demonstrate a new framework that uses a deep
learning architecture newly developed from PointNet and pointNEXT for
processing 3D point clouds to provide a reliable semantic segmentation of wood
and leaf in TLS point clouds from the tree base to branch tips, trained on data
from diverse mature European forests. Our model uses meticulously labelled data
combined with voxel-based sampling, neighbourhood rescaling, and a novel gated
reflectance integration module embedded throughout the feature extraction
layers. We evaluate its performance across open datasets from boreal,
temperate, Mediterranean and tropical regions, encompassing diverse ecosystem
types and sensor characteristics. Our results show consistent outperformance
against the most widely used PointNet based approach for leaf/wood segmentation
on our high-density TLS dataset collected across diverse mixed forest plots
across all major biomes in Europe. We also find consistently strong performance
tested on others open data from China, Eastern Cameroon, Germany and Finland,
collected using both time-of-flight and phase-shift sensors, showcasing the
transferability of our model to a wide range of ecosystems and sensors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning <span class="highlight-title">Transformer</span>-based World Models with Contrastive Predictive
  Coding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxime Burchi, Radu Timofte
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The DreamerV3 algorithm recently obtained remarkable performance across
diverse environment domains by learning an accurate world model based on
Recurrent Neural Networks (RNNs). Following the success of model-based
reinforcement learning algorithms and the rapid adoption of the Transformer
architecture for its superior training efficiency and favorable scaling
properties, recent works such as STORM have proposed replacing RNN-based world
models with Transformer-based world models using masked self-attention.
However, despite the improved training efficiency of these methods, their
impact on performance remains limited compared to the Dreamer algorithm,
struggling to learn competitive Transformer-based world models. In this work,
we show that the next state prediction objective adopted in previous approaches
is insufficient to fully exploit the representation capabilities of
Transformers. We propose to extend world model predictions to longer time
horizons by introducing TWISTER (Transformer-based World model wIth contraSTivE
Representations), a world model using action-conditioned Contrastive Predictive
Coding to learn high-level temporal feature representations and improve the
agent performance. TWISTER achieves a human-normalized mean score of 162% on
the Atari 100k benchmark, setting a new record among state-of-the-art methods
that do not employ look-ahead search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scale-Invariant Adversarial Attack against Arbitrary-scale
  Super-resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04385v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04385v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihao Huang, Xin Luo, Qing Guo, Felix Juefei-Xu, Xiaojun Jia, Weikai Miao, Geguang Pu, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of local continuous image function (LIIF) has garnered significant
attention for arbitrary-scale super-resolution (SR) techniques. However, while
the vulnerabilities of fixed-scale SR have been assessed, the robustness of
continuous representation-based arbitrary-scale SR against adversarial attacks
remains an area warranting further exploration. The elaborately designed
adversarial attacks for fixed-scale SR are scale-dependent, which will cause
time-consuming and memory-consuming problems when applied to arbitrary-scale
SR. To address this concern, we propose a simple yet effective
``scale-invariant'' SR adversarial attack method with good transferability,
termed SIAGT. Specifically, we propose to construct resource-saving attacks by
exploiting finite discrete points of continuous representation. In addition, we
formulate a coordinate-dependent loss to enhance the cross-model
transferability of the attack. The attack can significantly deteriorate the SR
images while introducing imperceptible distortion to the targeted
low-resolution (LR) images. Experiments carried out on three popular LIIF-based
SR approaches and four classical SR datasets show remarkable attack performance
and transferability of SIAGT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, accepted by TIFS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for
  Domain Generalized Stereo Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04376v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04376v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Xu, Zhiyu Xiang, Jingyun Fu, Tianyu Pu, Hanzhi Zhong, Eryun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the significant advances in domain generalized stereo matching,
existing methods still exhibit domain-specific preferences when transferring
from synthetic to real domains, hindering their practical applications in
complex and diverse scenarios. The probability distributions predicted by the
stereo network naturally encode rich similarity and uncertainty information.
Inspired by this observation, we propose to extract these two types of dark
knowledge from the pre-trained network to model intuitive multi-modal
ground-truth distributions for both edge and non-edge regions. To mitigate the
inherent domain preferences of a single network, we adopt network ensemble and
further distinguish between objective and biased knowledge in the Laplace
parameter space. Finally, the objective knowledge and the original disparity
labels are jointly modeled as a mixture of Laplacians to provide fine-grained
supervision for the stereo network training. Extensive experiments demonstrate
that: 1) Our method is generic and effectively improves the generalization of
existing networks. 2) PCWNet with our method achieves the state-of-the-art
generalization performance on both KITTI 2015 and 2012 datasets. 3) Our method
outperforms existing methods in comprehensive ranking across four popular
real-world datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ObjMST: An Object-Focused Multimodal Style Transfer Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04353v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04353v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chanda Grover Kamra, Indra Deep Mastan, Debayan Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose ObjMST, an object-focused multimodal style transfer framework that
provides separate style supervision for salient objects and surrounding
elements while addressing alignment issues in multimodal representation
learning. Existing image-text multimodal style transfer methods face the
following challenges: (1) generating non-aligned and inconsistent multimodal
style representations; and (2) content mismatch, where identical style patterns
are applied to both salient objects and their surrounding elements. Our
approach mitigates these issues by: (1) introducing a Style-Specific Masked
Directional CLIP Loss, which ensures consistent and aligned style
representations for both salient objects and their surroundings; and (2)
incorporating a salient-to-key mapping mechanism for stylizing salient objects,
followed by image harmonization to seamlessly blend the stylized objects with
their environment. We validate the effectiveness of ObjMST through experiments,
using both quantitative metrics and qualitative visual evaluations of the
stylized outputs. Our code is available at:
https://github.com/chandagrover/ObjMST.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 Figures, 3 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PLMP -- Point-Line Minimal Problems for Projective SfM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04351v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04351v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kim Kiehn, Albin Ahlbäck, Kathlén Kohn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We completely classify all minimal problems for Structure-from-Motion (SfM)
where arrangements of points and lines are fully observed by multiple
uncalibrated pinhole cameras. We find 291 minimal problems, 73 of which have
unique solutions and can thus be solved linearly. Two of the linear problems
allow an arbitrary number of views, while all other minimal problems have at
most 9 cameras. All minimal problems have at most 7 points and at most 12
lines. We compute the number of solutions of each minimal problem, as this
gives a measurement of the problem's intrinsic difficulty, and find that these
number are relatively low (e.g., when comparing with minimal problems for
calibrated cameras). Finally, by exploring stabilizer subgroups of
subarrangements, we develop a geometric and systematic way to 1) factorize
minimal problems into smaller problems, 2) identify minimal problems in
underconstrained problems, and 3) formally prove non-minimality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEDiT: Your Length-Extrapolatable Diffusion <span class="highlight-title">Transformer</span> without
  Positional Encoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04344v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04344v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shen Zhang, Yaning Tan, Siyuan Liang, Linze Li, Ge Wu, Yuhao Chen, Shuheng Li, Zhenyu Zhao, Caihua Chen, Jiajun Liang, Yao Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion transformers(DiTs) struggle to generate images at resolutions
higher than their training resolutions. The primary obstacle is that the
explicit positional encodings(PE), such as RoPE, need extrapolation which
degrades performance when the inference resolution differs from training. In
this paper, we propose a Length-Extrapolatable Diffusion Transformer(LEDiT), a
simple yet powerful architecture to overcome this limitation. LEDiT needs no
explicit PEs, thereby avoiding extrapolation. The key innovations of LEDiT are
introducing causal attention to implicitly impart global positional information
to tokens, while enhancing locality to precisely distinguish adjacent tokens.
Experiments on 256x256 and 512x512 ImageNet show that LEDiT can scale the
inference resolution to 512x512 and 1024x1024, respectively, while achieving
better image quality compared to current state-of-the-art length extrapolation
methods(NTK-aware, YaRN). Moreover, LEDiT achieves strong extrapolation
performance with just 100K steps of fine-tuning on a pretrained DiT,
demonstrating its potential for integration into existing text-to-image DiTs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GaussianVideo: Efficient Video Representation and Compression by
  Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04333v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04333v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Inseo Lee, Youngyoon Choi, Joonseok Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit Neural Representation for Videos (NeRV) has introduced a novel
paradigm for video representation and compression, outperforming traditional
codecs. As model size grows, however, slow encoding and decoding speed and high
memory consumption hinder its application in practice. To address these
limitations, we propose a new video representation and compression method based
on 2D Gaussian Splatting to efficiently handle video data. Our proposed
deformable 2D Gaussian Splatting dynamically adapts the transformation of 2D
Gaussians at each frame, significantly reducing memory cost. Equipped with a
multi-plane-based spatiotemporal encoder and a lightweight decoder, it predicts
changes in color, coordinates, and shape of initialized Gaussians, given the
time step. By leveraging temporal gradients, our model effectively captures
temporal redundancy at negligible cost, significantly enhancing video
representation efficiency. Our method reduces GPU memory usage by up to 78.4%,
and significantly expedites video processing, achieving 5.5x faster training
and 12.5x faster decoding compared to the state-of-the-art NeRV methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain
  tumour Segmentation on mp-MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04325v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04325v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cecilia Diana-Albelda, Roberto Alcover-Couso, Álvaro García-Martín, Jesus Bescos, Marcos Escudero-Viñolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gliomas are brain tumours that stand out for their highly lethal and
aggressive nature, which demands a precise approach in their diagnosis. Medical
image segmentation plays a crucial role in the evaluation and follow-up of
these tumours, allowing specialists to analyse their morphology. However,
existing methods for automatic glioma segmentation often lack generalization
capability across other brain tumour domains, require extensive computational
resources, or fail to fully utilize the multi-parametric MRI (mp-MRI) data used
to delineate them. In this work, we introduce GBT-SAM, a novel Generalizable
Brain Tumour (GBT) framework that extends the Segment Anything Model (SAM) to
brain tumour segmentation tasks. Our method employs a two-step training
protocol: first, fine-tuning the patch embedding layer to process the entire
mp-MRI modalities, and second, incorporating parameter-efficient LoRA blocks
and a Depth-Condition block into the Vision Transformer (ViT) to capture
inter-slice correlations. GBT-SAM achieves state-of-the-art performance on the
Adult Glioma dataset (Dice Score of $93.54$) while demonstrating robust
generalization across Meningioma, Pediatric Glioma, and Sub-Saharan Glioma
datasets. Furthermore, GBT-SAM uses less than 6.5M trainable parameters, thus
offering an efficient solution for brain tumour segmentation. \\ Our code and
models are available at https://github.com/vpulab/med-sam-brain .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Modular Pipeline for 3D Object Tracking Using RGB Cameras 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04322v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04322v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lars Bredereke, Yale Hartmann, Tanja Schultz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object tracking is a key challenge of computer vision with various
applications that all require different architectures. Most tracking systems
have limitations such as constraining all movement to a 2D plane and they often
track only one object. In this paper, we present a new modular pipeline that
calculates 3D trajectories of multiple objects. It is adaptable to various
settings where multiple time-synced and stationary cameras record moving
objects, using off the shelf webcams. Our pipeline was tested on the Table
Setting Dataset, where participants are recorded with various sensors as they
set a table with tableware objects. We need to track these manipulated objects,
using 6 rgb webcams. Challenges include: Detecting small objects in 9.874.699
camera frames, determining camera poses, discriminating between nearby and
overlapping objects, temporary occlusions, and finally calculating a 3D
trajectory using the right subset of an average of 11.12.456 pixel coordinates
per 3-minute trial. We implement a robust pipeline that results in accurate
trajectories with covariance of x,y,z-position as a confidence metric. It deals
dynamically with appearing and disappearing objects, instantiating new Extended
Kalman Filters. It scales to hundreds of table-setting trials with very little
human annotation input, even with the camera poses of each trial unknown. The
code is available at https://github.com/LarsBredereke/object_tracking
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 11 figures, original paper not to be published anywhere else</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ S2Gaussian: Sparse-View Super-Resolution 3D Gaussian Splatting <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04314v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04314v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yecong Wan, Mingwen Shao, Yuanshuo Cheng, Wangmeng Zuo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we aim ambitiously for a realistic yet challenging problem,
namely, how to reconstruct high-quality 3D scenes from sparse low-resolution
views that simultaneously suffer from deficient perspectives and clarity.
Whereas existing methods only deal with either sparse views or low-resolution
observations, they fail to handle such hybrid and complicated scenarios. To
this end, we propose a novel Sparse-view Super-resolution 3D Gaussian Splatting
framework, dubbed S2Gaussian, that can reconstruct structure-accurate and
detail-faithful 3D scenes with only sparse and low-resolution views. The
S2Gaussian operates in a two-stage fashion. In the first stage, we initially
optimize a low-resolution Gaussian representation with depth regularization and
densify it to initialize the high-resolution Gaussians through a tailored
Gaussian Shuffle Split operation. In the second stage, we refine the
high-resolution Gaussians with the super-resolved images generated from both
original sparse views and pseudo-views rendered by the low-resolution
Gaussians. In which a customized blur-free inconsistency modeling scheme and a
3D robust optimization strategy are elaborately designed to mitigate multi-view
inconsistency and eliminate erroneous updates caused by imperfect supervision.
Extensive experiments demonstrate superior results and in particular
establishing new state-of-the-art performances with more consistent geometry
and finer details.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shaken, Not Stirred: A Novel <span class="highlight-title">Dataset</span> for Visual Understanding of Glasses
  in Human-Robot Bartending Tasks <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04308v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04308v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukáš Gajdošech, Hassan Ali, Jan-Gerrit Habekost, Martin Madaras, Matthias Kerzel, Stefan Wermter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Datasets for object detection often do not account for enough variety of
glasses, due to their transparent and reflective properties. Specifically,
open-vocabulary object detectors, widely used in embodied robotic agents, fail
to distinguish subclasses of glasses. This scientific gap poses an issue to
robotic applications that suffer from accumulating errors between detection,
planning, and action execution. The paper introduces a novel method for the
acquisition of real-world data from RGB-D sensors that minimizes human effort.
We propose an auto-labeling pipeline that generates labels for all the acquired
frames based on the depth measurements. We provide a novel real-world glass
object dataset that was collected on the Neuro-Inspired COLlaborator (NICOL), a
humanoid robot platform. The data set consists of 7850 images recorded from
five different cameras. We show that our trained baseline model outperforms
state-of-the-art open-vocabulary approaches. In addition, we deploy our
baseline model in an embodied agent approach to the NICOL platform, on which it
achieves a success rate of 81% in a human-robot bartending scenario.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ControlFill: Spatially Adjustable Image Inpainting from <span class="highlight-title">Prompt</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boseong Jeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this report, I present an inpainting framework named \textit{ControlFill},
which involves training two distinct prompts: one for generating plausible
objects within a designated mask (\textit{creation}) and another for filling
the region by extending the background (\textit{removal}). During the inference
stage, these learned embeddings guide a diffusion network that operates without
requiring heavy text encoders. By adjusting the relative significance of the
two prompts and employing classifier-free guidance, users can control the
intensity of removal or creation. Furthermore, I introduce a method to
spatially vary the intensity of guidance by assigning different scales to
individual pixels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TAIL: Text-Audio Incremental Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04258v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04258v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingfei Sun, Xu Gu, Wei Ji, Hanbin Zhao, Hao Fei, Yifang Yin, Roger Zimmermann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many studies combine text and audio to capture multi-modal information but
they overlook the model's generalization ability on new datasets. Introducing
new datasets may affect the feature space of the original dataset, leading to
catastrophic forgetting. Meanwhile, large model parameters can significantly
impact training performance. To address these limitations, we introduce a novel
task called Text-Audio Incremental Learning (TAIL) task for text-audio
retrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text
incremental learning. This method utilizes prompt tuning to optimize the model
parameters while incorporating an audio-text similarity and feature
distillation module to effectively mitigate catastrophic forgetting. We
benchmark our method and previous incremental learning methods on AudioCaps,
Clotho, BBC Sound Effects and Audioset datasets, and our method outperforms
previous methods significantly, particularly demonstrating stronger resistance
to forgetting on older datasets. Compared to the full-parameters Finetune
(Sequential) method, our model only requires 2.42\% of its parameters,
achieving 4.46\% higher performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary
  Objects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonkwang Lee, Jongwon Jeong, Taehong Moon, Hyeon-Jong Kim, Jaehyeon Kim, Gunhee Kim, Byeong-Uk Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion synthesis for diverse object categories holds great potential for 3D
content creation but remains underexplored due to two key challenges: (1) the
lack of comprehensive motion datasets that include a wide range of high-quality
motions and annotations, and (2) the absence of methods capable of handling
heterogeneous skeletal templates from diverse objects. To address these
challenges, we contribute the following: First, we augment the Truebones Zoo
dataset, a high-quality animal motion dataset covering over 70 species, by
annotating it with detailed text descriptions, making it suitable for
text-based motion synthesis. Second, we introduce rig augmentation techniques
that generate diverse motion data while preserving consistent dynamics,
enabling models to adapt to various skeletal configurations. Finally, we
redesign existing motion diffusion models to dynamically adapt to arbitrary
skeletal templates, enabling motion synthesis for a diverse range of objects
with varying structures. Experiments show that our method learns to generate
high-fidelity motions from textual descriptions for diverse and even unseen
objects, setting a strong foundation for motion synthesis across diverse object
categories and skeletal templates. Qualitative results are available on this
link: t2m4lvo.github.io
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Egocentric Vision-Language Model based Portable Real-time Smart
  Assistant 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04250v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04250v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei Huang, Jilan Xu, Baoqi Pei, Yuping He, Guo Chen, Mingfang Zhang, Lijin Yang, Zheng Nie, Jinyao Liu, Guoshun Fan, Dechen Lin, Fang Fang, Kunpeng Li, Chang Yuan, Xinyuan Chen, Yaohui Wang, Yali Wang, Yu Qiao, Limin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Vinci, a vision-language system designed to provide real-time,
comprehensive AI assistance on portable devices. At its core, Vinci leverages
EgoVideo-VL, a novel model that integrates an egocentric vision foundation
model with a large language model (LLM), enabling advanced functionalities such
as scene understanding, temporal grounding, video summarization, and future
planning. To enhance its utility, Vinci incorporates a memory module for
processing long video streams in real time while retaining contextual history,
a generation module for producing visual action demonstrations, and a retrieval
module that bridges egocentric and third-person perspectives to provide
relevant how-to videos for skill acquisition. Unlike existing systems that
often depend on specialized hardware, Vinci is hardware-agnostic, supporting
deployment across a wide range of devices, including smartphones and wearable
cameras. In our experiments, we first demonstrate the superior performance of
EgoVideo-VL on multiple public benchmarks, showcasing its vision-language
reasoning and contextual understanding capabilities. We then conduct a series
of user studies to evaluate the real-world effectiveness of Vinci, highlighting
its adaptability and usability in diverse scenarios. We hope Vinci can
establish a new framework for portable, real-time egocentric AI systems,
empowering users with contextual and actionable insights. Including the
frontend, backend, and models, all codes of Vinci are available at
https://github.com/OpenGVLab/vinci.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometry-Constrained Monocular Scale Estimation Using Semantic
  Segmentation for Dynamic Scenes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04235v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04235v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Zhang, Zhiyang Wu, Qianqian Shangguan, Kang An
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monocular visual localization plays a pivotal role in advanced driver
assistance systems and autonomous driving by estimating a vehicle's ego-motion
from a single pinhole camera. Nevertheless, conventional monocular visual
odometry encoun-ters challenges in scale estimation due to the absence of depth
information during projection. Previous methodologies, whether rooted in
physical constraints or deep learning paradigms, con-tend with issues related
to computational complexity and the management of dynamic objects. This study
extends our prior research, presenting innovative strategies for ego-motion
estima-tion and the selection of ground points. Striving for a nuanced
equilibrium between computational efficiency and precision, we propose a hybrid
method that leverages the SegNeXt model for real-time applications,
encompassing both ego-motion estimation and ground point selection. Our
methodology incorporates dy-namic object masks to eliminate unstable features
and employs ground plane masks for meticulous triangulation. Furthermore, we
exploit Geometry-constraint to delineate road regions for scale recovery. The
integration of this approach with the mo-nocular version of ORB-SLAM3
culminates in the accurate esti-mation of a road model, a pivotal component in
our scale recov-ery process. Rigorous experiments, conducted on the KITTI
da-taset, systematically compare our method with existing monocu-lar visual
odometry algorithms and contemporary scale recovery methodologies. The results
undeniably confirm the superior ef-fectiveness of our approach, surpassing
state-of-the-art visual odometry algorithms. Our source code is available at
https://git hub.com/bFr0zNq/MVOSegScale.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Synthetic Data is an Elegant GIFT for Continual Vision-Language Models <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04229v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04229v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Wu, Wuxuan Shi, Jinqiao Wang, Mang Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained Vision-Language Models (VLMs) require Continual Learning (CL) to
efficiently update their knowledge and adapt to various downstream tasks
without retraining from scratch. However, for VLMs, in addition to the loss of
knowledge previously learned from downstream tasks, pre-training knowledge is
also corrupted during continual fine-tuning. This issue is exacerbated by the
unavailability of original pre-training data, leaving VLM's generalization
ability degrading. In this paper, we propose GIFT, a novel continual
fine-tuning approach that utilizes synthetic data to overcome catastrophic
forgetting in VLMs. Taking advantage of recent advances in text-to-image
synthesis, we employ a pre-trained diffusion model to recreate both
pre-training and learned downstream task data. In this way, the VLM can revisit
previous knowledge through distillation on matching diffusion-generated images
and corresponding text prompts. Leveraging the broad distribution and high
alignment between synthetic image-text pairs in VLM's feature space, we propose
a contrastive distillation loss along with an image-text alignment constraint.
To further combat in-distribution overfitting and enhance distillation
performance with limited amount of generated data, we incorporate adaptive
weight consolidation, utilizing Fisher information from these synthetic
image-text pairs and achieving a better stability-plasticity balance. Extensive
experiments demonstrate that our method consistently outperforms previous
state-of-the-art approaches across various settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work is accepted by CVPR 2025. Modifications may be performed</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spiking Meets Attention: Efficient Remote Sensing Image Super-Resolution
  with Attention Spiking Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04223v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04223v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Xiao, Qiangqiang Yuan, Kui Jiang, Qiang Zhang, Tingting Zheng, Chia-Wen Lin, Liangpei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking neural networks (SNNs) are emerging as a promising alternative to
traditional artificial neural networks (ANNs), offering biological plausibility
and energy efficiency. Despite these merits, SNNs are frequently hampered by
limited capacity and insufficient representation power, yet remain
underexplored in remote sensing super-resolution (SR) tasks. In this paper, we
first observe that spiking signals exhibit drastic intensity variations across
diverse textures, highlighting an active learning state of the neurons. This
observation motivates us to apply SNNs for efficient SR of RSIs. Inspired by
the success of attention mechanisms in representing salient information, we
devise the spiking attention block (SAB), a concise yet effective component
that optimizes membrane potentials through inferred attention weights, which,
in turn, regulates spiking activity for superior feature representation. Our
key contributions include: 1) we bridge the independent modulation between
temporal and channel dimensions, facilitating joint feature correlation
learning, and 2) we access the global self-similar patterns in large-scale
remote sensing imagery to infer spatial attention weights, incorporating
effective priors for realistic and faithful reconstruction. Building upon SAB,
we proposed SpikeSR, which achieves state-of-the-art performance across various
remote sensing benchmarks such as AID, DOTA, and DIOR, while maintaining high
computational efficiency. The code of SpikeSR will be available upon paper
acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Energy-Guided Optimization for Personalized Image Editing with
  <span class="highlight-title">Pretrain</span>ed Text-to-Image Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04215v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04215v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Jiang, Xinghe Fu, Guangcong Zheng, Teng Li, Taiping Yao, Xi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of pretrained text-driven diffusion models has
significantly enriched applications in image generation and editing. However,
as the demand for personalized content editing increases, new challenges emerge
especially when dealing with arbitrary objects and complex scenes. Existing
methods usually mistakes mask as the object shape prior, which struggle to
achieve a seamless integration result. The mostly used inversion noise
initialization also hinders the identity consistency towards the target object.
To address these challenges, we propose a novel training-free framework that
formulates personalized content editing as the optimization of edited images in
the latent space, using diffusion models as the energy function guidance
conditioned by reference text-image pairs. A coarse-to-fine strategy is
proposed that employs text energy guidance at the early stage to achieve a
natural transition toward the target class and uses point-to-point
feature-level image energy guidance to perform fine-grained appearance
alignment with the target object. Additionally, we introduce the latent space
content composition to enhance overall identity consistency with the target.
Extensive experiments demonstrate that our method excels in object replacement
even with a large domain gap, highlighting its potential for high-quality,
personalized image editing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging the Vision-Brain Gap with an Uncertainty-Aware Blur Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04207v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04207v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haitao Wu, Qing Li, Changqing Zhang, Zhen He, Xiaomin Ying
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Can our brain signals faithfully reflect the original visual stimuli, even
including high-frequency details? Although human perceptual and cognitive
capacities enable us to process and remember visual information, these
abilities are constrained by several factors, such as limited attentional
resources and the finite capacity of visual memory. When visual stimuli are
processed by human visual system into brain signals, some information is
inevitably lost, leading to a discrepancy known as the \textbf{System GAP}.
Additionally, perceptual and cognitive dynamics, along with technical noise in
signal acquisition, degrade the fidelity of brain signals relative to the
visual stimuli, known as the \textbf{Random GAP}. When encoded brain
representations are directly aligned with the corresponding pretrained image
features, the System GAP and Random GAP between paired data challenge the
model, requiring it to bridge these gaps. However, in the context of limited
paired data, these gaps are difficult for the model to learn, leading to
overfitting and poor generalization to new data. To address these GAPs, we
propose a simple yet effective approach called the \textbf{Uncertainty-aware
Blur Prior (UBP)}. It estimates the uncertainty within the paired data,
reflecting the mismatch between brain signals and visual stimuli. Based on this
uncertainty, UBP dynamically blurs the high-frequency details of the original
images, reducing the impact of the mismatch and improving alignment. Our method
achieves a top-1 accuracy of \textbf{50.9\%} and a top-5 accuracy of
\textbf{79.7\%} on the zero-shot brain-to-image retrieval task, surpassing
previous state-of-the-art methods by margins of \textbf{13.7\%} and
\textbf{9.8\%}, respectively. Code is available at
\href{https://github.com/HaitaoWuTJU/Uncertainty-aware-Blur-Prior}{GitHub}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning 3D Medical Image Models From Brain Functional Connectivity
  Network Supervision For Mental Disorder Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingcan Hu, Wei Wang, Li Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In MRI-based mental disorder diagnosis, most previous studies focus on
functional connectivity network (FCN) derived from functional MRI (fMRI).
However, the small size of annotated fMRI datasets restricts its wide
application. Meanwhile, structural MRIs (sMRIs), such as 3D T1-weighted (T1w)
MRI, which are commonly used and readily accessible in clinical settings, are
often overlooked. To integrate the complementary information from both function
and structure for improved diagnostic accuracy, we propose CINP (Contrastive
Image-Network Pre-training), a framework that employs contrastive learning
between sMRI and FCN. During pre-training, we incorporate masked image modeling
and network-image matching to enhance visual representation learning and
modality alignment. Since the CINP facilitates knowledge transfer from FCN to
sMRI, we introduce network prompting. It utilizes only sMRI from suspected
patients and a small amount of FCNs from different patient classes for
diagnosing mental disorders, which is practical in real-world clinical
scenario. The competitive performance on three mental disorder diagnosis tasks
demonstrate the effectiveness of the CINP in integrating multimodal MRI
information, as well as the potential of incorporating sMRI into clinical
diagnosis using network prompting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FUSE: First-Order and Second-Order Unified SynthEsis in Stochastic
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04204v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04204v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhanhong Jiang, Md Zahid Hasan, Aditya Balu, Joshua R. Waite, Genyi Huang, Soumik Sarkar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic optimization methods have actively been playing a critical role in
modern machine learning algorithms to deliver decent performance. While
numerous works have proposed and developed diverse approaches, first-order and
second-order methods are in entirely different situations. The former is
significantly pivotal and dominating in emerging deep learning but only leads
convergence to a stationary point. However, second-order methods are less
popular due to their computational intensity in large-dimensional problems.
This paper presents a novel method that leverages both the first-order and
second-order methods in a unified algorithmic framework, termed FUSE, from
which a practical version (PV) is derived accordingly. FUSE-PV stands as a
simple yet efficient optimization method involving a switch-over between first
and second orders. Additionally, we develop different criteria that determine
when to switch. FUSE-PV has provably shown a smaller computational complexity
than SGD and Adam. To validate our proposed scheme, we present an ablation
study on several simple test functions and show a comparison with baselines for
benchmark datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MASTER: Multimodal Segmentation with Text <span class="highlight-title">Prompt</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04199v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04199v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fuyang Liu, Shun Lu, Jilin Mei, Yu Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  RGB-Thermal fusion is a potential solution for various weather and light
conditions in challenging scenarios. However, plenty of studies focus on
designing complex modules to fuse different modalities. With the widespread
application of large language models (LLMs), valuable information can be more
effectively extracted from natural language. Therefore, we aim to leverage the
advantages of large language models to design a structurally simple and highly
adaptable multimodal fusion model architecture. We proposed MultimodAl
Segmentation with TExt PRompts (MASTER) architecture, which integrates LLM into
the fusion of RGB-Thermal multimodal data and allows complex query text to
participate in the fusion process. Our model utilizes a dual-path structure to
extract information from different modalities of images. Additionally, we
employ LLM as the core module for multimodal fusion, enabling the model to
generate learnable codebook tokens from RGB, thermal images, and textual
information. A lightweight image decoder is used to obtain semantic
segmentation results. The proposed MASTER performs exceptionally well in
benchmark tests across various automated driving scenarios, yielding promising
results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformal forecasting for surgical instrument trajectory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Sangalli, Gary Sarwin, Ertunc Erdil, Carlo Serra, Ender Konukoglu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Forecasting surgical instrument trajectories and predicting the next surgical
action recently started to attract attention from the research community. Both
these tasks are crucial for automation and assistance in endoscopy surgery.
Given the safety-critical nature of these tasks, reliable uncertainty
quantification is essential. Conformal prediction is a fast-growing and widely
recognized framework for uncertainty estimation in machine learning and
computer vision, offering distribution-free, theoretically valid prediction
intervals. In this work, we explore the application of standard conformal
prediction and conformalized quantile regression to estimate uncertainty in
forecasting surgical instrument motion, i.e., predicting direction and
magnitude of surgical instruments' future motion. We analyze and compare their
coverage and interval sizes, assessing the impact of multiple hypothesis
testing and correction methods. Additionally, we show how these techniques can
be employed to produce useful uncertainty heatmaps. To the best of our
knowledge, this is the first study applying conformal prediction to surgical
guidance, marking an initial step toward constructing principled prediction
intervals with formal coverage guarantees in this domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DuCos: Duality Constrained Depth Super-Resolution via Foundation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04171v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04171v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiqiang Yan, Zhengxue Wang, Haoye Dong, Jun Li, Jian Yang, Gim Hee Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce DuCos, a novel depth super-resolution framework grounded in
Lagrangian duality theory, offering a flexible integration of multiple
constraints and reconstruction objectives to enhance accuracy and robustness.
Our DuCos is the first to significantly improve generalization across diverse
scenarios with foundation models as prompts. The prompt design consists of two
key components: Correlative Fusion (CF) and Gradient Regulation (GR). CF
facilitates precise geometric alignment and effective fusion between prompt and
depth features, while GR refines depth predictions by enforcing consistency
with sharp-edged depth maps derived from foundation models. Crucially, these
prompts are seamlessly embedded into the Lagrangian constraint term, forming a
synergistic and principled framework. Extensive experiments demonstrate that
DuCos outperforms existing state-of-the-art methods, achieving superior
accuracy, robustness, and generalization. The source codes and pre-trained
models will be publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Role of Visual Modality in Multimodal Mathematical Reasoning:
  Challenges and Insights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04167v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04167v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yufang Liu, Yao Du, Tao Ji, Jianing Wang, Yang Liu, Yuanbin Wu, Aimin Zhou, Mengdi Zhang, Xunliang Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research has increasingly focused on multimodal mathematical
reasoning, particularly emphasizing the creation of relevant datasets and
benchmarks. Despite this, the role of visual information in reasoning has been
underexplored. Our findings show that existing multimodal mathematical models
minimally leverage visual information, and model performance remains largely
unaffected by changes to or removal of images in the dataset. We attribute this
to the dominance of textual information and answer options that inadvertently
guide the model to correct answers. To improve evaluation methods, we introduce
the HC-M3D dataset, specifically designed to require image reliance for
problem-solving and to challenge models with similar, yet distinct, images that
change the correct answer. In testing leading models, their failure to detect
these subtle visual differences suggests limitations in current visual
perception capabilities. Additionally, we observe that the common approach of
improving general VQA capabilities by combining various types of image encoders
does not contribute to math reasoning performance. This finding also presents a
challenge to enhancing visual reliance during math reasoning. Our benchmark and
code would be available at
\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\_modality\_role}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WeakSupCon: Weakly Supervised Contrastive Learning for Encoder
  <span class="highlight-title">Pre-train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04165v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04165v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bodong Zhang, Hamid Manoochehri, Beatrice S. Knudsen, Tolga Tasdizen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly supervised multiple instance learning (MIL) is a challenging task
given that only bag-level labels are provided, while each bag typically
contains multiple instances. This topic has been extensively studied in
histopathological image analysis, where labels are usually available only at
the whole slide image (WSI) level, while each whole slide image can be divided
into thousands of small image patches for training. The dominant MIL approaches
take fixed patch features as inputs to address computational constraints and
ensure model stability. These features are commonly generated by encoders
pre-trained on ImageNet, foundation encoders pre-trained on large datasets, or
through self-supervised learning on local datasets. While the self-supervised
encoder pre-training on the same dataset as downstream MIL tasks helps mitigate
domain shift and generate better features, the bag-level labels are not
utilized during the process, and the features of patches from different
categories may cluster together, reducing classification performance on MIL
tasks. Recently, pre-training with supervised contrastive learning (SupCon) has
demonstrated superior performance compared to self-supervised contrastive
learning and even end-to-end training on traditional image classification
tasks. In this paper, we propose a novel encoder pre-training method for
downstream MIL tasks called Weakly Supervised Contrastive Learning (WeakSupCon)
that utilizes bag-level labels. In our method, we employ multi-task learning
and define distinct contrastive learning losses for samples with different bag
labels. Our experiments demonstrate that the features generated using
WeakSupCon significantly enhance MIL classification performance compared to
self-supervised approaches across three datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised
  Monocular 3D Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chupeng Liu, Runkai Zhao, Weidong Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly supervised monocular 3D detection, while less annotation-intensive,
often struggles to capture the global context required for reliable 3D
reasoning. Conventional label-efficient methods focus on object-centric
features, neglecting contextual semantic relationships that are critical in
complex scenes. In this work, we propose a Context-Aware Weak Supervision for
Monocular 3D object detection, namely CA-W3D, to address this limitation in a
two-stage training paradigm. Specifically, we first introduce a pre-training
stage employing Region-wise Object Contrastive Matching (ROCM), which aligns
regional object embeddings derived from a trainable monocular 3D encoder and a
frozen open-vocabulary 2D visual grounding model. This alignment encourages the
monocular encoder to discriminate scene-specific attributes and acquire richer
contextual knowledge. In the second stage, we incorporate a pseudo-label
training process with a Dual-to-One Distillation (D2OD) mechanism, which
effectively transfers contextual priors into the monocular encoder while
preserving spatial fidelity and maintaining computational efficiency during
inference. Extensive experiments conducted on the public KITTI benchmark
demonstrate the effectiveness of our approach, surpassing the SoTA method over
all metrics, highlighting the importance of contextual-aware knowledge in
weakly-supervised monocular 3D detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper includes 8 pages, 6 figures and 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Multi-View Learning via Representation Fusion of Sample-Level
  Attention and Alignment of Simulated Perturbation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Xu, Na Zhao, Gang Niu, Masashi Sugiyama, Xiaofeng Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, multi-view learning (MVL) has garnered significant attention due to
its ability to fuse discriminative information from multiple views. However,
real-world multi-view datasets are often heterogeneous and imperfect, which
usually makes MVL methods designed for specific combinations of views lack
application potential and limits their effectiveness. To address this issue, we
propose a novel robust MVL method (namely RML) with simultaneous representation
fusion and alignment. Specifically, we introduce a simple yet effective
multi-view transformer fusion network where we transform heterogeneous
multi-view data into homogeneous word embeddings, and then integrate multiple
views by the sample-level attention mechanism to obtain a fused representation.
Furthermore, we propose a simulated perturbation based multi-view contrastive
learning framework that dynamically generates the noise and unusable
perturbations for simulating imperfect data conditions. The simulated noisy and
unusable data obtain two distinct fused representations, and we utilize
contrastive learning to align them for learning discriminative and robust
representations. Our RML is self-supervised and can also be applied for
downstream tasks as a regularization. In experiments, we employ it in
unsupervised multi-view clustering, noise-label classification, and as a
plug-and-play module for cross-modal hashing retrieval. Extensive comparison
experiments and ablation studies validate the effectiveness of RML.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person
  Retrieval <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04144v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04144v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yating Liu, Zimo Liu, Xiangyuan Lan, Wenming Yang, Yaowei Li, Qingmin Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-based person retrieval (TPR) has gained significant attention as a
fine-grained and challenging task that closely aligns with practical
applications. Tailoring CLIP to person domain is now a emerging research topic
due to the abundant knowledge of vision-language pretraining, but challenges
still remain during fine-tuning: (i) Previous full-model fine-tuning in TPR is
computationally expensive and prone to overfitting.(ii) Existing
parameter-efficient transfer learning (PETL) for TPR lacks of fine-grained
feature extraction. To address these issues, we propose Domain-Aware
Mixture-of-Adapters (DM-Adapter), which unifies Mixture-of-Experts (MOE) and
PETL to enhance fine-grained feature representations while maintaining
efficiency. Specifically, Sparse Mixture-of-Adapters is designed in parallel to
MLP layers in both vision and language branches, where different experts
specialize in distinct aspects of person knowledge to handle features more
finely. To promote the router to exploit domain information effectively and
alleviate the routing imbalance, Domain-Aware Router is then developed by
building a novel gating function and injecting learnable domain-aware prompts.
Extensive experiments show that our DM-Adapter achieves state-of-the-art
performance, outperforming previous methods by a significant margin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 5 figures, accepted by AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Computer-Vision based Construction Site Detection for
  Assistive-Technology Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04139v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04139v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junchi Feng, Giles Hamilton-Fletcher, Nikhil Ballem, Michael Batavia, Yifei Wang, Jiuling Zhong, Maurizio Porfiri, John-Ross Rizzo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Navigating urban environments poses significant challenges for people with
disabilities, particularly those with blindness and low vision. Environments
with dynamic and unpredictable elements like construction sites are especially
challenging. Construction sites introduce hazards like uneven surfaces,
obstructive barriers, hazardous materials, and excessive noise, and they can
alter routing, complicating safe mobility. Existing assistive technologies are
limited, as navigation apps do not account for construction sites during trip
planning, and detection tools that attempt hazard recognition struggle to
address the extreme variability of construction paraphernalia. This study
introduces a novel computer vision-based system that integrates open-vocabulary
object detection, a YOLO-based scaffolding-pole detection model, and an optical
character recognition (OCR) module to comprehensively identify and interpret
construction site elements for assistive navigation. In static testing across
seven construction sites, the system achieved an overall accuracy of 88.56\%,
reliably detecting objects from 2m to 10m within a 0$^\circ$ -- 75$^\circ$
angular offset. At closer distances (2--4m), the detection rate was 100\% at
all tested angles. At
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-time Spatial-temporal Traversability Assessment via Feature-based
  Sparse Gaussian Process 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04134v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04134v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Senming Tan, Zhenyu Hou, Zhihao Zhang, Long Xu, Mengke Zhang, Zhaoqi He, Chao Xu, Fei Gao, Yanjun Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Terrain analysis is critical for the practical application of ground mobile
robots in real-world tasks, especially in outdoor unstructured environments. In
this paper, we propose a novel spatial-temporal traversability assessment
method, which aims to enable autonomous robots to effectively navigate through
complex terrains. Our approach utilizes sparse Gaussian processes (SGP) to
extract geometric features (curvature, gradient, elevation, etc.) directly from
point cloud scans. These features are then used to construct a high-resolution
local traversability map. Then, we design a spatial-temporal Bayesian Gaussian
kernel (BGK) inference method to dynamically evaluate traversability scores,
integrating historical and real-time data while considering factors such as
slope, flatness, gradient, and uncertainty metrics. GPU acceleration is applied
in the feature extraction step, and the system achieves real-time performance.
Extensive simulation experiments across diverse terrain scenarios demonstrate
that our method outperforms SOTA approaches in both accuracy and computational
efficiency. Additionally, we develop an autonomous navigation framework
integrated with the traversability map and validate it with a differential
driven vehicle in complex outdoor environments. Our code will be open-source
for further research and development by the community,
https://github.com/ZJU-FAST-Lab/FSGP_BGK.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Q-PART: Quasi-Periodic Adaptive Regression with Test-time Training for
  Pediatric Left Ventricular Ejection Fraction Regression <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04131v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04131v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Liu, Tiexin Qin, Hui Liu, Yilei Shi, Lichao Mou, Xiao Xiang Zhu, Shiqi Wang, Haoliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we address the challenge of adaptive pediatric Left Ventricular
Ejection Fraction (LVEF) assessment. While Test-time Training (TTT) approaches
show promise for this task, they suffer from two significant limitations.
Existing TTT works are primarily designed for classification tasks rather than
continuous value regression, and they lack mechanisms to handle the
quasi-periodic nature of cardiac signals. To tackle these issues, we propose a
novel \textbf{Q}uasi-\textbf{P}eriodic \textbf{A}daptive \textbf{R}egression
with \textbf{T}est-time Training (Q-PART) framework. In the training stage, the
proposed Quasi-Period Network decomposes the echocardiogram into periodic and
aperiodic components within latent space by combining parameterized helix
trajectories with Neural Controlled Differential Equations. During inference,
our framework further employs a variance minimization strategy across image
augmentations that simulate common quality issues in echocardiogram
acquisition, along with differential adaptation rates for periodic and
aperiodic components. Theoretical analysis is provided to demonstrate that our
variance minimization objective effectively bounds the regression error under
mild conditions. Furthermore, extensive experiments across three pediatric age
groups demonstrate that Q-PART not only significantly outperforms existing
approaches in pediatric LVEF prediction, but also exhibits strong clinical
screening capability with high mAUROC scores (up to 0.9747) and maintains
gender-fair performance across all metrics, validating its robustness and
practical utility in pediatric echocardiography analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Token-Efficient Long Video Understanding for Multimodal LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jindong Jiang, Xiuyu Li, Zhijian Liu, Muyang Li, Guo Chen, Zhiqi Li, De-An Huang, Guilin Liu, Zhiding Yu, Kurt Keutzer, Sungjin Ahn, Jan Kautz, Hongxu Yin, Yao Lu, Song Han, Wonmin Byeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in video-based multimodal large language models (Video-LLMs)
have significantly improved video understanding by processing videos as
sequences of image frames. However, many existing methods treat frames
independently in the vision backbone, lacking explicit temporal modeling, which
limits their ability to capture dynamic patterns and efficiently handle long
videos. To address these limitations, we introduce STORM
(\textbf{S}patiotemporal \textbf{TO}ken \textbf{R}eduction for
\textbf{M}ultimodal LLMs), a novel architecture incorporating a dedicated
temporal encoder between the image encoder and the LLM. Our temporal encoder
leverages the Mamba State Space Model to integrate temporal information into
image tokens, generating enriched representations that preserve inter-frame
dynamics across the entire video sequence. This enriched encoding not only
enhances video reasoning capabilities but also enables effective token
reduction strategies, including test-time sampling and training-based temporal
and spatial pooling, substantially reducing computational demands on the LLM
without sacrificing key temporal information. By integrating these techniques,
our approach simultaneously reduces training and inference latency while
improving performance, enabling efficient and robust video understanding over
extended temporal contexts. Extensive evaluations show that STORM achieves
state-of-the-art results across various long video understanding benchmarks
(more than 5\% improvement on MLVU and LongVideoBench) while reducing the
computation costs by up to $8\times$ and the decoding latency by
2.4-2.9$\times$ for the fixed numbers of input frames. Project page is
available at https://research.nvidia.com/labs/lpr/storm
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diff-Reg v2: Diffusion-Based Matching Matrix Estimation for Image
  Matching and 3D Registration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04127v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04127v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianliang Wu, Haobo Jiang, Yaqing Ding, Lei Luo, Jin Xie, Jian Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Establishing reliable correspondences is crucial for all registration tasks,
including 2D image registration, 3D point cloud registration, and 2D-3D
image-to-point cloud registration. However, these tasks are often complicated
by challenges such as scale inconsistencies, symmetry, and large deformations,
which can lead to ambiguous matches. Previous feature-based and
correspondence-based methods typically rely on geometric or semantic features
to generate or polish initial potential correspondences. Some methods typically
leverage specific geometric priors, such as topological preservation, to devise
diverse and innovative strategies tailored to a given enhancement goal, which
cannot be exhaustively enumerated. Additionally, many previous approaches rely
on a single-step prediction head, which can struggle with local minima in
complex matching scenarios. To address these challenges, we introduce an
innovative paradigm that leverages a diffusion model in matrix space for robust
matching matrix estimation. Our model treats correspondence estimation as a
denoising diffusion process in the matching matrix space, gradually refining
the intermediate matching matrix to the optimal one. Specifically, we apply the
diffusion model in the doubly stochastic matrix space for 3D-3D and 2D-3D
registration tasks. In the 2D image registration task, we deploy the diffusion
model in a matrix subspace where dual-softmax projection regularization is
applied. For all three registration tasks, we provide adaptive matching matrix
embedding implementations tailored to the specific characteristics of each task
while maintaining a consistent "match-to-warp" encoding pattern. Furthermore,
we adopt a lightweight design for the denoising module. In inference, once
points or image features are extracted and fixed, this module performs
multi-step denoising predictions through reverse sampling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2403.19919</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DVM-SLAM: Decentralized Visual Monocular Simultaneous Localization and
  Mapping for Multi-Agent Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04126v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04126v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Bird, Jan Blumenkamp, Amanda Prorok
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cooperative Simultaneous Localization and Mapping (C-SLAM) enables multiple
agents to work together in mapping unknown environments while simultaneously
estimating their own positions. This approach enhances robustness, scalability,
and accuracy by sharing information between agents, reducing drift, and
enabling collective exploration of larger areas. In this paper, we present
Decentralized Visual Monocular SLAM (DVM-SLAM), the first open-source
decentralized monocular C-SLAM system. By only utilizing low-cost and
light-weight monocular vision sensors, our system is well suited for small
robots and micro aerial vehicles (MAVs). DVM-SLAM's real-world applicability is
validated on physical robots with a custom collision avoidance framework,
showcasing its potential in real-time multi-agent autonomous navigation
scenarios. We also demonstrate comparable accuracy to state-of-the-art
centralized monocular C-SLAM systems. We open-source our code and provide
supplementary material online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GAGrasp: Geometric Algebra Diffusion for Dexterous Grasping <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04123v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04123v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Zhong, Christine Allen-Blanchette
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose GAGrasp, a novel framework for dexterous grasp generation that
leverages geometric algebra representations to enforce equivariance to SE(3)
transformations. By encoding the SE(3) symmetry constraint directly into the
architecture, our method improves data and parameter efficiency while enabling
robust grasp generation across diverse object poses. Additionally, we
incorporate a differentiable physics-informed refinement layer, which ensures
that generated grasps are physically plausible and stable. Extensive
experiments demonstrate the model's superior performance in generalization,
stability, and adaptability compared to existing methods. Additional details at
https://gagrasp.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simple Self Organizing Map with Visual <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04121v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04121v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alan Luo, Kaiwen Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Transformers (ViTs) have demonstrated exceptional performance in
various vision tasks. However, they tend to underperform on smaller datasets
due to their inherent lack of inductive biases. Current approaches address this
limitation implicitly-often by pairing ViTs with pretext tasks or by distilling
knowledge from convolutional neural networks (CNNs) to strengthen the prior. In
contrast, Self-Organizing Maps (SOMs), a widely adopted self-supervised
framework, are inherently structured to preserve topology and spatial
organization, making them a promising candidate to directly address the
limitations of ViTs in limited or small training datasets. Despite this
potential, equipping SOMs with modern deep learning architectures remains
largely unexplored. In this study, we conduct a novel exploration on how Vision
Transformers (ViTs) and Self-Organizing Maps (SOMs) can empower each other,
aiming to bridge this critical research gap. Our findings demonstrate that
these architectures can synergistically enhance each other, leading to
significantly improved performance in both unsupervised and supervised tasks.
Code will be publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures. Submitted to IEEE. All experiments and code work
  were performed by the first author, with the second author serving in a
  PI/mentor role, guiding the progression of the work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SCSA: A Plug-and-Play Semantic Continuous-Sparse Attention for Arbitrary
  Semantic Style Transfer <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04119v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04119v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunnan Shang, Zhizhong Wang, Hongwei Wang, Xiangming Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Attention-based arbitrary style transfer methods, including CNN-based,
Transformer-based, and Diffusion-based, have flourished and produced
high-quality stylized images. However, they perform poorly on the content and
style images with the same semantics, i.e., the style of the corresponding
semantic region of the generated stylized image is inconsistent with that of
the style image. We argue that the root cause lies in their failure to consider
the relationship between local regions and semantic regions. To address this
issue, we propose a plug-and-play semantic continuous-sparse attention, dubbed
SCSA, for arbitrary semantic style transfer -- each query point considers
certain key points in the corresponding semantic region. Specifically, semantic
continuous attention ensures each query point fully attends to all the
continuous key points in the same semantic region that reflect the overall
style characteristics of that region; Semantic sparse attention allows each
query point to focus on the most similar sparse key point in the same semantic
region that exhibits the specific stylistic texture of that region. By
combining the two modules, the resulting SCSA aligns the overall style of the
corresponding semantic regions while transferring the vivid textures of these
regions. Qualitative and quantitative results prove that SCSA enables
attention-based arbitrary style transfer methods to produce high-quality
semantic stylized images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fractional Correspondence Framework in Detection <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04107v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04107v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masoumeh Zareapoor, Pourya Shamsolmoali, Huiyu Zhou, Yue Lu, Salvador García
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Detection Transformer (DETR), by incorporating the Hungarian algorithm,
has significantly simplified the matching process in object detection tasks.
This algorithm facilitates optimal one-to-one matching of predicted bounding
boxes to ground-truth annotations during training. While effective, this strict
matching process does not inherently account for the varying densities and
distributions of objects, leading to suboptimal correspondences such as failing
to handle multiple detections of the same object or missing small objects. To
address this, we propose the Regularized Transport Plan (RTP). RTP introduces a
flexible matching strategy that captures the cost of aligning predictions with
ground truths to find the most accurate correspondences between these sets. By
utilizing the differentiable Sinkhorn algorithm, RTP allows for soft,
fractional matching rather than strict one-to-one assignments. This approach
enhances the model's capability to manage varying object densities and
distributions effectively. Our extensive evaluations on the MS-COCO and VOC
benchmarks demonstrate the effectiveness of our approach. RTP-DETR, surpassing
the performance of the Deform-DETR and the recently introduced DINO-DETR,
achieving absolute gains in mAP of +3.8% and +1.7%, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WeakMedSAM: Weakly-Supervised Medical Image Segmentation via SAM with
  Sub-Class Exploration and <span class="highlight-title">Prompt</span> Affinity Mining 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04106v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04106v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Wang, Lian Huai, Wenbin Li, Lei Qi, Xingqun Jiang, Yinghuan Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We have witnessed remarkable progress in foundation models in vision tasks.
Currently, several recent works have utilized the segmenting anything model
(SAM) to boost the segmentation performance in medical images, where most of
them focus on training an adaptor for fine-tuning a large amount of pixel-wise
annotated medical images following a fully supervised manner. In this paper, to
reduce the labeling cost, we investigate a novel weakly-supervised SAM-based
segmentation model, namely WeakMedSAM. Specifically, our proposed WeakMedSAM
contains two modules: 1) to mitigate severe co-occurrence in medical images, a
sub-class exploration module is introduced to learn accurate feature
representations. 2) to improve the quality of the class activation maps, our
prompt affinity mining module utilizes the prompt capability of SAM to obtain
an affinity map for random-walk refinement. Our method can be applied to any
SAM-like backbone, and we conduct experiments with SAMUS and EfficientSAM. The
experimental results on three popularly-used benchmark datasets, i.e., BraTS
2019, AbdomenCT-1K, and MSD Cardiac dataset, show the promising results of our
proposed WeakMedSAM. Our code is available at
https://github.com/wanghr64/WeakMedSAM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Image-Based Relocalization and Alignment for Long-Term Monitoring of
  Dynamic Underwater Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04096v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04096v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Beverley Gorry, Tobias Fischer, Michael Milford, Alejandro Fontan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective monitoring of underwater ecosystems is crucial for tracking
environmental changes, guiding conservation efforts, and ensuring long-term
ecosystem health. However, automating underwater ecosystem management with
robotic platforms remains challenging due to the complexities of underwater
imagery, which pose significant difficulties for traditional visual
localization methods. We propose an integrated pipeline that combines Visual
Place Recognition (VPR), feature matching, and image segmentation on
video-derived images. This method enables robust identification of revisited
areas, estimation of rigid transformations, and downstream analysis of
ecosystem changes. Furthermore, we introduce the SQUIDLE+ VPR Benchmark-the
first large-scale underwater VPR benchmark designed to leverage an extensive
collection of unstructured data from multiple robotic platforms, spanning time
intervals from days to years. The dataset encompasses diverse trajectories,
arbitrary overlap and diverse seafloor types captured under varying
environmental conditions, including differences in depth, lighting, and
turbidity. Our code is available at: https://github.com/bev-gorry/underloc
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Brain Tumor Detection in MRI Based on Federated Learning with YOLOv11 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04087v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04087v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheikh Moonwara Anjum Monisha, Ratun Rahman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the primary challenges in medical diagnostics is the accurate and
efficient use of magnetic resonance imaging (MRI) for the detection of brain
tumors. But the current machine learning (ML) approaches have two major
limitations, data privacy and high latency. To solve the problem, in this work
we propose a federated learning architecture for a better accurate brain tumor
detection incorporating the YOLOv11 algorithm. In contrast to earlier methods
of centralized learning, our federated learning approach protects the
underlying medical data while supporting cooperative deep learning model
training across multiple institutions. To allow the YOLOv11 model to locate and
identify tumor areas, we adjust it to handle MRI data. To ensure robustness and
generalizability, the model is trained and tested on a wide range of MRI data
collected from several anonymous medical facilities. The results indicate that
our method significantly maintains higher accuracy than conventional
approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instrument-Splatting: Controllable Photorealistic Reconstruction of
  Surgical Instruments Using Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04082v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04082v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuojue Yang, Zijian Wu, Mingxuan Hong, Qian Li, Daiyun Shen, Septimiu E. Salcudean, Yueming Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real2Sim is becoming increasingly important with the rapid development of
surgical artificial intelligence (AI) and autonomy. In this work, we propose a
novel Real2Sim methodology, \textit{Instrument-Splatting}, that leverages 3D
Gaussian Splatting to provide fully controllable 3D reconstruction of surgical
instruments from monocular surgical videos. To maintain both high visual
fidelity and manipulability, we introduce a geometry pre-training to bind
Gaussian point clouds on part mesh with accurate geometric priors and define a
forward kinematics to control the Gaussians as flexible as real instruments.
Afterward, to handle unposed videos, we design a novel instrument pose tracking
method leveraging semantics-embedded Gaussians to robustly refine per-frame
instrument poses and joint states in a render-and-compare manner, which allows
our instrument Gaussian to accurately learn textures and reach photorealistic
rendering. We validated our method on 2 publicly released surgical videos and 4
videos collected on ex vivo tissues and green screens. Quantitative and
qualitative evaluations demonstrate the effectiveness and superiority of the
proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Surgical Gaussian Surfels: Highly Accurate Real-time Surgical Scene
  Rendering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04079v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04079v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Idris O. Sunmola, Zhenjun Zhao, Samuel Schmidgall, Yumeng Wang, Paul Maria Scheikl, Axel Krieger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate geometric reconstruction of deformable tissues in monocular
endoscopic video remains a fundamental challenge in robot-assisted minimally
invasive surgery. Although recent volumetric and point primitive methods based
on neural radiance fields (NeRF) and 3D Gaussian primitives have efficiently
rendered surgical scenes, they still struggle with handling artifact-free tool
occlusions and preserving fine anatomical details. These limitations stem from
unrestricted Gaussian scaling and insufficient surface alignment constraints
during reconstruction. To address these issues, we introduce Surgical Gaussian
Surfels (SGS), which transforms anisotropic point primitives into
surface-aligned elliptical splats by constraining the scale component of the
Gaussian covariance matrix along the view-aligned axis. We predict accurate
surfel motion fields using a lightweight Multi-Layer Perceptron (MLP) coupled
with locality constraints to handle complex tissue deformations. We use
homodirectional view-space positional gradients to capture fine image details
by splitting Gaussian Surfels in over-reconstructed regions. In addition, we
define surface normals as the direction of the steepest density change within
each Gaussian surfel primitive, enabling accurate normal estimation without
requiring monocular normal priors. We evaluate our method on two in-vivo
surgical datasets, where it outperforms current state-of-the-art methods in
surface geometry, normal map quality, and rendering efficiency, while remaining
competitive in real-time rendering performance. We make our code available at
https://github.com/aloma85/SurgicalGaussianSurfels
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spatial-Temporal Perception with Causal Inference for Naturalistic
  Driving Action Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qing Chang, Wei Dai, Zhihao Shuai, Limin Yu, Yutao Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Naturalistic driving action recognition is essential for vehicle cabin
monitoring systems. However, the complexity of real-world backgrounds presents
significant challenges for this task, and previous approaches have struggled
with practical implementation due to their limited ability to observe subtle
behavioral differences and effectively learn inter-frame features from video.
In this paper, we propose a novel Spatial-Temporal Perception (STP)
architecture that emphasizes both temporal information and spatial
relationships between key objects, incorporating a causal decoder to perform
behavior recognition and temporal action localization. Without requiring
multimodal input, STP directly extracts temporal and spatial distance features
from RGB video clips. Subsequently, these dual features are jointly encoded by
maximizing the expected likelihood across all possible permutations of the
factorization order. By integrating temporal and spatial features at different
scales, STP can perceive subtle behavioral changes in challenging scenarios.
Additionally, we introduce a causal-aware module to explore relationships
between video frame features, significantly enhancing detection efficiency and
performance. We validate the effectiveness of our approach using two publicly
available driver distraction detection benchmarks. The results demonstrate that
our framework achieves state-of-the-art performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven
  Talking Portrait Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04067v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04067v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqi Ni, Ao Fu, Yi Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving high-fidelity lip-speech synchronization in audio-driven talking
portrait synthesis remains challenging. While multi-stage pipelines or
diffusion models yield high-quality results, they suffer from high
computational costs. Some approaches perform well on specific individuals with
low resources, yet still exhibit mismatched lip movements. The aforementioned
methods are modeled in the pixel domain. We observed that there are noticeable
discrepancies in the frequency domain between the synthesized talking videos
and natural videos. Currently, no research on talking portrait synthesis has
considered this aspect. To address this, we propose a FREquency-modulated,
high-fidelity, and real-time Audio-driven talKing portrait synthesis framework,
named FREAK, which models talking portraits from the frequency domain
perspective, enhancing the fidelity and naturalness of the synthesized
portraits. FREAK introduces two novel frequency-based modules: 1) the Visual
Encoding Frequency Modulator (VEFM) to couple multi-scale visual features in
the frequency domain, better preserving visual frequency information and
reducing the gap in the frequency spectrum between synthesized and natural
frames. and 2) the Audio Visual Frequency Modulator (AVFM) to help the model
learn the talking pattern in the frequency domain and improve audio-visual
synchronization. Additionally, we optimize the model in both pixel domain and
frequency domain jointly. Furthermore, FREAK supports seamless switching
between one-shot and video dubbing settings, offering enhanced flexibility. Due
to its superior performance, it can simultaneously support high-resolution
video results and real-time inference. Extensive experiments demonstrate that
our method synthesizes high-fidelity talking portraits with detailed facial
textures and precise lip synchronization in real-time, outperforming
state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PP-DocBee: Improving Multimodal Document Understanding Through a Bag of
  Tricks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feng Ni, Kui Huang, Yao Lu, Wenyu Lv, Guanzhong Wang, Zeyu Chen, Yi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of digitalization, various document images are
being applied more extensively in production and daily life, and there is an
increasingly urgent need for fast and accurate parsing of the content in
document images. Therefore, this report presents PP-DocBee, a novel multimodal
large language model designed for end-to-end document image understanding.
First, we develop a data synthesis strategy tailored to document scenarios in
which we build a diverse dataset to improve the model generalization. Then, we
apply a few training techniques, including dynamic proportional sampling, data
preprocessing, and OCR postprocessing strategies. Extensive evaluations
demonstrate the superior performance of PP-DocBee, achieving state-of-the-art
results on English document understanding benchmarks and even outperforming
existing open source and commercial models in Chinese document understanding.
The source code and pre-trained models are publicly available at
\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ H3O: Hyper-Efficient 3D Occupancy Prediction with Heterogeneous
  Supervision <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04059v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04059v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunxiao Shi, Hong Cai, Amin Ansari, Fatih Porikli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D occupancy prediction has recently emerged as a new paradigm for holistic
3D scene understanding and provides valuable information for downstream
planning in autonomous driving. Most existing methods, however, are
computationally expensive, requiring costly attention-based 2D-3D
transformation and 3D feature processing. In this paper, we present a novel 3D
occupancy prediction approach, H3O, which features highly efficient
architecture designs that incur a significantly lower computational cost as
compared to the current state-of-the-art methods. In addition, to compensate
for the ambiguity in ground-truth 3D occupancy labels, we advocate leveraging
auxiliary tasks to complement the direct 3D supervision. In particular, we
integrate multi-camera depth estimation, semantic segmentation, and surface
normal estimation via differentiable volume rendering, supervised by
corresponding 2D labels that introduces rich and heterogeneous supervision
signals. We conduct extensive experiments on the Occ3D-nuScenes and
SemanticKITTI benchmarks that demonstrate the superiority of our proposed H3O.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Systematic Weaknesses in Vision Models along Predefined
  Human-Understandable Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12360v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12360v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sujan Sai Gannamaneni, Rohil Prakash Rao, Michael Mock, Maram Akila, Stefan Wrobel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Slice discovery methods (SDMs) are prominent algorithms for finding
systematic weaknesses in DNNs. They identify top-k semantically coherent
slices/subsets of data where a DNN-under-test has low performance. For being
directly useful, slices should be aligned with human-understandable and
relevant dimensions, which, for example, are defined by safety and domain
experts as part of the operational design domain (ODD). While SDMs can be
applied effectively on structured data, their application on image data is
complicated by the lack of semantic metadata. To address these issues, we
present an algorithm that combines foundation models for zero-shot image
classification to generate semantic metadata with methods for combinatorial
search to find systematic weaknesses in images. In contrast to existing
approaches, ours identifies weak slices that are in line with pre-defined
human-understandable dimensions. As the algorithm includes foundation models,
its intermediate and final results may not always be exact. Therefore, we
include an approach to address the impact of noisy metadata. We validate our
algorithm on both synthetic and real-world datasets, demonstrating its ability
to recover human-understandable systematic weaknesses. Furthermore, using our
approach, we identify systematic weaknesses of multiple pre-trained and
publicly available state-of-the-art computer vision DNNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ZeroBench: An Impossible Visual Benchmark for Contemporary Large
  Multimodal Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09696v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09696v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Roberts, Mohammad Reza Taesiri, Ansh Sharma, Akash Gupta, Samuel Roberts, Ioana Croitoru, Simion-Vlad Bogolin, Jialu Tang, Florian Langer, Vyas Raina, Vatsal Raina, Hanyi Xiong, Vishaal Udandarao, Jingyi Lu, Shiyang Chen, Sam Purkis, Tianshuo Yan, Wenye Lin, Gyungin Shin, Qiaochu Yang, Anh Totti Nguyen, David I. Atkinson, Aaditya Baranwal, Alexandru Coca, Mikah Dang, Sebastian Dziadzio, Jakob D. Kunz, Kaiqu Liang, Alexander Lo, Brian Pulfer, Steven Walton, Charig Yang, Kai Han, Samuel Albanie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Multimodal Models (LMMs) exhibit major shortfalls when interpreting
images and, by some measures, have poorer spatial cognition than small children
or animals. Despite this, they attain high scores on many popular visual
benchmarks, with headroom rapidly eroded by an ongoing surge of model progress.
To address this, there is a pressing need for difficult benchmarks that remain
relevant for longer. We take this idea to its limit by introducing ZeroBench-a
lightweight visual reasoning benchmark that is entirely impossible for
contemporary frontier LMMs. Our benchmark consists of 100 manually curated
questions and 334 less difficult subquestions. We evaluate 20 LMMs on
ZeroBench, all of which score 0.0%, and rigorously analyse the errors. To
encourage progress in visual understanding, we publicly release ZeroBench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Back Home: A Machine Learning Approach to Seashell Classification and
  Ecosystem Restoration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04873v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04873v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Valverde, Luis Solano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Costa Rica, an average of 5 tons of seashells are extracted from
ecosystems annually. Confiscated seashells, cannot be returned to their
ecosystems due to the lack of origin recognition. To address this issue, we
developed a convolutional neural network (CNN) specifically for seashell
identification. We built a dataset from scratch, consisting of approximately
19000 images from the Pacific and Caribbean coasts. Using this dataset, the
model achieved a classification accuracy exceeding 85%. The model has been
integrated into a user-friendly application, which has classified over 36,000
seashells to date, delivering real-time results within 3 seconds per image. To
further enhance the system's accuracy, an anomaly detection mechanism was
incorporated to filter out irrelevant or anomalous inputs, ensuring only valid
seashell images are processed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Simple and Effective Reinforcement Learning Method for Text-to-Image
  Diffusion Fine-tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00897v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00897v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shashank Gupta, Chaitanya Ahuja, Tsung-Yu Lin, Sreya Dutta Roy, Harrie Oosterhuis, Maarten de Rijke, Satya Narayan Shukla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful
approach for aligning diffusion models with black-box objectives. Proximal
policy optimization (PPO) is the most popular choice of method for policy
optimization. While effective in terms of performance, PPO is highly sensitive
to hyper-parameters and involves substantial computational overhead. REINFORCE,
on the other hand, mitigates some computational complexities such as high
memory overhead and sensitive hyper-parameter tuning, but has suboptimal
performance due to high-variance and sample inefficiency. While the variance of
the REINFORCE can be reduced by sampling multiple actions per input prompt and
using a baseline correction term, it still suffers from sample inefficiency. To
address these challenges, we systematically analyze the
efficiency-effectiveness trade-off between REINFORCE and PPO, and propose
leave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP
combines variance reduction techniques from REINFORCE, such as sampling
multiple actions per input prompt and a baseline correction term, with the
robustness and sample efficiency of PPO via clipping and importance sampling.
Our results demonstrate that LOOP effectively improves diffusion models on
various black-box objectives, and achieves a better balance between
computational efficiency and performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Deep Learning-based Radiology Report Generation Using
  Multimodal Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12833v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12833v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Wang, Grazziela Figueredo, Ruizhe Li, Wei Emma Zhang, Weitong Chen, Xin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic radiology report generation can alleviate the workload for
physicians and minimize regional disparities in medical resources, therefore
becoming an important topic in the medical image analysis field. It is a
challenging task, as the computational model needs to mimic physicians to
obtain information from multi-modal input data (i.e., medical images, clinical
information, medical knowledge, etc.), and produce comprehensive and accurate
reports. Recently, numerous works have emerged to address this issue using
deep-learning-based methods, such as transformers, contrastive learning, and
knowledge-base construction. This survey summarizes the key techniques
developed in the most recent works and proposes a general workflow for
deep-learning-based report generation with five main components, including
multi-modality data acquisition, data preparation, feature learning, feature
fusion and interaction, and report generation. The state-of-the-art methods for
each of these components are highlighted. Additionally, we summarize the latest
developments in large model-based methods and model explainability, along with
public datasets, evaluation methods, current challenges, and future directions
in this field. We have also conducted a quantitative comparison between
different methods in the same experimental setting. This is the most up-to-date
survey that focuses on multi-modality inputs and data fusion for radiology
report generation. The aim is to provide comprehensive and rich information for
researchers interested in automatic clinical report generation and medical
image analysis, especially when using multimodal inputs, and to assist them in
developing new algorithms to advance the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language
  Models for Referring Expression Comprehension <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11919v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11919v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amaia Cardiel, Eloi Zablocki, Elias Ramzi, Oriane Siméoni, Matthieu Cord
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) have demonstrated remarkable capabilities in
various open-vocabulary tasks, yet their zero-shot performance lags behind
task-specific fine-tuned models, particularly in complex tasks like Referring
Expression Comprehension (REC). Fine-tuning usually requires 'white-box' access
to the model's architecture and weights, which is not always feasible due to
proprietary or privacy concerns. In this work, we propose LLM-wrapper, a method
for 'black-box' adaptation of VLMs for the REC task using Large Language Models
(LLMs). LLM-wrapper capitalizes on the reasoning abilities of LLMs, improved
with a light fine-tuning, to select the most relevant bounding box matching the
referring expression, from candidates generated by a zero-shot black-box VLM.
Our approach offers several advantages: it enables the adaptation of
closed-source models without needing access to their internal workings, it is
versatile as it works with any VLM, it transfers to new VLMs and datasets, and
it allows for the adaptation of an ensemble of VLMs. We evaluate LLM-wrapper on
multiple datasets using different VLMs and LLMs, demonstrating significant
performance improvements and highlighting the versatility of our method. While
LLM-wrapper is not meant to directly compete with standard white-box
fine-tuning, it offers a practical and effective alternative for black-box VLM
adaptation. Code and checkpoints are available at
https://github.com/valeoai/LLM_wrapper .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>LLM-wrapper (v3) is published as a conference paper at ICLR 2025. (v1
  was presented at EVAL-FoMo workshop, ECCV 2024.)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Human-Feedback Efficient Reinforcement Learning for Online Diffusion
  Model Finetuning <span class="chip">ICLR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05116v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05116v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable generation through Stable Diffusion (SD) fine-tuning aims to
improve fidelity, safety, and alignment with human guidance. Existing
reinforcement learning from human feedback methods usually rely on predefined
heuristic reward functions or pretrained reward models built on large-scale
datasets, limiting their applicability to scenarios where collecting such data
is costly or difficult. To effectively and efficiently utilize human feedback,
we develop a framework, HERO, which leverages online human feedback collected
on the fly during model learning. Specifically, HERO features two key
mechanisms: (1) Feedback-Aligned Representation Learning, an online training
method that captures human feedback and provides informative learning signals
for fine-tuning, and (2) Feedback-Guided Image Generation, which involves
generating images from SD's refined initialization samples, enabling faster
convergence towards the evaluator's intent. We demonstrate that HERO is 4x more
efficient in online feedback for body part anomaly correction compared to the
best existing method. Additionally, experiments show that HERO can effectively
handle tasks like reasoning, counting, personalization, and reducing NSFW
content with only 0.5K online feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in International Conference on Learning Representations
  (ICLR) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BHViT: Binarized Hybrid Vision <span class="highlight-title">Transformer</span> <span class="chip">CVPR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02394v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02394v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tian Gao, Zhiyuan Zhang, Yu Zhang, Huajun Liu, Kaijie Yin, Chengzhong Xu, Hui Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model binarization has made significant progress in enabling real-time and
energy-efficient computation for convolutional neural networks (CNN), offering
a potential solution to the deployment challenges faced by Vision Transformers
(ViTs) on edge devices. However, due to the structural differences between CNN
and Transformer architectures, simply applying binary CNN strategies to the ViT
models will lead to a significant performance drop. To tackle this challenge,
we propose BHViT, a binarization-friendly hybrid ViT architecture and its full
binarization model with the guidance of three important observations.
Initially, BHViT utilizes the local information interaction and hierarchical
feature aggregation technique from coarse to fine levels to address redundant
computations stemming from excessive tokens. Then, a novel module based on
shift operations is proposed to enhance the performance of the binary
Multilayer Perceptron (MLP) module without significantly increasing
computational overhead. In addition, an innovative attention matrix
binarization method based on quantization decomposition is proposed to evaluate
the token's importance in the binarized attention matrix. Finally, we propose a
regularization loss to address the inadequate optimization caused by the
incompatibility between the weight oscillation in the binary layers and the
Adam Optimizer. Extensive experimental results demonstrate that our proposed
algorithm achieves SOTA performance among binary ViT methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Self-supervised</span> <span class="highlight-title">pre-train</span>ing with diffusion model for few-shot landmark
  detection in x-ray images <span class="chip">WACV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.18125v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.18125v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roberto Di Via, Francesca Odone, Vito Paolo Pastore
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks have been extensively applied in the medical domain for
various tasks, including image classification, segmentation, and landmark
detection. However, their application is often hindered by data scarcity, both
in terms of available annotations and images. This study introduces a novel
application of denoising diffusion probabilistic models (DDPMs) to the landmark
detection task, specifically addressing the challenge of limited annotated data
in x-ray imaging. Our key innovation lies in leveraging DDPMs for
self-supervised pre-training in landmark detection, a previously unexplored
approach in this domain. This method enables accurate landmark detection with
minimal annotated training data (as few as 50 images), surpassing both ImageNet
supervised pre-training and traditional self-supervised techniques across three
popular x-ray benchmark datasets. To our knowledge, this work represents the
first application of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at WACV 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Multimodal Medical Image Classification using Cross-Graph
  Modal Contrastive Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.17494v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.17494v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun-En Ding, Chien-Chin Hsu, Chi-Hsiang Chu, Shuqiang Wang, Feng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The classification of medical images is a pivotal aspect of disease
diagnosis, often enhanced by deep learning techniques. However, traditional
approaches typically focus on unimodal medical image data, neglecting the
integration of diverse non-image patient data. This paper proposes a novel
Cross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal
structured data from different data domains to improve medical image
classification. The model effectively integrates both image and non-image data
by constructing cross-modality graphs and leveraging contrastive learning to
align multimodal features in a shared latent space. An inter-modality feature
scaling module further optimizes the representation learning process by
reducing the gap between heterogeneous modalities. The proposed approach is
evaluated on two datasets: a Parkinson's disease (PD) dataset and a public
melanoma dataset. Results demonstrate that CGMCL outperforms conventional
unimodal methods in accuracy, interpretability, and early disease prediction.
Additionally, the method shows superior performance in multi-class melanoma
classification. The CGMCL framework provides valuable insights into medical
image classification while offering improved disease interpretability and
predictive capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Li, Bing Hu, Rui Shao, Leyang Shen, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  First-person video assistants are highly anticipated to enhance our daily
lives through online video dialogue. However, existing online video assistants
often sacrifice assistant efficacy for real-time efficiency by processing
low-frame-rate videos with coarse-grained visual features.To overcome the
trade-off between efficacy and efficiency, we propose "Fast & Slow
Video-Language Thinker" as an onLIne videO assistaNt, LION-FS, achieving
real-time, proactive, temporally accurate, and contextually precise responses.
LION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based
Response Determination evaluates frame-by-frame whether an immediate response
is necessary. To enhance response determination accuracy and handle higher
frame-rate inputs efficiently, we employ Token Aggregation Routing to
dynamically fuse spatiotemporal features without increasing token numbers,
while utilizing Token Dropping Routing to eliminate redundant features. 2)Slow
Path: Multi-granularity Keyframe Augmentation optimizes keyframes during
response generation. To provide comprehensive and detailed responses beyond
atomic actions constrained by training data, fine-grained spatial features and
human-environment interaction features are extracted through multi-granular
pooling. These features are further integrated into a meticulously designed
multimodal Thinking Template to guide more precise response generation.
Comprehensive evaluations on online video tasks demonstrate that LION-FS
achieves state-of-the-art efficacy and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accept to CVPR 2025, Project page:
  https://github.com/JiuTian-VL/LION-FS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from
  Multi-Turn Jailbreaks without Compromising Usability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09990v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09990v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the rapid development of safety alignment techniques for LLMs,
defending against multi-turn jailbreaks is still a challenging task. In this
paper, we conduct a comprehensive comparison, revealing that some existing
defense methods can improve the robustness of LLMs against multi-turn
jailbreaks but compromise usability, i.e., reducing general capabilities or
causing the over-refusal problem. From the perspective of mechanism
interpretability of LLMs, we discover that these methods fail to establish a
boundary that exactly distinguishes safe and harmful feature representations.
Therefore, boundary-safe representations close to harmful representations are
inevitably disrupted, leading to a decline in usability. To address this issue,
we propose X-Boundary to push harmful representations away from boundary-safe
representations and obtain an exact distinction boundary. In this way, harmful
representations can be precisely erased without disrupting safe ones.
Experimental results show that X-Boundary achieves state-of-the-art defense
performance against multi-turn jailbreaks, while reducing the over-refusal rate
by about 20% and maintaining nearly complete general capability. Furthermore,
we theoretically prove and empirically verify that X-Boundary can accelerate
the convergence process during training. Please see our code at:
https://github.com/AI45Lab/X-Boundary.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GSPR: Multimodal Place Recognition Using 3D Gaussian Splatting for
  Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00299v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00299v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhangshuo Qi, Junyi Ma, Jingyi Xu, Zijie Zhou, Luqi Cheng, Guangming Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Place recognition is a crucial component that enables autonomous vehicles to
obtain localization results in GPS-denied environments. In recent years,
multimodal place recognition methods have gained increasing attention. They
overcome the weaknesses of unimodal sensor systems by leveraging complementary
information from different modalities. However, most existing methods explore
cross-modality correlations through feature-level or descriptor-level fusion,
suffering from a lack of interpretability. Conversely, the recently proposed 3D
Gaussian Splatting provides a new perspective on multimodal fusion by
harmonizing different modalities into an explicit scene representation. In this
paper, we propose a 3D Gaussian Splatting-based multimodal place recognition
network dubbed GSPR. It explicitly combines multi-view RGB images and LiDAR
point clouds into a spatio-temporally unified scene representation with the
proposed Multimodal Gaussian Splatting. A network composed of 3D graph
convolution and transformer is designed to extract spatio-temporal features and
global descriptors from the Gaussian scenes for place recognition. Extensive
evaluations on three datasets demonstrate that our method can effectively
leverage complementary strengths of both multi-view cameras and LiDAR,
achieving SOTA place recognition performance while maintaining solid
generalization ability. Our open-source code will be released at
https://github.com/QiZS-BIT/GSPR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed
  GFlowNets <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07775v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07775v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Liu, Tim Z. Xiao, Weiyang Liu, <span class="highlight-author">Yoshua Bengio</span>, Dinghuai Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While one commonly trains large diffusion models by collecting datasets on
target downstream tasks, it is often desired to align and finetune pretrained
diffusion models with some reward functions that are either designed by experts
or learned from small-scale datasets. Existing post-training methods for reward
finetuning of diffusion models typically suffer from lack of diversity in
generated samples, lack of prior preservation, and/or slow convergence in
finetuning. Inspired by recent successes in generative flow networks
(GFlowNets), a class of probabilistic models that sample with the unnormalized
density of a reward function, we propose a novel GFlowNet method dubbed
Nabla-GFlowNet (abbreviated as \methodname), the first GFlowNet method that
leverages the rich signal in reward gradients, together with an objective
called \graddb plus its variant \resgraddb designed for prior-preserving
diffusion finetuning. We show that our proposed method achieves fast yet
diversity- and prior-preserving finetuning of Stable Diffusion, a large-scale
text-conditioned image diffusion model, on different realistic reward
functions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report (35 pages, 31 figures), Accepted at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor
  Scene Generation <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhifei Yang, Keyang Lu, Chao Zhang, Jiaxing Qi, Hanqi Jiang, Ruifei Ma, Shenglin Yin, Yifan Xu, Mingzhe Xing, Zhen Xiao, Jieyi Long, Xiangde Liu, Guangyao Zhai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable 3D scene generation has extensive applications in virtual
reality and interior design, where the generated scenes should exhibit high
levels of realism and controllability in terms of geometry. Scene graphs
provide a suitable data representation that facilitates these applications.
However, current graph-based methods for scene generation are constrained to
text-based inputs and exhibit insufficient adaptability to flexible user
inputs, hindering the ability to precisely control object geometry. To address
this issue, we propose MMGDreamer, a dual-branch diffusion model for scene
generation that incorporates a novel Mixed-Modality Graph, visual enhancement
module, and relation predictor. The mixed-modality graph allows object nodes to
integrate textual and visual modalities, with optional relationships between
nodes. It enhances adaptability to flexible user inputs and enables meticulous
control over the geometry of objects in the generated scenes. The visual
enhancement module enriches the visual fidelity of text-only nodes by
constructing visual representations using text embeddings. Furthermore, our
relation predictor leverages node representations to infer absent relationships
between nodes, resulting in more coherent scene layouts. Extensive experimental
results demonstrate that MMGDreamer exhibits superior control of object
geometry, achieving state-of-the-art scene generation performance. Project
page: https://yangzhifeio.github.io/project/MMGDreamer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2025 Main Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FSPGD: Rethinking Black-box Attacks on Semantic Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.01262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.01262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eun-Sol Park, MiSo Park, Seung Park, Yong-Goo Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transferability, the ability of adversarial examples crafted for one model to
deceive other models, is crucial for black-box attacks. Despite advancements in
attack methods for semantic segmentation, transferability remains limited,
reducing their effectiveness in real-world applications. To address this, we
introduce the Feature Similarity Projected Gradient Descent (FSPGD) attack, a
novel black-box approach that enhances both attack performance and
transferability. Unlike conventional segmentation attacks that rely on output
predictions for gradient calculation, FSPGD computes gradients from
intermediate layer features. Specifically, our method introduces a loss
function that targets local information by comparing features between clean
images and adversarial examples, while also disrupting contextual information
by accounting for spatial relationships between objects. Experiments on Pascal
VOC 2012 and Cityscapes datasets demonstrate that FSPGD achieves superior
transferability and attack performance, establishing a new state-of-the-art
benchmark. Code is available at https://github.com/KU-AIVS/FSPGD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniMLVG: Unified Framework for Multi-view Long Video Generation with
  Comprehensive Control Capabilities for Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04842v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04842v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Chen, Zehuan Wu, Yichen Liu, Yuxin Guo, Jingcheng Ni, Haifeng Xia, Siyu Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The creation of diverse and realistic driving scenarios has become essential
to enhance perception and planning capabilities of the autonomous driving
system. However, generating long-duration, surround-view consistent driving
videos remains a significant challenge. To address this, we present UniMLVG, a
unified framework designed to generate extended street multi-perspective videos
under precise control. By integrating single- and multi-view driving videos
into the training data, our approach updates a DiT-based diffusion model
equipped with cross-frame and cross-view modules across three stages with multi
training objectives, substantially boosting the diversity and quality of
generated visual content. Importantly, we propose an innovative explicit
viewpoint modeling approach for multi-view video generation to effectively
improve motion transition consistency. Capable of handling various input
reference formats (e.g., text, images, or video), our UniMLVG generates
high-quality multi-view videos according to the corresponding condition
constraints such as 3D bounding boxes or frame-level text descriptions.
Compared to the best models with similar capabilities, our framework achieves
improvements of 48.2% in FID and 35.2% in FVD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mocap-2-to-3: Lifting 2D Diffusion-Based <span class="highlight-title">Pretrain</span>ed Models for 3D Motion
  Capture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03222v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03222v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhumei Wang, Zechen Hu, Ruoxi Guo, Huaijin Pi, Ziyong Feng, Sida Peng, Xiaowei Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recovering absolute poses in the world coordinate system from monocular views
presents significant challenges. Two primary issues arise in this context.
Firstly, existing methods rely on 3D motion data for training, which requires
collection in limited environments. Acquiring such 3D labels for new actions in
a timely manner is impractical, severely restricting the model's generalization
capabilities. In contrast, 2D poses are far more accessible and easier to
obtain. Secondly, estimating a person's absolute position in metric space from
a single viewpoint is inherently more complex. To address these challenges, we
introduce Mocap-2-to-3, a novel framework that decomposes intricate 3D motions
into 2D poses, leveraging 2D data to enhance 3D motion reconstruction in
diverse scenarios and accurately predict absolute positions in the world
coordinate system. We initially pretrain a single-view diffusion model with
extensive 2D data, followed by fine-tuning a multi-view diffusion model for
view consistency using publicly available 3D data. This strategy facilitates
the effective use of large-scale 2D data. Additionally, we propose an
innovative human motion representation that decouples local actions from global
movements and encodes geometric priors of the ground, ensuring the generative
model learns accurate motion priors from 2D data. During inference, this allows
for the gradual recovery of global movements, resulting in more plausible
positioning. We evaluate our model's performance on real-world datasets,
demonstrating superior accuracy in motion and absolute human positioning
compared to state-of-the-art methods, along with enhanced generalization and
scalability. Our code will be made publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D
  Medical Image Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13524v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13524v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Dai, Jun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient evaluation of three-dimensional (3D) medical images is crucial for
diagnostic and therapeutic practices in healthcare. Recent years have seen a
substantial uptake in applying deep learning and computer vision to analyse and
interpret medical images. Traditional approaches, such as convolutional neural
networks (CNNs) and vision transformers (ViTs), face significant computational
challenges, prompting the need for architectural advancements. Recent efforts
have led to the introduction of novel architectures like the ``Mamba'' model as
alternative solutions to traditional CNNs or ViTs. The Mamba model excels in
the linear processing of one-dimensional data with low computational demands.
However, Mamba's potential for 3D medical image analysis remains underexplored
and could face significant computational challenges as the dimension increases.
This manuscript presents MobileViM, a streamlined architecture for efficient
segmentation of 3D medical images. In the MobileViM network, we invent a new
dimension-independent mechanism and a dual-direction traversing approach to
incorporate with a vision-Mamba-based framework. MobileViM also features a
cross-scale bridging technique to improve efficiency and accuracy across
various medical imaging modalities. With these enhancements, MobileViM achieves
segmentation speeds exceeding 90 frames per second (FPS) on a single graphics
processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster
than the state-of-the-art deep learning models for processing 3D images with
the same computational resources. In addition, experimental evaluations
demonstrate that MobileViM delivers superior performance, with Dice similarity
scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,
ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses
existing models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The corresponding author disagrees with the manuscript submitted to
  arXiv</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.04484v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.04484v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Xu, Lingdong Kong, Hui Shuai, Qingshan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LiDAR segmentation has become a crucial component of advanced autonomous
driving systems. Recent range-view LiDAR segmentation approaches show promise
for real-time processing. However, they inevitably suffer from corrupted
contextual information and rely heavily on post-processing techniques for
prediction refinement. In this work, we propose FRNet, a simple yet powerful
method aimed at restoring the contextual information of range image pixels
using corresponding frustum LiDAR points. First, a frustum feature encoder
module is used to extract per-point features within the frustum region, which
preserves scene consistency and is critical for point-level predictions. Next,
a frustum-point fusion module is introduced to update per-point features
hierarchically, enabling each point to extract more surrounding information
through the frustum features. Finally, a head fusion module is used to fuse
features at different levels for final semantic predictions. Extensive
experiments conducted on four popular LiDAR segmentation benchmarks under
various task setups demonstrate the superiority of FRNet. Notably, FRNet
achieves 73.3% and 82.5% mIoU scores on the testing sets of SemanticKITTI and
nuScenes. While achieving competitive performance, FRNet operates 5 times
faster than state-of-the-art approaches. Such high efficiency opens up new
possibilities for more scalable LiDAR segmentation. The code has been made
publicly available at https://github.com/Xiangxu-0103/FRNet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>TIP 2025; 18 pages, 11 figures, 14 tables; Code at
  https://github.com/Xiangxu-0103/FRNet</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Dataset</span> and Benchmark for Shape Completion of Fruits for Agricultural
  Robotics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13304v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13304v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Federico Magistri, Thomas Läbe, Elias Marks, Sumanth Nagulavancha, Yue Pan, Claus Smitt, Lasse Klingbeil, Michael Halstead, Heiner Kuhlmann, Chris McCool, Jens Behley, Cyrill Stachniss
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the world population is expected to reach 10 billion by 2050, our
agricultural production system needs to double its productivity despite a
decline of human workforce in the agricultural sector. Autonomous robotic
systems are one promising pathway to increase productivity by taking over
labor-intensive manual tasks like fruit picking. To be effective, such systems
need to monitor and interact with plants and fruits precisely, which is
challenging due to the cluttered nature of agricultural environments causing,
for example, strong occlusions. Thus, being able to estimate the complete 3D
shapes of objects in presence of occlusions is crucial for automating
operations such as fruit harvesting. In this paper, we propose the first
publicly available 3D shape completion dataset for agricultural vision systems.
We provide an RGB-D dataset for estimating the 3D shape of fruits.
Specifically, our dataset contains RGB-D frames of single sweet peppers in lab
conditions but also in a commercial greenhouse. For each fruit, we additionally
collected high-precision point clouds that we use as ground truth. For
acquiring the ground truth shape, we developed a measuring process that allows
us to record data of real sweet pepper plants, both in the lab and in the
greenhouse with high precision, and determine the shape of the sensed fruits.
We release our dataset, consisting of almost 7,000 RGB-D frames belonging to
more than 100 different fruits. We provide segmented RGB-D frames, with camera
intrinsics to easily obtain colored point clouds, together with the
corresponding high-precision, occlusion-free point clouds obtained with a
high-precision laser scanner. We additionally enable evaluation of shape
completion approaches on a hidden test set through a public challenge on a
benchmark server.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Effective and Sparse Adversarial Attack on Spiking Neural
  Networks via Breaking Invisible Surrogate Gradients <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03272v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03272v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Lun, Kunyu Feng, Qinglong Ni, Ling Liang, Yuan Wang, Ying Li, Dunshan Yu, Xiaoxin Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking neural networks (SNNs) have shown their competence in handling
spatial-temporal event-based data with low energy consumption. Similar to
conventional artificial neural networks (ANNs), SNNs are also vulnerable to
gradient-based adversarial attacks, wherein gradients are calculated by
spatial-temporal back-propagation (STBP) and surrogate gradients (SGs).
However, the SGs may be invisible for an inference-only model as they do not
influence the inference results, and current gradient-based attacks are
ineffective for binary dynamic images captured by the dynamic vision sensor
(DVS). While some approaches addressed the issue of invisible SGs through
universal SGs, their SGs lack a correlation with the victim model, resulting in
sub-optimal performance. Moreover, the imperceptibility of existing SNN-based
binary attacks is still insufficient. In this paper, we introduce an innovative
potential-dependent surrogate gradient (PDSG) method to establish a robust
connection between the SG and the model, thereby enhancing the adaptability of
adversarial attacks across various models with invisible SGs. Additionally, we
propose the sparse dynamic attack (SDA) to effectively attack binary dynamic
images. Utilizing a generation-reduction paradigm, SDA can fully optimize the
sparsity of adversarial perturbations. Experimental results demonstrate that
our PDSG and SDA outperform state-of-the-art SNN-based attacks across various
models and datasets. Specifically, our PDSG achieves 100% attack success rate
on ImageNet, and our SDA obtains 82% attack success rate by modifying only
0.24% of the pixels on CIFAR10DVS. The code is available at
https://github.com/ryime/PDSG-SDA .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continual Learning in 3D Point Clouds: Employing Spectral Techniques for
  Exemplar Selection <span class="chip">WACV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08388v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08388v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hossein Resani, Behrooz Nasihatkon, Mohammadreza Alimoradi Jazi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel framework for Continual Learning in 3D object
classification. Our approach, CL3D, is based on the selection of prototypes
from each class using spectral clustering. For non-Euclidean data such as point
clouds, spectral clustering can be employed as long as one can define a
distance measure between pairs of samples. Choosing the appropriate distance
measure enables us to leverage 3D geometric characteristics to identify
representative prototypes for each class. We explore the effectiveness of
clustering in the input space (3D points), local feature space
(1024-dimensional points), and global feature space. We conduct experiments on
the ModelNet40, ShapeNet, and ScanNet datasets, achieving state-of-the-art
accuracy exclusively through the use of input space features. By leveraging the
combined input, local, and global features, we have improved the
state-of-the-art on ModelNet and ShapeNet, utilizing nearly half the memory
used by competing approaches. For the challenging ScanNet dataset, our method
enhances accuracy by 4.1% while consuming just 28% of the memory used by our
competitors, demonstrating the scalability of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to WACV 2025, Tucson, Arizona, USA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Implantable Adaptive Cells: A Novel Enhancement for <span class="highlight-title">Pre-Train</span>ed U-Nets
  in Medical Image Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03420v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03420v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emil Benedykciuk, Marcin Denkowski, Grzegorz Wójcik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel approach to enhance the performance of
pre-trained neural networks in medical image segmentation using gradient-based
Neural Architecture Search (NAS) methods. We present the concept of Implantable
Adaptive Cell (IAC), small modules identified through Partially-Connected DARTS
based approach, designed to be injected into the skip connections of an
existing and already trained U-shaped model. Unlike traditional NAS methods,
our approach refines existing architectures without full retraining.
Experiments on four medical datasets with MRI and CT images show consistent
accuracy improvements on various U-Net configurations, with segmentation
accuracy gain by approximately 5 percentage points across all validation
datasets, with improvements reaching up to 11\%pt in the best-performing cases.
The findings of this study not only offer a cost-effective alternative to the
complete overhaul of complex models for performance upgrades but also indicate
the potential applicability of our method to other architectures and problem
domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Structured Preference Optimization for Vision-Language Long-Horizon Task
  Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20742v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20742v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiwen Liang, Min Lin, Weiqi Ruan, Rongtao Xu, Yuecheng Liu, Jiaqi Chen, Bingqian Lin, Yuzheng Zhuang, Xiaodan Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods for vision-language task planning excel in short-horizon
tasks but often fall short in complex, long-horizon planning within dynamic
environments. These challenges primarily arise from the difficulty of
effectively training models to produce high-quality reasoning processes for
long-horizon tasks. To address this, we propose Structured Preference
Optimization (SPO), which aims to enhance reasoning and action selection in
long-horizon task planning through structured preference evaluation and
optimized training strategies. Specifically, SPO introduces: 1)
Preference-Based Scoring and Optimization, which systematically evaluates
reasoning chains based on task relevance, visual grounding, and historical
consistency; and 2) Curriculum-Guided Training, where the model progressively
adapts from simple to complex tasks, improving its generalization ability in
long-horizon scenarios and enhancing reasoning robustness. To advance research
in vision-language long-horizon task planning, we introduce ExtendaBench, a
comprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat
2.0, categorized into ultra-short, short, medium, and long tasks. Experimental
results demonstrate that SPO significantly improves reasoning quality and final
decision accuracy, outperforming prior methods on long-horizon tasks and
underscoring the effectiveness of preference-driven optimization in
vision-language task planning. Specifically, SPO achieves a +5.98% GCR and
+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement
in Habitat over the best-performing baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Vietnamese VQA through Curriculum Learning on Raw and
  Augmented Text Representations <span class="chip">AAAI-25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03285v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03285v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khoi Anh Nguyen, Linh Yen Vu, Thang Dinh Duong, Thuan Nguyen Duong, Huy Thanh Nguyen, Vinh Quang Dinh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Question Answering (VQA) is a multimodal task requiring reasoning
across textual and visual inputs, which becomes particularly challenging in
low-resource languages like Vietnamese due to linguistic variability and the
lack of high-quality datasets. Traditional methods often rely heavily on
extensive annotated datasets, computationally expensive pipelines, and large
pre-trained models, specifically in the domain of Vietnamese VQA, limiting
their applicability in such scenarios. To address these limitations, we propose
a training framework that combines a paraphrase-based feature augmentation
module with a dynamic curriculum learning strategy. Explicitly, augmented
samples are considered "easy" while raw samples are regarded as "hard". The
framework then utilizes a mechanism that dynamically adjusts the ratio of easy
to hard samples during training, progressively modifying the same dataset to
increase its difficulty level. By enabling gradual adaptation to task
complexity, this approach helps the Vietnamese VQA model generalize well, thus
improving overall performance. Experimental results show consistent
improvements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,
highlighting both the potential and challenges of our approach in advancing VQA
for Vietnamese language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and
  Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pathfinder for Low-altitude Aircraft with Binary Neural Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08824v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08824v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaijie Yin, Tian Gao, Hui Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A prior global topological map (e.g., the OpenStreetMap, OSM) can boost the
performance of autonomous mapping by a ground mobile robot. However, the prior
map is usually incomplete due to lacking labeling in partial paths. To solve
this problem, this paper proposes an OSM maker using airborne sensors carried
by low-altitude aircraft, where the core of the OSM maker is a novel efficient
pathfinder approach based on LiDAR and camera data, i.e., a binary dual-stream
road segmentation model. Specifically, a multi-scale feature extraction based
on the UNet architecture is implemented for images and point clouds. To reduce
the effect caused by the sparsity of point cloud, an attention-guided gated
block is designed to integrate image and point-cloud features. To optimize the
model for edge deployment that significantly reduces storage footprint and
computational demands, we propose a binarization streamline to each model
component, including a variant of vision transformer (ViT) architecture as the
encoder of the image branch, and new focal and perception losses to optimize
the model training. The experimental results on two datasets demonstrate that
our pathfinder method achieves SOTA accuracy with high efficiency in finding
paths from the low-level airborne sensors, and we can create complete OSM prior
maps based on the segmented road skeletons. Code and data are available at:
\href{https://github.com/IMRL/Pathfinder}{https://github.com/IMRL/Pathfinder}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep unrolling for learning optimal spatially varying regularisation
  parameters for Total Generalised Variation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thanh Trung Vu, Andreas Kofler, Kostas Papafitsoros
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We extend a recently introduced deep unrolling framework for learning
spatially varying regularisation parameters in inverse imaging problems to the
case of Total Generalised Variation (TGV). The framework combines a deep
convolutional neural network (CNN) inferring the two spatially varying TGV
parameters with an unrolled algorithmic scheme that solves the corresponding
variational problem. The two subnetworks are jointly trained end-to-end in a
supervised fashion and as such the CNN learns to compute those parameters that
drive the reconstructed images as close to the ground truth as possible.
Numerical results in image denoising and MRI reconstruction show a significant
qualitative and quantitative improvement compared to the best TGV scalar
parameter case as well as to other approaches employing spatially varying
parameters computed by unsupervised methods. We also observe that the inferred
spatially varying parameter maps have a consistent structure near the image
edges, asking for further theoretical investigations. In particular, the
parameter that weighs the first-order TGV term has a triple-edge structure with
alternating high-low-high values whereas the one that weighs the second-order
term attains small values in a large neighbourhood around the edges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ InfoDisent: Explainability of Image Classification Models by Information
  Disentanglement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10329v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10329v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Łukasz Struski, Dawid Rymarczyk, Jacek Tabor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we introduce InfoDisent, a hybrid approach to explainability
based on the information bottleneck principle. InfoDisent enables the
disentanglement of information in the final layer of any pretrained model into
atomic concepts, which can be interpreted as prototypical parts. This approach
merges the flexibility of post-hoc methods with the concept-level modeling
capabilities of self-explainable neural networks, such as ProtoPNets. We
demonstrate the effectiveness of InfoDisent through computational experiments
and user studies across various datasets using modern backbones such as ViTs
and convolutional networks. Notably, InfoDisent generalizes the prototypical
parts approach to novel domains (ImageNet).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Backbone for Long-Horizon Robot Task Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01334v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01334v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoshuai Chen, Wei Chen, Dongmyoung Lee, Yukun Ge, Nicolas Rojas, Petar Kormushev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end robot learning, particularly for long-horizon tasks, often results
in unpredictable outcomes and poor generalization. To address these challenges,
we propose a novel Therblig-Based Backbone Framework (TBBF) as a fundamental
structure to enhance interpretability, data efficiency, and generalization in
robotic systems. TBBF utilizes expert demonstrations to enable therblig-level
task decomposition, facilitate efficient action-object mapping, and generate
adaptive trajectories for new scenarios. The approach consists of two stages:
offline training and online testing. During the offline training stage, we
developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig
segmentation across various tasks. In the online testing stage, after a
one-shot demonstration of a new task is collected, our MGSF network extracts
high-level knowledge, which is then encoded into the image using Action
Registration (ActionREG). Additionally, Large Language Model (LLM)-Alignment
Policy for Visual Correction (LAP-VC) is employed to ensure precise action
registration, facilitating trajectory transfer in novel robot scenarios.
Experimental results validate these methods, achieving 94.37% recall in
therblig segmentation and success rates of 94.4% and 80% in real-world online
robot testing for simple and complex scenarios, respectively. Supplementary
material is available at:
https://sites.google.com/view/therbligsbasedbackbone/home
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures. This work has been published by IEEE Robotics and
  Automation Letters (RA-L)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DongbaMIE: A Multimodal Information Extraction <span class="highlight-title">Dataset</span> for Evaluating
  Semantic Understanding of Dongba Pictograms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03644v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03644v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaojun Bi, Shuo Li, Ziyue Wang, Fuwen Luo, Weizheng Qiao, Lu Han, Ziwei Sun, Peng Li, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dongba pictographs are the only pictographs still in use in the world. They
have pictorial ideographic features, and their symbols carry rich cultural and
contextual information. Due to the lack of relevant datasets, existing research
has difficulty in advancing the study of semantic understanding of Dongba
pictographs. To this end, we propose DongbaMIE, the first multimodal dataset
for semantic understanding and extraction of Dongba pictographs. The dataset
consists of Dongba pictograph images and their corresponding Chinese semantic
annotations. It contains 23,530 sentence-level and 2,539 paragraph-level
images, covering four semantic dimensions: objects, actions, relations, and
attributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL
models. Experimental results show that the F1 scores of GPT-4o and Gemini in
the best object extraction are only 3.16 and 3.11 respectively. The F1 score of
Qwen2-VL after supervised fine-tuning is only 11.49. These results suggest that
current large multimodal models still face significant challenges in accurately
recognizing the diverse semantic information in Dongba pictographs. The dataset
can be obtained from this URL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Federated Learning With Individualized Privacy Through Client Sampling <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17634v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17634v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Lange, Ole Borchardt, Erhard Rahm
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With growing concerns about user data collection, individualized privacy has
emerged as a promising solution to balance protection and utility by accounting
for diverse user privacy preferences. Instead of enforcing a uniform level of
anonymization for all users, this approach allows individuals to choose privacy
settings that align with their comfort levels. Building on this idea, we
propose an adapted method for enabling Individualized Differential Privacy
(IDP) in Federated Learning (FL) by handling clients according to their
personal privacy preferences. By extending the SAMPLE algorithm from
centralized settings to FL, we calculate client-specific sampling rates based
on their heterogeneous privacy budgets and integrate them into a modified
IDP-FedAvg algorithm. We test this method under realistic privacy distributions
and multiple datasets. The experimental results demonstrate that our approach
achieves clear improvements over uniform DP baselines, reducing the trade-off
between privacy and utility. Compared to the alternative SCALE method in
related work, which assigns differing noise scales to clients, our method
performs notably better. However, challenges remain for complex tasks with
non-i.i.d. data, primarily stemming from the constraints of the decentralized
setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at 10th International Conference on Machine Learning
  Technologies (ICMLT 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modulating CNN Features with <span class="highlight-title">Pre-Train</span>ed ViT Representations for
  Open-Vocabulary Object Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16981v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16981v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Gao, Yu Dai, Benliu Qiu, Lanxiao Wang, Heqian Qiu, Hongliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Owing to large-scale image-text contrastive training, pre-trained vision
language model (VLM) like CLIP shows superior open-vocabulary recognition
ability. Most existing open-vocabulary object detectors attempt to utilize the
pre-trained VLMs to attain generalized representation. F-ViT uses the
pre-trained visual encoder as the backbone network and freezes it during
training. However, its frozen backbone doesn't benefit from the labeled data to
strengthen the representation for detection. Therefore, we propose a novel
two-branch backbone network, named as \textbf{V}iT-Feature-\textbf{M}odulated
Multi-Scale \textbf{C}onvolutional Network (VMCNet), which consists of a
trainable convolutional branch, a frozen pre-trained ViT branch and a VMC
module. The trainable CNN branch could be optimized with labeled data while the
frozen pre-trained ViT branch could keep the representation ability derived
from large-scale pre-training. Then, the proposed VMC module could modulate the
multi-scale CNN features with the representations from ViT branch. With this
proposed mixed structure, the detector is more likely to discover objects of
novel categories. Evaluated on two popular benchmarks, our method boosts the
detection performance on novel category and outperforms state-of-the-art
methods. On OV-COCO, the proposed method achieves 44.3
AP$_{50}^{\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\mathrm{novel}}$
with ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and
38.4 mAP$_{r}$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $σ$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial
  Examples <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01879v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01879v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Emanuele Cinà, Francesco Villani, Maura Pintor, Lea Schönherr, Battista Biggio, Marcello Pelillo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating the adversarial robustness of deep networks to gradient-based
attacks is challenging. While most attacks consider $\ell_2$- and
$\ell_\infty$-norm constraints to craft input perturbations, only a few
investigate sparse $\ell_1$- and $\ell_0$-norm attacks. In particular,
$\ell_0$-norm attacks remain the least studied due to the inherent complexity
of optimizing over a non-convex and non-differentiable constraint. However,
evaluating adversarial robustness under these attacks could reveal weaknesses
otherwise left untested with more conventional $\ell_2$- and $\ell_\infty$-norm
attacks. In this work, we propose a novel $\ell_0$-norm attack, called
$\sigma$-zero, which leverages a differentiable approximation of the $\ell_0$
norm to facilitate gradient-based optimization, and an adaptive projection
operator to dynamically adjust the trade-off between loss minimization and
perturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet
datasets, involving robust and non-robust models, show that
$\sigma$\texttt{-zero} finds minimum $\ell_0$-norm adversarial examples without
requiring any time-consuming hyperparameter tuning, and that it outperforms all
competing sparse attacks in terms of success rate, perturbation size, and
efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted at International Conference on Learning
  Representations (ICLR 2025). Code available at
  https://github.com/sigma0-advx/sigma-zero</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VISION-XL: High Definition Video Inverse Problem Solver using Latent
  Image Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.00156v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.00156v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taesung Kwon, Jong Chul Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel framework for solving high-definition video
inverse problems using latent image diffusion models. Building on recent
advancements in spatio-temporal optimization for video inverse problems using
image diffusion models, our approach leverages latent-space diffusion models to
achieve enhanced video quality and resolution. To address the high
computational demands of processing high-resolution frames, we introduce a
pseudo-batch consistent sampling strategy, allowing efficient operation on a
single GPU. Additionally, to improve temporal consistency, we present
pseudo-batch inversion, an initialization technique that incorporates
informative latents from the measurement. By integrating with SDXL, our
framework achieves state-of-the-art video reconstruction across a wide range of
spatio-temporal inverse problems, including complex combinations of frame
averaging and various spatial degradations, such as deblurring,
super-resolution, and inpainting. Unlike previous methods, our approach
supports multiple aspect ratios (landscape, vertical, and square) and delivers
HD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame
on a single NVIDIA 4090 GPU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://vision-xl.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ No More Sliding Window: Efficient 3D Medical Image Segmentation with
  Differentiable Top-k Patch Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.10814v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.10814v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Young Seok Jeon, Hongfei Yang, Huazhu Fu, Mengling Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D models surpass 2D models in CT/MRI segmentation by effectively capturing
inter-slice relationships. However, the added depth dimension substantially
increases memory consumption. While patch-based training alleviates memory
constraints, it significantly slows down the inference speed due to the sliding
window (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel
end-to-end trainable framework that enhances the efficiency of generic 3D
segmentation backbone during an inference step by eliminating the need for SW.
NMSW employs a differentiable Top-k module to selectively sample only the most
relevant patches, thereby minimizing redundant computations. When patch-level
predictions are insufficient, the framework intelligently leverages coarse
global predictions to refine results. Evaluated across 3 tasks using 3
segmentation backbones, NMSW achieves competitive accuracy compared to SW
inference while significantly reducing computational complexity by 91% (88.0 to
8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU
(99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to
189 sec). NMSW is model-agnostic, further boosting efficiency when integrated
with any existing efficient segmentation backbones.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OmniGuard: Hybrid Manipulation Localization via Augmented Versatile Deep
  Image Watermarking <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.01615v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.01615v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanyu Zhang, Zecheng Tang, Zhipei Xu, Runyi Li, Youmin Xu, Bin Chen, Feng Gao, Jian Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid growth of generative AI and its widespread application in
image editing, new risks have emerged regarding the authenticity and integrity
of digital content. Existing versatile watermarking approaches suffer from
trade-offs between tamper localization precision and visual quality.
Constrained by the limited flexibility of previous framework, their localized
watermark must remain fixed across all images. Under AIGC-editing, their
copyright extraction accuracy is also unsatisfactory. To address these
challenges, we propose OmniGuard, a novel augmented versatile watermarking
approach that integrates proactive embedding with passive, blind extraction for
robust copyright protection and tamper localization. OmniGuard employs a hybrid
forensic framework that enables flexible localization watermark selection and
introduces a degradation-aware tamper extraction network for precise
localization under challenging conditions. Additionally, a lightweight
AIGC-editing simulation layer is designed to enhance robustness across global
and local editing. Extensive experiments show that OmniGuard achieves superior
fidelity, robustness, and flexibility. Compared to the recent state-of-the-art
approach EditGuard, our method outperforms it by 4.25dB in PSNR of the
container image, 20.7% in F1-Score under noisy conditions, and 14.8% in average
bit accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for
  Microscopic Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nimra Dilawar, Sara Nadeem, Javed Iqbal, Waqas Sultani, Mohsen Ali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing generic unsupervised domain adaptation approaches require access to
both a large labeled source dataset and a sufficient unlabeled target dataset
during adaptation. However, collecting a large dataset, even if unlabeled, is a
challenging and expensive endeavor, especially in medical imaging. In addition,
constraints such as privacy issues can result in cases where source data is
unavailable. Taking in consideration these challenges, we propose MIAdapt, an
adaptive approach for Microscopic Imagery Adaptation as a solution for
Source-free Few-shot Domain Adaptive Object detection (SF-FSDA). We also define
two competitive baselines (1) Faster-FreeShot and (2) MT-FreeShot. Extensive
experiments on the challenging M5-Malaria and Raabin-WBC datasets validate the
effectiveness of MIAdapt. Without using any image from the source domain
MIAdapt surpasses state-of-the-art source-free UDA (SF-UDA) methods by +21.3%
mAP and few-shot domain adaptation (FSDA) approaches by +4.7% mAP on
Raabin-WBC. Our code and models will be publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Indirect Gradient Matching for Adversarial Robust Distillation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03286v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03286v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongsin Lee, Seungju Cho, Changick Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial training significantly improves adversarial robustness, but
superior performance is primarily attained with large models. This substantial
performance gap for smaller models has spurred active research into adversarial
distillation (AD) to mitigate the difference. Existing AD methods leverage the
teacher's logits as a guide. In contrast to these approaches, we aim to
transfer another piece of knowledge from the teacher, the input gradient. In
this paper, we propose a distillation module termed Indirect Gradient
Distillation Module (IGDM) that indirectly matches the student's input gradient
with that of the teacher. Experimental results show that IGDM seamlessly
integrates with existing AD methods, significantly enhancing their performance.
Particularly, utilizing IGDM on the CIFAR-100 dataset improves the AutoAttack
accuracy from 28.06% to 30.32% with the ResNet-18 architecture and from 26.18%
to 29.32% with the MobileNetV2 architecture when integrated into the SOTA
method without additional data augmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation
  for 3D Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18672v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18672v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in 3D scene editing have been propelled by the rapid
development of generative models. Existing methods typically utilize generative
models to perform text-guided editing on 3D representations, such as 3D
Gaussian Splatting (3DGS). However, these methods are often limited to texture
modifications and fail when addressing geometric changes, such as editing a
character's head to turn around. Moreover, such methods lack accurate control
over the spatial position of editing results, as language struggles to
precisely describe the extent of edits. To overcome these limitations, we
introduce DYG, an effective 3D drag-based editing method for 3D Gaussian
Splatting. It enables users to conveniently specify the desired editing region
and the desired dragging direction through the input of 3D masks and pairs of
control points, thereby enabling precise control over the extent of editing.
DYG integrates the strengths of the implicit triplane representation to
establish the geometric scaffold of the editing results, effectively overcoming
suboptimal editing outcomes caused by the sparsity of 3DGS in the desired
editing regions. Additionally, we incorporate a drag-based Latent Diffusion
Model into our method through the proposed Drag-SDS loss function, enabling
flexible, multi-view consistent, and fine-grained editing. Extensive
experiments demonstrate that DYG conducts effective drag-based editing guided
by control point prompts, surpassing other baselines in terms of editing effect
and quality, both qualitatively and quantitatively. Visit our project page at
https://quyans.github.io/Drag-Your-Gaussian.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Visit our project page at https://quyans.github.io/Drag-Your-Gaussian</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GIFT: Unlocking Full Potential of Labels in Distilled <span class="highlight-title">Dataset</span> at
  Near-zero Cost 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14736v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14736v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Shang, Peng Sun, Tao Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in dataset distillation have demonstrated the significant
benefits of employing soft labels generated by pre-trained teacher models. In
this paper, we introduce a novel perspective by emphasizing the full
utilization of labels. We first conduct a comprehensive comparison of various
loss functions for soft label utilization in dataset distillation, revealing
that the model trained on the synthetic dataset exhibits high sensitivity to
the choice of loss function for soft label utilization. This finding highlights
the necessity of a universal loss function for training models on synthetic
datasets. Building on these insights, we introduce an extremely simple yet
surprisingly effective plug-and-play approach, GIFT, which encompasses soft
label refinement and a cosine similarity-based loss function to efficiently
leverage full label information. Extensive experiments indicate that GIFT
consistently enhances state-of-the-art dataset distillation methods across
various dataset scales, without incurring additional computational costs.
Importantly, GIFT significantly enhances cross-optimizer generalization, an
area previously overlooked. For instance, on ImageNet-1K with IPC = 10, GIFT
enhances the state-of-the-art method RDED by 30.8% in cross-optimizer
generalization. Our code is available at https://github.com/LINs-lab/GIFT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/LINs-lab/GIFT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Manta: Enhancing Mamba for Few-Shot Action Recognition of Long
  Sub-Sequence <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07481v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07481v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenbo Huang, Jinghui Zhang, Guang Li, Lei Zhang, Shuoyuan Wang, Fang Dong, Jiahui Jin, Takahiro Ogawa, Miki Haseyama
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In few-shot action recognition (FSAR), long sub-sequences of video naturally
express entire actions more effectively. However, the high computational
complexity of mainstream Transformer-based methods limits their application.
Recent Mamba demonstrates efficiency in modeling long sequences, but directly
applying Mamba to FSAR overlooks the importance of local feature modeling and
alignment. Moreover, long sub-sequences within the same class accumulate
intra-class variance, which adversely impacts FSAR performance. To solve these
challenges, we propose a Matryoshka MAmba and CoNtrasTive LeArning framework
(Manta). Firstly, the Matryoshka Mamba introduces multiple Inner Modules to
enhance local feature representation, rather than directly modeling global
features. An Outer Module captures dependencies of timeline between these local
features for implicit temporal alignment. Secondly, a hybrid contrastive
learning paradigm, combining both supervised and unsupervised methods, is
designed to mitigate the negative effects of intra-class variance accumulation.
The Matryoshka Mamba and the hybrid contrastive learning paradigm operate in
two parallel branches within Manta, enhancing Mamba for FSAR of long
sub-sequence. Manta achieves new state-of-the-art performance on prominent
benchmarks, including SSv2, Kinetics, UCF101, and HMDB51. Extensive empirical
studies prove that Manta significantly improves FSAR of long sub-sequence from
multiple perspectives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for
  Remote Sensing Community 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09110v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09110v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiancheng Pan, Yanxing Liu, Yuqian Fu, Muyuan Ma, Jiahao Li, Danda Pani Paudel, Luc Van Gool, Xiaomeng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object detection, particularly open-vocabulary object detection, plays a
crucial role in Earth sciences, such as environmental monitoring, natural
disaster assessment, and land-use planning. However, existing open-vocabulary
detectors, primarily trained on natural-world images, struggle to generalize to
remote sensing images due to a significant data domain gap. Thus, this paper
aims to advance the development of open-vocabulary object detection in remote
sensing community. To achieve this, we first reformulate the task as Locate
Anything on Earth (LAE) with the goal of detecting any novel concepts on Earth.
We then developed the LAE-Label Engine which collects, auto-annotates, and
unifies up to 10 remote sensing datasets creating the LAE-1M - the first
large-scale remote sensing object detection dataset with broad category
coverage. Using the LAE-1M, we further propose and train the novel LAE-DINO
Model, the first open-vocabulary foundation object detector for the LAE task,
featuring Dynamic Vocabulary Construction (DVC) and Visual-Guided Text Prompt
Learning (VisGT) modules. DVC dynamically constructs vocabulary for each
training batch, while VisGT maps visual features to semantic space, enhancing
text features. We comprehensively conduct experiments on established remote
sensing benchmark DIOR, DOTAv2.0, as well as our newly introduced 80-class
LAE-80C benchmark. Results demonstrate the advantages of the LAE-1M dataset and
the effectiveness of the LAE-DINO method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SSL4EO-S12 v1.1: A Multimodal, Multiseasonal <span class="highlight-title">Dataset</span> for <span class="highlight-title">Pretrain</span>ing,
  Updated 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00168v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00168v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benedikt Blumenstiel, Nassim Ait Ali Braham, Conrad M Albrecht, Stefano Maurogiovanni, Paolo Fraccaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This technical report presents SSL4EO-S12 v1.1, a multimodal, multitemporal
Earth Observation dataset designed for pretraining large-scale foundation
models. Building on the success of SSL4EO-S12 v1.0, the new version addresses
the previous challenges of data misalignment and a limited data structure for
low-barrier, analysis-ready EO processing. SSL4EO-S12 v1.1 covers the world's
10,000 largest cities and its surroundings within a 50 km radius across four
seasons, resulting in a diverse collection of nearly one million patches.
SSL4EO-S12 v1.1 packages the data in Zarr file format for cloud-efficient
loading and representation of meta-information such as including cloud masks
and geolocation. Released under the CC-BY-4.0 license, SSL4EO-S12 v1.1
facilitates open research and provides a robust foundation for future
advancements in self-supervised learning and geospatial analysis. The dataset
is available online through https://datapub.fz-juelich.de/ssl4eo-s12, and we
provided additional resources at https://github.com/DLR-MF-DAS/SSL4EO-S12-v1.1.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StoryTeller: Improving Long Video Description through Global
  Audio-Visual Character Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.07076v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.07076v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichen He, Yuan Lin, Jianchao Wu, Hanchong Zhang, Yuchen Zhang, Ruicheng Le
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing large vision-language models (LVLMs) are largely limited to
processing short, seconds-long videos and struggle with generating coherent
descriptions for extended video spanning minutes or more. Long video
description introduces new challenges, such as consistent character
identification and plot-level descriptions incorporating both visual and audio
information. To address these, we figure out audio-visual character
identification, matching character names to each dialogue, as a key factor. We
propose StoryTeller, a system for generating dense descriptions of long videos,
incorporating both low-level visual concepts and high-level plot information.
StoryTeller uses a multimodal large language model that integrates visual,
audio, and text modalities to perform audio-visual character identification on
minute-long video clips. The results are then fed into a LVLM to enhance
consistency of video description. We validate our approach on movie description
tasks and introduce MovieStory101, a dataset with dense descriptions for
three-minute movie clips. To evaluate long video descriptions, we create
StoryQA, a large set of multiple-choice questions for MovieStory101 test set.
We assess descriptions by inputting them into GPT-4 to answer these questions,
using accuracy as an automatic evaluation metric. Experiments show that
StoryTeller outperforms all open and closed-source baselines on StoryQA,
achieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and
demonstrating a +15.56% advantage in human side-by-side evaluations.
Additionally, incorporating audio-visual character identification from
StoryTeller improves the performance of all video description models, with
Gemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,
respectively, in accuracy on StoryQA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rethinking Weight-Averaged Model-merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.09263v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.09263v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hu Wang, Congbo Ma, Ibrahim Almakky, Ian Reid, Gustavo Carneiro, Mohammad Yaqub
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model-merging has emerged as a powerful approach in deep learning, capable of
enhancing model performance without any training. However, the underlying
mechanisms that explain its effectiveness remain largely unexplored. In this
paper, we investigate this technique from three novel perspectives to
empirically provide deeper insights into why and how weight-averaged
model-merging works: (1) we examine the intrinsic patterns captured by the
learning of the model weights, through the visualizations of their patterns on
several datasets, showing that these weights often encode structured and
interpretable patterns and that is the essential why model-merging can work;
(2) we mathematically and empirically investigate model ensemble merging
strategies based on averaging on weights versus averaging on features,
providing detailed analyses across diverse architectures and datasets; and (3)
we explore the impact on model-merging prediction stability in terms of
changing the parameter magnitude, revealing insights into the way of weight
averaging works as regularization by showing the robustness across different
parameter scales. Our findings shed light on the "black box" of weight-averaged
model-merging, offering valuable insights and practical recommendations that
advance the model-merging process. The code is available at
https://github.com/billhhh/Rethink-Merge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explaining Caption-Image Interactions in CLIP models with Second-Order
  Attributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14153v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14153v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Möller, Pascal Tilli, Ngoc Thang Vu, Sebastian Padó
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dual encoder architectures like CLIP models map two types of inputs into a
shared embedding space and predict similarities between them. Despite their
success, it is, however, not understood how these models compare their two
inputs. Common first-order feature-attribution methods can only provide limited
insights into dual-encoders since their predictions depend on
feature-interactions rather than on individual features. In this paper, we
first derive a second-order method enabling the attribution of predictions by
any differentiable dual encoder onto feature-interactions between its inputs.
Second, we apply our method to CLIP models and show that they learn
fine-grained correspondences between parts of captions and regions in images.
They match objects across input modes also account for mismatches. This
visual-linguistic grounding ability, however, varies heavily between object
classes and exhibits pronounced out-of-domain effects. We can identify
individual errors as well as systematic failure categories including object
coverage, unusual scenes and correlated contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Meta-Learned Modality-Weighted Knowledge Distillation for Robust
  Multi-Modal Learning with Missing Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.07155v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.07155v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hu Wang, Salma Hassan, Yuyuan Liu, Congbo Ma, Yuanhong Chen, Yutong Xie, Mostafa Salem, Yu Tian, Jodie Avery, Louise Hull, Ian Reid, Mohammad Yaqub, Gustavo Carneiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multi-modal learning, some modalities are more influential than others,
and their absence can have a significant impact on classification/segmentation
accuracy. Addressing this challenge, we propose a novel approach called
Meta-learned Modality-weighted Knowledge Distillation (MetaKD), which enables
multi-modal models to maintain high accuracy even when key modalities are
missing. MetaKD adaptively estimates the importance weight of each modality
through a meta-learning process. These learned importance weights guide a
pairwise modality-weighted knowledge distillation process, allowing
high-importance modalities to transfer knowledge to lower-importance ones,
resulting in robust performance despite missing inputs. Unlike previous methods
in the field, which are often task-specific and require significant
modifications, our approach is designed to work in multiple tasks (e.g.,
segmentation and classification) with minimal adaptation. Experimental results
on five prevalent datasets, including three Brain Tumor Segmentation datasets
(BraTS2018, BraTS2019 and BraTS2020), the Alzheimer's Disease Neuroimaging
Initiative (ADNI) classification dataset and the Audiovision-MNIST
classification dataset, demonstrate the proposed model is able to outperform
the compared models by a large margin. The code is available at
https://github.com/billhhh/MetaKD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Masked AutoEncoder for Video Object Counting and A Large-Scale
  Benchmark <span class="chip">ICLR25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13056v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13056v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bing Cao, Quanhao Lu, Jiekang Feng, Qilong Wang, Qinghua Hu, Pengfei Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The dynamic imbalance of the fore-background is a major challenge in video
object counting, which is usually caused by the sparsity of target objects.
This remains understudied in existing works and often leads to severe
under-/over-prediction errors. To tackle this issue in video object counting,
we propose a density-embedded Efficient Masked Autoencoder Counting (E-MAC)
framework in this paper. To empower the model's representation ability on
density regression, we develop a new $\mathtt{D}$ensity-$\mathtt{E}$mbedded
$\mathtt{M}$asked m$\mathtt{O}$deling ($\mathtt{DEMO}$) method, which first
takes the density map as an auxiliary modality to perform multimodal
self-representation learning for image and density map. Although
$\mathtt{DEMO}$ contributes to effective cross-modal regression guidance, it
also brings in redundant background information, making it difficult to focus
on the foreground regions. To handle this dilemma, we propose an efficient
spatial adaptive masking derived from density maps to boost efficiency.
Meanwhile, we employ an optical flow-based temporal collaborative fusion
strategy to effectively capture the dynamic variations across frames, aligning
features to derive multi-frame density residuals. The counting accuracy of the
current frame is boosted by harnessing the information from adjacent frames. In
addition, considering that most existing datasets are limited to human-centric
scenarios, we first propose a large video bird counting dataset, DroneBird, in
natural scenarios for migratory bird protection. Extensive experiments on three
crowd datasets and our \textit{DroneBird} validate our superiority against the
counterparts. The code and dataset are available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LaVin-DiT: Large Vision Diffusion <span class="highlight-title">Transformer</span> <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.11505v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.11505v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoqing Wang, Xiaobo Xia, Runnan Chen, Dongdong Yu, Changhu Wang, Mingming Gong, Tongliang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the Large Vision Diffusion Transformer (LaVin-DiT), a
scalable and unified foundation model designed to tackle over 20 computer
vision tasks in a generative framework. Unlike existing large vision models
directly adapted from natural language processing architectures, which rely on
less efficient autoregressive techniques and disrupt spatial relationships
essential for vision data, LaVin-DiT introduces key innovations to optimize
generative performance for vision tasks. First, to address the high
dimensionality of visual data, we incorporate a spatial-temporal variational
autoencoder that encodes data into a continuous latent space. Second, for
generative modeling, we develop a joint diffusion transformer that
progressively produces vision outputs. Third, for unified multi-task training,
in-context learning is implemented. Input-target pairs serve as task context,
which guides the diffusion transformer to align outputs with specific tasks
within the latent space. During inference, a task-specific context set and test
data as queries allow LaVin-DiT to generalize across tasks without fine-tuning.
Trained on extensive vision datasets, the model is scaled from 0.1B to 3.4B
parameters, demonstrating substantial scalability and state-of-the-art
performance across diverse vision tasks. This work introduces a novel pathway
for large vision foundation models, underscoring the promising potential of
diffusion transformers. The code and models are available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages, 30 figures, 4 tables. Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-Adaptive Gamma Context-Aware SSM-based Model for Metal Defect
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01234v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01234v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sijin Sun, Ming Deng, Xingrui Yu, Xinyu Xi, Liangbin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Metal defect detection is critical in industrial quality assurance, yet
existing methods struggle with grayscale variations and complex defect states,
limiting its robustness. To address these challenges, this paper proposes a
Self-Adaptive Gamma Context-Aware SSM-based model(GCM-DET). This advanced
detection framework integrating a Dynamic Gamma Correction (GC) module to
enhance grayscale representation and optimize feature extraction for precise
defect reconstruction. A State-Space Search Management (SSM) architecture
captures robust multi-scale features, effectively handling defects of varying
shapes and scales. Focal Loss is employed to mitigate class imbalance and
refine detection accuracy. Additionally, the CD5-DET dataset is introduced,
specifically designed for port container maintenance, featuring significant
grayscale variations and intricate defect patterns. Experimental results
demonstrate that the proposed model achieves substantial improvements, with
mAP@0.5 gains of 27.6\%, 6.6\%, and 2.6\% on the CD5-DET, NEU-DET, and GC10-DET
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 9 figures, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail
  Recovery and a Novel Contrastive Learning Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14595v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14595v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gao Yu Lee, Tanmoy Dam, Md Meftahul Ferdaus, Daniel Puiu Poenar, Vu Duong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image dehazing is crucial for clarifying images obscured by haze or fog, but
current learning-based approaches is dependent on large volumes of training
data and hence consumed significant computational power. Additionally, their
performance is often inadequate under non-uniform or heavy haze. To address
these challenges, we developed the Detail Recovery And Contrastive DehazeNet,
which facilitates efficient and effective dehazing via a dense dilated inverted
residual block and an attention-based detail recovery network that tailors
enhancements to specific dehazed scene contexts. A major innovation is its
ability to train effectively with limited data, achieved through a novel
quadruplet loss-based contrastive dehazing paradigm. This approach distinctly
separates hazy and clear image features while also distinguish lower-quality
and higher-quality dehazed images obtained from each sub-modules of our
network, thereby refining the dehazing process to a larger extent. Extensive
tests on a variety of benchmarked haze datasets demonstrated the superiority of
our approach. The code repository for this work is available at
https://github.com/GreedYLearner1146/DRACO-DehazeNet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Once the paper is accepted and published, the copyright will be
  transferred to the corresponding journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Novel Pipeline for Diagnosing Acute Lymphoblastic Leukemia Sensitive to
  Related Biomarkers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.04014v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.04014v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhossein Askari Farsangi, Ali Sharifi-Zarchi, Mohammad Hossein Rohban
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acute Lymphoblastic Leukemia (ALL) is one of the most common types of
childhood blood cancer. The quick start of the treatment process is critical to
saving the patient's life, and for this reason, early diagnosis of this disease
is essential. Examining the blood smear images of these patients is one of the
methods used by expert doctors to diagnose this disease. Deep learning-based
methods have numerous applications in medical fields, as they have
significantly advanced in recent years. ALL diagnosis is not an exception in
this field, and several machine learning-based methods for this problem have
been proposed. In previous methods, high diagnostic accuracy was reported, but
our work showed that this alone is not sufficient, as it can lead to models
taking shortcuts and not making meaningful decisions. This issue arises due to
the small size of medical training datasets. To address this, we constrained
our model to follow a pipeline inspired by experts' work. We also demonstrated
that, since a judgement based on only one image is insufficient, redefining the
problem as a multiple-instance learning problem is necessary for achieving a
practical result. Our model is the first to provide a solution to this problem
in a multiple-instance learning setup. We introduced a novel pipeline for
diagnosing ALL that approximates the process used by hematologists, is
sensitive to disease biomarkers, and achieves an accuracy of 96.15%, an
F1-score of 94.24%, a sensitivity of 97.56%, and a specificity of 90.91% on ALL
IDB 1. Our method was further evaluated on an out-of-distribution dataset,
which posed a challenging test and had acceptable performance. Notably, our
model was trained on a relatively small dataset, highlighting the potential for
our approach to be applied to other medical datasets with limited data
availability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dur360BEV: A Real-world 360-degree Single Camera <span class="highlight-title">Dataset</span> and Benchmark
  for Bird-Eye View Mapping in Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenke E, Chao Yuan, Li Li, Yixin Sun, Yona Falinie A. Gaus, Amir Atapour-Abarghouei, Toby P. Breckon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Dur360BEV, a novel spherical camera autonomous driving dataset
equipped with a high-resolution 128-channel 3D LiDAR and a RTK-refined GNSS/INS
system, along with a benchmark architecture designed to generate Bird-Eye-View
(BEV) maps using only a single spherical camera. This dataset and benchmark
address the challenges of BEV generation in autonomous driving, particularly by
reducing hardware complexity through the use of a single 360-degree camera
instead of multiple perspective cameras. Within our benchmark architecture, we
propose a novel spherical-image-to-BEV module that leverages spherical imagery
and a refined sampling strategy to project features from 2D to 3D. Our approach
also includes an innovative application of focal loss, specifically adapted to
address the extreme class imbalance often encountered in BEV segmentation
tasks, that demonstrates improved segmentation performance on the Dur360BEV
dataset. The results show that our benchmark not only simplifies the sensor
setup but also achieves competitive performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DexMimicGen: Automated Data Generation for Bimanual Dexterous
  Manipulation via Imitation Learning <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.24185v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.24185v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenyu Jiang, Yuqi Xie, Kevin Lin, Zhenjia Xu, Weikang Wan, Ajay Mandlekar, Linxi Fan, Yuke Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Imitation learning from human demonstrations is an effective means to teach
robots manipulation skills. But data acquisition is a major bottleneck in
applying this paradigm more broadly, due to the amount of cost and human effort
involved. There has been significant interest in imitation learning for
bimanual dexterous robots, like humanoids. Unfortunately, data collection is
even more challenging here due to the challenges of simultaneously controlling
multiple arms and multi-fingered hands. Automated data generation in simulation
is a compelling, scalable alternative to fuel this need for data. To this end,
we introduce DexMimicGen, a large-scale automated data generation system that
synthesizes trajectories from a handful of human demonstrations for humanoid
robots with dexterous hands. We present a collection of simulation environments
in the setting of bimanual dexterous manipulation, spanning a range of
manipulation behaviors and different requirements for coordination among the
two arms. We generate 21K demos across these tasks from just 60 source human
demos and study the effect of several data generation and policy learning
decisions on agent performance. Finally, we present a real-to-sim-to-real
pipeline and deploy it on a real-world humanoid can sorting task. Generated
datasets, simulation environments and additional results are at
https://dexmimicgen.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICRA 2025. Project website: https://dexmimicgen.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LangGas: Introducing Language in Selective Zero-Shot Background
  Subtraction for Semi-Transparent Gas Leak Detection with a New <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02910v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02910v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqi Guo, Yiyang Du, Shan Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gas leakage poses a significant hazard that requires prevention.
Traditionally, human inspection has been used for detection, a slow and
labour-intensive process. Recent research has applied machine learning
techniques to this problem, yet there remains a shortage of high-quality,
publicly available datasets. This paper introduces a synthetic dataset
featuring diverse backgrounds, interfering foreground objects, diverse leak
locations, and precise segmentation ground truth. We propose a zero-shot method
that combines background subtraction, zero-shot object detection, filtering,
and segmentation to leverage this dataset. Experimental results indicate that
our approach significantly outperforms baseline methods based solely on
background subtraction and zero-shot object detection with segmentation,
reaching an IoU of 69\% overall. We also present an analysis of various prompt
configurations and threshold settings to provide deeper insights into the
performance of our method. The code and dataset will be released after
publication.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Comparing Deep Neural Network for Multi-Label ECG Diagnosis From Scanned
  ECG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14909v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14909v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cuong V. Nguyen, Hieu X. Nguyen, Dung D. Pham Minh, Cuong D. Do
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated ECG diagnosis has seen significant advancements with deep learning
techniques, but real-world applications still face challenges when dealing with
scanned paper ECGs. In this study, we explore multi-label classification of
ECGs extracted from scanned images, moving beyond traditional binary
classification (normal/abnormal). We evaluate the performance of multiple deep
neural network architectures, including AlexNet, VGG, ResNet, and Vision
Transformer, on scanned ECG datasets. Our comparative analysis examines model
accuracy, robustness to image artifacts, and generalizability across different
ECG conditions. Additionally, we investigate whether ECG signals extracted from
scanned images retain sufficient diagnostic information for reliable automated
classification. The findings highlight the strengths and limitations of each
architecture, providing insights into the feasibility of image-based ECG
diagnosis and its potential integration into clinical workflows.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Human Motion Instruction Tuning <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16805v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16805v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Li, Sen Jia, Wang Jianhao, Zhongyu Jiang, Feng Zhou, Ju Dai, Tianfang Zhang, Wu Zongkai, Jenq-Neng Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents LLaMo (Large Language and Human Motion Assistant), a
multimodal framework for human motion instruction tuning. In contrast to
conventional instruction-tuning approaches that convert non-linguistic inputs,
such as video or motion sequences, into language tokens, LLaMo retains motion
in its native form for instruction tuning. This method preserves
motion-specific details that are often diminished in tokenization, thereby
improving the model's ability to interpret complex human behaviors. By
processing both video and motion data alongside textual inputs, LLaMo enables a
flexible, human-centric analysis. Experimental evaluations across
high-complexity domains, including human behaviors and professional activities,
indicate that LLaMo effectively captures domain-specific knowledge, enhancing
comprehension and prediction in motion-intensive scenarios. We hope LLaMo
offers a foundation for future multimodal AI systems with broad applications,
from sports analytics to behavioral prediction. Our code and models are
available on the project website: https://github.com/ILGLJ/LLaMo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DreamText: High Fidelity Scene Text Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14701v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14701v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yibin Wang, Weizhong Zhang, Honghui Xu, Cheng Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene text synthesis involves rendering specified texts onto arbitrary
images. Current methods typically formulate this task in an end-to-end manner
but lack effective character-level guidance during training. Besides, their
text encoders, pre-trained on a single font type, struggle to adapt to the
diverse font styles encountered in practical applications. Consequently, these
methods suffer from character distortion, repetition, and absence, particularly
in polystylistic scenarios. To this end, this paper proposes DreamText for
high-fidelity scene text synthesis. Our key idea is to reconstruct the
diffusion training process, introducing more refined guidance tailored to this
task, to expose and rectify the model's attention at the character level and
strengthen its learning of text regions. This transformation poses a hybrid
optimization challenge, involving both discrete and continuous variables. To
effectively tackle this challenge, we employ a heuristic alternate optimization
strategy. Meanwhile, we jointly train the text encoder and generator to
comprehensively learn and utilize the diverse font present in the training
dataset. This joint training is seamlessly integrated into the alternate
optimization process, fostering a synergistic relationship between learning
character embedding and re-estimating character attention. Specifically, in
each step, we first encode potential character-generated position information
from cross-attention maps into latent character masks. These masks are then
utilized to update the representation of specific characters in the current
step, which, in turn, enables the generator to correct the character's
attention in the subsequent steps. Both qualitative and quantitative results
demonstrate the superiority of our method to the state of the art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/CodeGoat24/DreamText, Project page:
  https://codegoat24.github.io/DreamText/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TractCloud-FOV: Deep Learning-based Robust Tractography Parcellation in
  Diffusion MRI with Incomplete Field of View 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20637v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20637v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuqian Chen, Leo Zekelman, Yui Lo, Suheyla Cetin-Karayumak, Tengfei Xue, Yogesh Rathi, Nikos Makris, Fan Zhang, Weidong Cai, Lauren J. O'Donnell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tractography parcellation classifies streamlines reconstructed from diffusion
MRI into anatomically defined fiber tracts for clinical and research
applications. However, clinical scans often have incomplete fields of view
(FOV) where brain regions are partially imaged, leading to partial or truncated
fiber tracts. To address this challenge, we introduce TractCloud-FOV, a deep
learning framework that robustly parcellates tractography under conditions of
incomplete FOV. We propose a novel training strategy, FOV-Cut Augmentation
(FOV-CA), in which we synthetically cut tractograms to simulate a spectrum of
real-world inferior FOV cutoff scenarios. This data augmentation approach
enriches the training set with realistic truncated streamlines, enabling the
model to achieve superior generalization. We evaluate the proposed
TractCloud-FOV on both synthetically cut tractography and two real-life
datasets with incomplete FOV. TractCloud-FOV significantly outperforms several
state-of-the-art methods on all testing datasets in terms of streamline
classification accuracy, generalization ability, tract anatomical depiction,
and computational efficiency. Overall, TractCloud-FOV achieves efficient and
consistent tractography parcellation in diffusion MRI with incomplete FOV.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reasoning to Attend: Try to Understand How <SEG> Token Works <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.17741v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.17741v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Qian, Xin Yin, Dejing Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current Large Multimodal Models (LMMs) empowered visual grounding typically
rely on $\texttt{<SEG>}$ tokens as a text prompt to jointly optimize the
vision-language model (e.g., LLaVA) and the downstream task-specific model
(e.g., SAM). However, we observe that little research has looked into how it
works.In this work, we first visualize the similarity maps, which are obtained
by computing the semantic similarity between the $\texttt{<SEG>}$ token and the
image token embeddings derived from the last hidden layer in both the LLaVA
encoder and SAM decoder. Intriguingly, we have found that a striking
consistency holds in terms of activation responses in the similarity map, which
reveals that what the $\texttt{<SEG>}$ token contributes to is semantic
similarity within image-text pairs. Specifically, the $\texttt{<SEG>}$ token, a
placeholder expanded in text vocabulary, extensively queries among individual
tokenized image patches to match the semantics of an object from text to the
paired image, while the Large Language Models (LLMs) are being fine-tuned. Upon
the above findings, we present READ, which facilitates LMMs' resilient
$\textbf{REA}$soning capability of where to atten$\textbf{D}$ under the
guidance of highly activated points borrowed from similarity maps. Remarkably,
READ features an intuitive design, Similarity as Points module (SasP), which
can be seamlessly applied to $\texttt{<SEG>}$-like paradigms in a plug-and-play
fashion. Also, extensive experiments have been conducted on ReasonSeg and
RefCOCO(+/g) datasets. To validate whether READ suffers from catastrophic
forgetting of previous skills after fine-tuning, we further assess its
generation ability on an augmented FP-RefCOCO(+/g) dataset. All codes and
models are publicly available at https://github.com/rui-qian/READ.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted to CVPR 2025, please refer to
  https://github.com/rui-qian/READ</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Visual Description Grounding Reduces Hallucinations and Boosts Reasoning
  in LVLMs <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15683v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15683v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, Oriol Nieto, Zeyu Jin, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) often produce responses that misalign
with factual information, a phenomenon known as hallucinations. While
hallucinations are well-studied, the exact causes behind them remain
underexplored. In this paper, we first investigate the root causes of
hallucinations in LVLMs. Our findings reveal that existing mitigation
techniques primarily reduce hallucinations for visual recognition prompts-those
that require simple descriptions of visual elements-but fail for cognitive
prompts that demand deliberate reasoning. We identify the core issue as a lack
of true visual perception in LVLMs: although they can accurately recognize
visual elements, they struggle to fully interpret these elements in the context
of the input prompt and effectively link this recognition to their internal
knowledge, which is critical for reasoning. To address this gap, we introduce
Visual Description Grounded Decoding (VDGD), a simple, robust, and
training-free method designed to enhance visual perception and improve
reasoning capabilities in LVLMs. VDGD works by first generating a detailed
description of the image and appending it as a prefix to the instruction.
During response generation, tokens are sampled based on their KL divergence to
the description, favoring candidates with lower divergence. Experimental
results on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD
consistently outperforms existing baselines 2% - 33%. Finally, we introduce
VaLLu, a benchmark designed for comprehensive evaluation of the cognitive
capabilities of LVLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Iterative Flow Matching -- Path Correction and Gradual Refinement for
  Enhanced Generative Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16445v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16445v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eldad Haber, Shadab Ahamed, Md. Shahriar Rahim Siddiqui, Niloufar Zakariaei, Moshe Eliasof
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models for image generation are now commonly used for a wide
variety of applications, ranging from guided image generation for entertainment
to solving inverse problems. Nonetheless, training a generator is a non-trivial
feat that requires fine-tuning and can lead to so-called hallucinations, that
is, the generation of images that are unrealistic. In this work, we explore
image generation using flow matching. We explain and demonstrate why flow
matching can generate hallucinations, and propose an iterative process to
improve the generation process. Our iterative process can be integrated into
virtually $\textit{any}$ generative modeling technique, thereby enhancing the
performance and robustness of image synthesis systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LesionDiffusion: Towards Text-controlled General Lesion Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00741v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00741v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Henrui Tian, Wenhui Lei, Linrui Dai, Hanyu Chen, Xiaofan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fully-supervised lesion recognition methods in medical imaging face
challenges due to the reliance on large annotated datasets, which are expensive
and difficult to collect. To address this, synthetic lesion generation has
become a promising approach. However, existing models struggle with
scalability, fine-grained control over lesion attributes, and the generation of
complex structures. We propose LesionDiffusion, a text-controllable lesion
synthesis framework for 3D CT imaging that generates both lesions and
corresponding masks. By utilizing a structured lesion report template, our
model provides greater control over lesion attributes and supports a wider
variety of lesion types. We introduce a dataset of 1,505 annotated CT scans
with paired lesion masks and structured reports, covering 14 lesion types
across 8 organs. LesionDiffusion consists of two components: a lesion mask
synthesis network (LMNet) and a lesion inpainting network (LINet), both guided
by lesion attributes and image features. Extensive experiments demonstrate that
LesionDiffusion significantly improves segmentation performance, with strong
generalization to unseen lesion types and organs, outperforming current
state-of-the-art models. Code will be available at
https://github.com/HengruiTianSJTU/LesionDiffusion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shazam: Unifying Multiple Foundation Models for Advanced Computational
  Pathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00736v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00736v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhui Lei, Anqi Li, Yusheng Tan, Hanyu Chen, Xiaofan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation Models (FMs) in computational pathology (CPath) have significantly
advanced the extraction of meaningful features from histopathology image
datasets, achieving strong performance across various clinical tasks. Despite
their impressive performance, these models often exhibit variability when
applied to different tasks, prompting the need for a unified framework capable
of consistently excelling across various applications. In this work, we propose
Shazam, a novel framework designed to efficiently combine multiple CPath
models. Unlike previous approaches that train a fixed-parameter FM, Shazam
dynamically extracts and refines information from diverse FMs for each specific
task. To ensure that each FM contributes effectively without dominance, a novel
distillation strategy is applied, guiding the student model with features from
all teacher models, which enhances its generalization ability. Experimental
results on two pathology patch classification datasets demonstrate that Shazam
outperforms existing CPath models and other fusion methods. Its lightweight,
flexible design makes it a promising solution for improving CPath analysis in
real-world settings. Code will be available at
https://github.com/Tuner12/Shazam.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03190v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03190v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingzhou Luo, Yang Liu, Weixing Chen, Zhen Li, Yaowei Wang, Guanbin Li, Liang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Question Answering (3D QA) requires the model to comprehensively
understand its situated 3D scene described by the text, then reason about its
surrounding environment and answer a question under that situation. However,
existing methods usually rely on global scene perception from pure 3D point
clouds and overlook the importance of rich local texture details from
multi-view images. Moreover, due to the inherent noise in camera poses and
complex occlusions, there exists significant feature degradation and reduced
feature robustness problems when aligning 3D point cloud with multi-view
images. In this paper, we propose a Dual-vision Scene Perception Network
(DSPNet), to comprehensively integrate multi-view and point cloud features to
improve robustness in 3D QA. Our Text-guided Multi-view Fusion (TGMF) module
prioritizes image views that closely match the semantic content of the text. To
adaptively fuse back-projected multi-view images with point cloud features, we
design the Adaptive Dual-vision Perception (ADVP) module, enhancing 3D scene
comprehension. Additionally, our Multimodal Context-guided Reasoning (MCGR)
module facilitates robust reasoning by integrating contextual information
across visual and linguistic modalities. Experimental results on SQA3D and
ScanQA datasets demonstrate the superiority of our DSPNet. Codes will be
available at https://github.com/LZ-CH/DSPNet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoBench-V: Can Large Vision-Language Models Benchmark Themselves? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21259v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21259v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Bao, Yue Huang, Yanbo Wang, Jiayi Ye, Xiangqi Wang, Xiuying Chen, Yue Zhao, Tianyi Zhou, Mohamed Elhoseiny, Xiangliang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) have become essential for advancing the
integration of visual and linguistic information. However, the evaluation of
LVLMs presents significant challenges as the evaluation benchmark always
demands lots of human cost for its construction, and remains static, lacking
flexibility once constructed. Even though automatic evaluation has been
explored in textual modality, the visual modality remains under-explored. As a
result, in this work, we address a question: "Can LVLMs themselves be used to
benchmark each other in the visual automatically domain?". We introduce
AutoBench-V, an automated framework for serving evaluation on demand, i.e.,
benchmarking LVLMs based on specific aspects of model capability. AutoBench-V
leverages text-to-image models to generate relevant image samples and then
utilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing
the evaluation process efficiently and flexibly. Through an extensive
evaluation of nine popular LVLMs across five demanded user inputs (i.e.,
evaluation capabilities), the framework shows effectiveness and reliability.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval
  via Radiology Report Mining 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04653v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04653v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tengfei Zhang, Ziheng Zhao, Chaoyi Wu, Xiao Zhou, Ya Zhang, Yangfeng Wang, Weidi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing advanced medical imaging retrieval systems is challenging due to
the varying definitions of `similar images' across different medical contexts.
This challenge is compounded by the lack of large-scale, high-quality medical
imaging retrieval datasets and benchmarks. In this paper, we propose a novel
methodology that leverages dense radiology reports to define image-wise
similarity ordering at multiple granularities in a scalable and fully automatic
manner. Using this approach, we construct two comprehensive medical imaging
retrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans,
providing detailed image-image ranking annotations conditioned on diverse
anatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR
and model-ChestCT, which demonstrate superior performance in traditional
image-image and image-report retrieval tasks. These systems also enable
flexible, effective image retrieval conditioned on specific anatomical
structures described in text, achieving state-of-the-art results on 77 out of
78 metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in
  Expert-Domain Information Retrieval <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04644v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04644v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingyu Song, Guo Gan, Mingsheng Shang, Yilun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce IFIR, the first comprehensive benchmark designed to evaluate
instruction-following information retrieval (IR) in expert domains. IFIR
includes 2,426 high-quality examples and covers eight subsets across four
specialized domains: finance, law, healthcare, and science literature. Each
subset addresses one or more domain-specific retrieval tasks, replicating
real-world scenarios where customized instructions are critical. IFIR enables a
detailed analysis of instruction-following retrieval capabilities by
incorporating instructions at different levels of complexity. We also propose a
novel LLM-based evaluation method to provide a more precise and reliable
assessment of model performance in following instructions. Through extensive
experiments on 15 frontier retrieval models, including those based on LLMs, our
results reveal that current models face significant challenges in effectively
following complex, domain-specific instructions. We further provide in-depth
analyses to highlight these limitations, offering valuable insights to guide
future advancements in retriever development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training-Free Graph Filtering via Multimodal Feature Refinement for
  Extremely Fast Multimodal Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04406v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04406v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Seung Roh, Joo-Young Kim, Jin-Duk Park, Won-Yong Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal recommender systems improve the performance of canonical
recommender systems with no item features by utilizing diverse content types
such as text, images, and videos, while alleviating inherent sparsity of
user-item interactions and accelerating user engagement. However, current
neural network-based models often incur significant computational overhead due
to the complex training process required to learn and integrate information
from multiple modalities. To overcome this limitation, we propose
MultiModal-Graph Filtering (MM-GF), a training-free method based on the notion
of graph filtering (GF) for efficient and accurate multimodal recommendations.
Specifically, MM-GF first constructs multiple similarity graphs through
nontrivial multimodal feature refinement such as robust scaling and vector
shifting by addressing the heterogeneous characteristics across modalities.
Then, MM-GF optimally fuses multimodal information using linear low-pass
filters across different modalities. Extensive experiments on real-world
benchmark datasets demonstrate that MM-GF not only improves recommendation
accuracy by up to 13.35% compared to the best competitor but also dramatically
reduces computational costs by achieving the runtime of less than 10 seconds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In-depth Analysis of Graph-based RAG in a Unified Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04338v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04338v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingli Zhou, Yaodong Su, Youran Sun, Shu Wang, Taotao Wang, Runyuan He, Yongwei Zhang, Sicong Liang, Xilin Liu, Yuchi Ma, Yixiang Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-based Retrieval-Augmented Generation (RAG) has proven effective in
integrating external knowledge into large language models (LLMs), improving
their factual accuracy, adaptability, interpretability, and trustworthiness. A
number of graph-based RAG methods have been proposed in the literature.
However, these methods have not been systematically and comprehensively
compared under the same experimental settings. In this paper, we first
summarize a unified framework to incorporate all graph-based RAG methods from a
high-level perspective. We then extensively compare representative graph-based
RAG methods over a range of questing-answering (QA) datasets -- from specific
questions to abstract questions -- and examine the effectiveness of all
methods, providing a thorough analysis of graph-based RAG approaches. As a
byproduct of our experimental analysis, we are also able to identify new
variants of the graph-based RAG methods over specific QA and abstract QA tasks
respectively, by combining existing techniques, which outperform the
state-of-the-art methods. Finally, based on these findings, we offer promising
research opportunities. We believe that a deeper understanding of the behavior
of existing methods can provide new valuable insights for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Measuring temporal effects of agent knowledge by date-controlled tool
  use 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04188v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04188v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R. Patrick Xian, Qiming Cui, Stefan Bauer, Reza Abbasi-Asl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal progression is an integral part of knowledge accumulation and
update. Web search is frequently adopted as grounding for agent knowledge, yet
its inappropriate configuration affects the quality of agent responses. Here,
we construct a tool-based out-of-sample testing framework to measure the
knowledge variability of large language model (LLM) agents from distinct
date-controlled tools (DCTs). We demonstrate the temporal effects of an LLM
agent as a writing assistant, which can use web search to help complete
scientific publication abstracts. We show that temporal effects of the search
engine translates into tool-dependent agent performance but can be alleviated
with base model choice and explicit reasoning instructions such as
chain-of-thought prompting. Our results indicate that agent evaluation should
take a dynamical view and account for the temporal influence of tools and the
updates of external resources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>comments welcome</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic Retrieval Augmented Contrastive Learning for Sequential
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04162v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04162v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiang Cui, Yunpeng Weng, Xing Tang, Xiaokun Zhang, Dugang Liu, Shiwei Li, Peiyang Liu, Bowei He, Weihong Luo, Xiuqiang He, Chen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation aims to model user preferences based on historical
behavior sequences, which is crucial for various online platforms. Data
sparsity remains a significant challenge in this area as most users have
limited interactions and many items receive little attention. To mitigate this
issue, contrastive learning has been widely adopted. By constructing positive
sample pairs from the data itself and maximizing their agreement in the
embedding space,it can leverage available data more effectively. Constructing
reasonable positive sample pairs is crucial for the success of contrastive
learning. However, current approaches struggle to generate reliable positive
pairs as they either rely on representations learned from inherently sparse
collaborative signals or use random perturbations which introduce significant
uncertainty. To address these limitations, we propose a novel approach named
Semantic Retrieval Augmented Contrastive Learning (SRA-CL), which leverages
semantic information to improve the reliability of contrastive samples. SRA-CL
comprises two main components: (1) Cross-Sequence Contrastive Learning via User
Semantic Retrieval, which utilizes large language models (LLMs) to understand
diverse user preferences and retrieve semantically similar users to form
reliable positive samples through a learnable sample synthesis method; and (2)
Intra-Sequence Contrastive Learning via Item Semantic Retrieval, which employs
LLMs to comprehend items and retrieve similar items to perform semantic-based
item substitution, thereby creating semantically consistent augmented views for
contrastive learning. SRA-CL is plug-and-play and can be integrated into
standard sequential recommendation models. Extensive experiments on four public
datasets demonstrate the effectiveness and generalizability of the proposed
approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for
  Training-free Retrieval of Conversational Data using LLMs <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04141v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04141v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sangyeop Kim, Hangyeul Lee, Yohan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growth of conversational AI services has increased demand for effective
information retrieval from dialogue data. However, existing methods often face
challenges in capturing semantic intent or require extensive labeling and
fine-tuning. This paper introduces HEISIR (Hierarchical Expansion of Inverted
Semantic Indexing for Retrieval), a novel framework that enhances semantic
understanding in conversational data retrieval through optimized data
ingestion, eliminating the need for resource-intensive labeling or model
adaptation. HEISIR implements a two-step process: (1) Hierarchical Triplets
Formulation and (2) Adjunct Augmentation, creating semantic indices consisting
of Subject-Verb-Object-Adjunct (SVOA) quadruplets. This structured
representation effectively captures the underlying semantic information from
dialogue content. HEISIR achieves high retrieval performance while maintaining
low latency during the actual retrieval process. Our experimental results
demonstrate that HEISIR outperforms fine-tuned models across various embedding
types and language models. Beyond improving retrieval capabilities, HEISIR also
offers opportunities for intent and topic analysis in conversational data,
providing a versatile solution for dialogue systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NAACL 2025 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Decoupled Recommender Systems: Exploring Alternative Recommender
  Ecosystem Designs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03606v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03606v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anas Buhayh, Elizabeth McKinnie, Robin Burke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender ecosystems are an emerging subject of research. Such research
examines how the characteristics of algorithms, recommendation consumers, and
item providers influence system dynamics and long-term outcomes. One
architectural possibility that has not yet been widely explored in this line of
research is the consequences of a configuration in which recommendation
algorithms are decoupled from the platforms they serve. This is sometimes
called "the friendly neighborhood algorithm store" or "middleware" model. We
are particularly interested in how such architectures might offer a range of
different distributions of utility across consumers, providers, and
recommendation platforms. In this paper, we create a model of a recommendation
ecosystem that incorporates algorithm choice and examine the outcomes of such a
design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assisting Mathematical Formalization with A Learning-based Premise
  Retriever 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.13959v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.13959v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yicheng Tao, Haotian Liu, Shanwen Wang, Hongteng Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Premise selection is a crucial yet challenging step in mathematical
formalization, especially for users with limited experience. Due to the lack of
available formalization projects, existing approaches that leverage language
models often suffer from data scarcity. In this work, we introduce an
innovative method for training a premise retriever to support the formalization
of mathematics. Our approach employs a BERT model to embed proof states and
premises into a shared latent space. The retrieval model is trained within a
contrastive learning framework and incorporates a domain-specific tokenizer
along with a fine-grained similarity computation method. Experimental results
show that our model is highly competitive compared to existing baselines,
achieving strong performance while requiring fewer computational resources.
Performance is further enhanced through the integration of a re-ranking module.
To streamline the formalization process, we will release a search engine that
enables users to query Mathlib theorems directly using proof states,
significantly improving accessibility and efficiency. Codes are available at
https://github.com/ruc-ai4math/Premise-Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SRAG: Structured Retrieval-Augmented Generation for Multi-Entity
  Question Answering over Wikipedia Graph 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teng Lin, Yizhang Zhu, Yuyu Luo, Nan Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-entity question answering (MEQA) poses significant challenges for large
language models (LLMs), which often struggle to consolidate scattered
information across multiple documents. An example question might be "What is
the distribution of IEEE Fellows among various fields of study?", which
requires retrieving information from diverse sources e.g., Wikipedia pages. The
effectiveness of current retrieval-augmented generation (RAG) methods is
limited by the LLMs' capacity to aggregate insights from numerous pages. To
address this gap, this paper introduces a structured RAG (SRAG) framework that
systematically organizes extracted entities into relational tables (e.g.,
tabulating entities with schema columns like "name" and "field of study") and
then apply table-based reasoning techniques. Our approach decouples retrieval
and reasoning, enabling LLMs to focus on structured data analysis rather than
raw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA
tasks demonstrate that SRAG significantly outperforms state-of-the-art
long-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.
The results underscore the efficacy of structuring unstructured data to enhance
LLMs' reasoning capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Search Engines and Large Language Models for Answering Health
  Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12468v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12468v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcos Fernández-Pichel, Juan C. Pichel, David E. Losada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Search engines (SEs) have traditionally been primary tools for information
seeking, but the new Large Language Models (LLMs) are emerging as powerful
alternatives, particularly for question-answering tasks. This study compares
the performance of four popular SEs, seven LLMs, and retrieval-augmented (RAG)
variants in answering 150 health-related questions from the TREC Health
Misinformation (HM) Track. Results reveal SEs correctly answer between 50 and
70% of questions, often hindered by many retrieval results not responding to
the health question. LLMs deliver higher accuracy, correctly answering about
80% of questions, though their performance is sensitive to input prompts. RAG
methods significantly enhance smaller LLMs' effectiveness, improving accuracy
by up to 30% by integrating retrieval evidence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semi-Parametric Retrieval via Binary Bag-of-Tokens Index 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawei Zhou, Li Dong, Furu Wei, Lei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval has transitioned from standalone systems into essential
components across broader applications, with indexing efficiency,
cost-effectiveness, and freshness becoming increasingly critical yet often
overlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval
(SiDR), a bi-encoder retrieval framework that decouples retrieval index from
neural parameters to enable efficient, low-cost, and parameter-agnostic
indexing for emerging use cases. Specifically, in addition to using embeddings
as indexes like existing neural retrieval methods, SiDR supports a
non-parametric tokenization index for search, achieving BM25-like indexing
complexity with significantly better effectiveness. Our comprehensive
evaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms
both neural and term-based retrieval baselines under the same indexing
workload: (i) When using an embedding-based index, SiDR exceeds the performance
of conventional neural retrievers while maintaining similar training
complexity; (ii) When using a tokenization-based index, SiDR drastically
reduces indexing cost and time, matching the complexity of traditional
term-based retrieval, while consistently outperforming BM25 on all in-domain
datasets; (iii) Additionally, we introduce a late parametric mechanism that
matches BM25 index preparation time while outperforming other neural retrieval
baselines in effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">100</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ L$^2$M: Mutual Information Scaling Law for Long-Context Language
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuo Chen, Oriol Mayné i Comas, Zhuotao Jin, Di Luo, Marin Soljačić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We rigorously establish a bipartite mutual information scaling law in natural
language that governs long-range dependencies. This scaling law, which we show
is distinct from and scales independently of the conventional two-point mutual
information, is the key to understanding long-context language modeling. Using
this scaling law, we formulate the Long-context Language Modeling (L$^2$M)
condition, which relates a model's capacity for effective long context length
modeling to the scaling of its latent state size for storing past information.
Our results are validated through experiments on both transformers and state
space models. This work establishes a theoretical foundation that guides the
development of large language models toward longer context lengths.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 12 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enough Coin Flips Can Make LLMs Act Bayesian 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) exhibit the ability to generalize given few-shot
examples in their input prompt, an emergent capability known as in-context
learning (ICL). We investigate whether LLMs utilize ICL to perform structured
reasoning in ways that are consistent with a Bayesian framework or rely on
pattern matching. Using a controlled setting of biased coin flips, we find
that: (1) LLMs often possess biased priors, causing initial divergence in
zero-shot settings, (2) in-context evidence outweighs explicit bias
instructions, (3) LLMs broadly follow Bayesian posterior updates, with
deviations primarily due to miscalibrated priors rather than flawed updates,
and (4) attention magnitude has negligible effect on Bayesian inference. With
sufficient demonstrations of biased coin flips via ICL, LLMs update their
priors in a Bayesian manner.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04718v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04718v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David T. Hoffmann, Syed Haseeb Raza, Hanqiu Jiang, Denis Tananaev, Steffen Klingenhoefer, Martin Meinke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene flow estimation is a foundational task for many robotic applications,
including robust dynamic object detection, automatic labeling, and sensor
synchronization. Two types of approaches to the problem have evolved: 1)
Supervised and 2) optimization-based methods. Supervised methods are fast
during inference and achieve high-quality results, however, they are limited by
the need for large amounts of labeled training data and are susceptible to
domain gaps. In contrast, unsupervised test-time optimization methods do not
face the problem of domain gaps but usually suffer from substantial runtime,
exhibit artifacts, or fail to converge to the right solution. In this work, we
mitigate several limitations of existing optimization-based methods. To this
end, we 1) introduce a simple voxel grid-based model that improves over the
standard MLP-based formulation in multiple dimensions and 2) introduce a new
multiframe loss formulation. 3) We combine both contributions in our new
method, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only
by EulerFlow among unsupervised methods while achieving comparable performance
at a fraction of the computational cost. Floxels achieves a massive speedup of
more than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10
minutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels
achieves a speedup of ~14x.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large
  Language Model <span class="highlight-title">Pretrain</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04715v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04715v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Houyi Li, Wenzheng Zheng, Jingcheng Hu, Qiufeng Wang, Hanshan Zhang, Zili Wang, Yangshijie Xu, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The impressive capabilities of Large Language Models (LLMs) across diverse
tasks are now well-established, yet their effective deployment necessitates
careful hyperparameter optimization. Through extensive empirical studies
involving grid searches across diverse configurations, we discover universal
scaling laws governing these hyperparameters: optimal learning rate follows a
power-law relationship with both model parameters and data sizes, while optimal
batch size scales primarily with data sizes. Our analysis reveals a convex
optimization landscape for hyperparameters under fixed models and data size
conditions. This convexity implies an optimal hyperparameter plateau. We
contribute a universal, plug-and-play optimal hyperparameter tool for the
community. Its estimated values on the test set are merely 0.07\% away from the
globally optimal LLM performance found via an exhaustive search. These laws
demonstrate remarkable robustness across variations in model sparsity, training
data distribution, and model shape. To our best known, this is the first work
that unifies different model shapes and structures, such as Mixture-of-Experts
models and dense transformers, as well as establishes optimal hyperparameter
scaling laws across diverse data distributions. This exhaustive optimization
process demands substantial computational resources, utilizing nearly one
million NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and
hyperparameters from scratch and consuming approximately 100 trillion tokens in
total. To facilitate reproducibility and further research, we will
progressively release all loss measurements and model checkpoints through our
designated repository https://step-law.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Rich Style-<span class="highlight-title">Prompt</span>ed Text-to-Speech <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anuj Diwan, Zhisheng Zheng, David Harwath, Eunsol Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale
dataset that annotates speech utterances with rich style captions. While rich
abstract tags (e.g. guttural, nasal, pained) have been explored in small-scale
human-annotated datasets, existing large-scale datasets only cover basic tags
(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech
embedders, classifiers and an audio language model to automatically scale rich
tag annotations for the first time. ParaSpeechCaps covers a total of 59 style
tags, including both speaker-level intrinsic tags and utterance-level
situational tags. It consists of 342 hours of human-labelled data (PSC-Base)
and 2427 hours of automatically annotated data (PSC-Scaled). We finetune
Parler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and
achieve improved style consistency (+7.9% Consistency MOS) and speech quality
(+15.5% Naturalness MOS) over the best performing baseline that combines
existing rich style tag datasets. We ablate several of our dataset design
choices to lay the foundation for future work in this space. Our dataset,
models and code are released at https://github.com/ajd12342/paraspeechcaps .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficiently Escaping Saddle Points under Generalized Smoothness via
  Self-Bounding Regularity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Yiming Cao, August Y. Chen, Karthik Sridharan, Benjamin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study the problem of non-convex optimization on functions
that are not necessarily smooth using first order methods. Smoothness
(functions whose gradient and/or Hessian are Lipschitz) is not satisfied by
many machine learning problems in both theory and practice, motivating a recent
line of work studying the convergence of first order methods to first order
stationary points under appropriate generalizations of smoothness.
  We develop a novel framework to study convergence of first order methods to
first and \textit{second} order stationary points under generalized smoothness,
under more general smoothness assumptions than the literature. Using our
framework, we show appropriate variants of GD and SGD (e.g. with appropriate
perturbations) can converge not just to first order but also \textit{second
order stationary points} in runtime polylogarithmic in the dimension. To our
knowledge, our work contains the first such result, as well as the first
'non-textbook' rate for non-convex optimization under generalized smoothness.
We demonstrate that several canonical non-convex optimization problems fall
under our setting and framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>79 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sample-Optimal Agnostic Boosting with Unlabeled Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04706v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04706v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Udaya Ghai, Karan Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Boosting provides a practical and provably effective framework for
constructing accurate learning algorithms from inaccurate rules of thumb. It
extends the promise of sample-efficient learning to settings where direct
Empirical Risk Minimization (ERM) may not be implementable efficiently. In the
realizable setting, boosting is known to offer this computational reprieve
without compromising on sample efficiency. However, in the agnostic case,
existing boosting algorithms fall short of achieving the optimal sample
complexity.
  This paper highlights an unexpected and previously unexplored avenue of
improvement: unlabeled samples. We design a computationally efficient agnostic
boosting algorithm that matches the sample complexity of ERM, given
polynomially many additional unlabeled samples. In fact, we show that the total
number of samples needed, unlabeled and labeled inclusive, is never more than
that for the best known agnostic boosting algorithm -- so this result is never
worse -- while only a vanishing fraction of these need to be labeled for the
algorithm to succeed. This is particularly fortuitous for learning-theoretic
applications of agnostic boosting, which often take place in the
distribution-specific setting, where unlabeled samples can be availed for free.
We detail other applications of this result in reinforcement learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Universality of Layer-Level Entropy-Weighted Quantization Beyond Model
  Architecture and Size 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Behtash, Marijan Fofonjka, Ethan Baird, Tyler Mauer, Hossein Moghimifam, David Stout, Joel Dennison
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to selective model quantization that transcends
the limitations of architecture-specific and size-dependent compression methods
for Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By
analyzing the entropy distribution across transformer blocks, EWQ determines
which blocks can be safely quantized without causing significant performance
degradation, independent of model architecture or size. Our method outperforms
uniform quantization approaches, maintaining Massive Multitask Language
Understanding (MMLU) accuracy scores within 0.5% of unquantized models while
reducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ
across multiple architectures-from 1.6B to 70B parameters-showcasing consistent
improvements in the quality-compression trade-off regardless of model scale or
architectural design. A surprising finding of EWQ is its ability to reduce
perplexity compared to unquantized models, suggesting the presence of
beneficial regularization through selective precision reduction. This
improvement holds across different model families, indicating a fundamental
relationship between layer-level entropy and optimal precision requirements.
Additionally, we introduce FastEWQ, a rapid method for entropy distribution
analysis that eliminates the need for loading model weights. This technique
leverages universal characteristics of entropy distribution that persist across
various architectures and scales, enabling near-instantaneous quantization
decisions while maintaining 80% classification accuracy with full entropy
analysis. Our results demonstrate that effective quantization strategies can be
developed independently of specific architectural choices or model sizes,
opening new possibilities for efficient LLM deployment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 7 figures, 14 tables; Comments are welcome</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ L1: Controlling How Long A Reasoning Model Thinks With Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranjal Aggarwal, Sean Welleck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reasoning language models have shown an uncanny ability to improve
performance at test-time by ``thinking longer''-that is, by generating longer
chain-of-thought sequences and hence using more compute. However, the length of
their chain-of-thought reasoning is not controllable, making it impossible to
allocate test-time compute to achieve a desired level of performance. We
introduce Length Controlled Policy Optimization (LCPO), a simple reinforcement
learning method that optimizes for accuracy and adherence to user-specified
length constraints. We use LCPO to train L1, a reasoning language model that
produces outputs satisfying a length constraint given in its prompt. L1's
length control allows for smoothly trading off computational cost and accuracy
on a wide range of tasks, and outperforms the state-of-the-art S1 method for
length control. Furthermore, we uncover an unexpected short chain-of-thought
capability in models trained with LCPO. For instance, our 1.5B L1 model
surpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise
control over reasoning length, allowing for fine-grained allocation of
test-time compute and accuracy. We release code and models at
https://www.cmu-l3.github.io/l1
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coarse graining and reduced order models for plume ejection dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ike Griss Salas, Megan R. Ebers, Jake Stevens-Haas, J. Nathan Kutz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monitoring the atmospheric dispersion of pollutants is increasingly critical
for environmental impact assessments. High-fidelity computational models are
often employed to simulate plume dynamics, guiding decision-making and
prioritizing resource deployment. However, such models can be prohibitively
expensive to simulate, as they require resolving turbulent flows at fine
spatial and temporal resolutions. Moreover, there are at least two distinct
dynamical regimes of interest in the plume: (i) the initial ejection of the
plume where turbulent mixing is generated by the shear-driven Kelvin-Helmholtz
instability, and (ii) the ensuing turbulent diffusion and advection which is
often modeled by the Gaussian plume model. We address the challenge of modeling
the initial plume generation. Specifically, we propose a data-driven framework
that identifies a reduced-order analytical model for plume dynamics -- directly
from video data. We extract a time series of plume center and edge points from
video snapshots and evaluate different regressions based to their extrapolation
performance to generate a time series of coefficients that characterize the
plume's overall direction and spread. We regress to a sinusoidal model inspired
by the Kelvin-Helmholtz instability for the edge points in order to identify
the plume's dispersion and vorticity. Overall, this reduced-order modeling
framework provides a data-driven and lightweight approach to capture the
dominant features of the initial nonlinear point-source plume dynamics,
agnostic to plume type and starting only from video. The resulting model is a
pre-cursor to standard models such as the Gaussian plume model and has the
potential to enable rapid assessment and evaluation of critical environmental
hazards, such as methane leaks, chemical spills, and pollutant dispersal from
smokestacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compositional World Knowledge leads to High Utility Synthetic data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sachit Gaudi, Gautam Sreekumar, Vishnu Boddeti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning systems struggle with robustness, under subpopulation
shifts. This problem becomes especially pronounced in scenarios where only a
subset of attribute combinations is observed during training -a severe form of
subpopulation shift, referred as compositional shift. To address this problem,
we ask the following question: Can we improve the robustness by training on
synthetic data, spanning all possible attribute combinations? We first show
that training of conditional diffusion models on limited data lead to incorrect
underlying distribution. Therefore, synthetic data sampled from such models
will result in unfaithful samples and does not lead to improve performance of
downstream machine learning systems. To address this problem, we propose CoInD
to reflect the compositional nature of the world by enforcing conditional
independence through minimizing Fisher's divergence between joint and marginal
distributions. We demonstrate that synthetic data generated by CoInD is
faithful and this translates to state-of-the-art worst-group accuracy on
compositional shift tasks on CelebA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Propagating Model Uncertainty through Filtering-based Probabilistic
  Numerical ODE Solvers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04684v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04684v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dingling Yao, Filip Tronarp, Nathanael Bosch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Filtering-based probabilistic numerical solvers for ordinary differential
equations (ODEs), also known as ODE filters, have been established as efficient
methods for quantifying numerical uncertainty in the solution of ODEs. In
practical applications, however, the underlying dynamical system often contains
uncertain parameters, requiring the propagation of this model uncertainty to
the ODE solution. In this paper, we demonstrate that ODE filters, despite their
probabilistic nature, do not automatically solve this uncertainty propagation
problem. To address this limitation, we present a novel approach that combines
ODE filters with numerical quadrature to properly marginalize over uncertain
parameters, while accounting for both parameter uncertainty and numerical
solver uncertainty. Experiments across multiple dynamical systems demonstrate
that the resulting uncertainty estimates closely match reference solutions.
Notably, we show how the numerical uncertainty from the ODE solver can help
prevent overconfidence in the propagated uncertainty estimates, especially when
using larger step sizes. Our results illustrate that probabilistic numerical
methods can effectively quantify both numerical and parametric uncertainty in
dynamical systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Matrix Factorization for Inferring Associations and Missing Links 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan Barron, Maksim E. Eren, Duc P. Truong, Cynthia Matuszek, James Wendelberger, Mary F. Dorn, Boian Alexandrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Missing link prediction is a method for network analysis, with applications
in recommender systems, biology, social sciences, cybersecurity, information
retrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.
Missing link prediction identifies unseen but potentially existing connections
in a network by analyzing the observed patterns and relationships. In
proliferation detection, this supports efforts to identify and characterize
attempts by state and non-state actors to acquire nuclear weapons or associated
technology - a notoriously challenging but vital mission for global security.
Dimensionality reduction techniques like Non-Negative Matrix Factorization
(NMF) and Logistic Matrix Factorization (LMF) are effective but require
selection of the matrix rank parameter, that is, of the number of hidden
features, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),
Boolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along
with ensemble variants incorporating logistic factorization, for link
prediction. Our methods integrate automatic model determination for rank
estimation by evaluating stability and accuracy using a modified bootstrap
methodology and uncertainty quantification (UQ), assessing prediction
reliability under random perturbations. We incorporate Otsu threshold selection
and k-means clustering for Boolean matrix factorization, comparing them to
coordinate descent-based Boolean thresholding. Our experiments highlight the
impact of rank k selection, evaluate model performance under varying test-set
sizes, and demonstrate the benefits of UQ for reliable predictions using
abstention. We validate our methods on three synthetic datasets (Boolean and
uniformly distributed) and benchmark them against LMF and symmetric LMF
(symLMF) on five real-world protein-protein interaction networks, showcasing an
improved prediction performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 14 figures, 3 tables, 1 algorithm</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Agent Inverse Q-Learning from Demonstrations <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04679v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04679v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathaniel Haynam, Adam Khoja, Dhruv Kumar, Vivek Myers, Erdem Bıyık
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When reward functions are hand-designed, deep reinforcement learning
algorithms often suffer from reward misspecification, causing them to learn
suboptimal policies in terms of the intended task objectives. In the
single-agent case, inverse reinforcement learning (IRL) techniques attempt to
address this issue by inferring the reward function from expert demonstrations.
However, in multi-agent problems, misalignment between the learned and true
objectives is exacerbated due to increased environment non-stationarity and
variance that scales with multiple agents. As such, in multi-agent general-sum
games, multi-agent IRL algorithms have difficulty balancing cooperative and
competitive objectives. To address these issues, we propose Multi-Agent
Marginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient
framework for multi-agent IRL. For each agent, MAMQL learns a critic
marginalized over the other agents' policies, allowing for a well-motivated use
of Boltzmann policies in the multi-agent context. We identify a connection
between optimal marginalized critics and single-agent soft-Q IRL, allowing us
to apply a direct, simple optimization criterion from the single-agent domain.
Across our experiments on three different simulated domains, MAMQL
significantly outperforms previous multi-agent methods in average reward,
sample efficiency, and reward recovery by often more than 2-5x. We make our
code available at https://sites.google.com/view/mamql .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, 2 tables. Published at the International
  Conference on Robotics and Automation (ICRA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Information-theoretic Multi-task Representation Learning Framework
  for Natural Language Understanding <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04667v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04667v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a new principled multi-task representation learning
framework (InfoMTL) to extract noise-invariant sufficient representations for
all tasks. It ensures sufficiency of shared representations for all tasks and
mitigates the negative effect of redundant features, which can enhance language
understanding of pre-trained language models (PLMs) under the multi-task
paradigm. Firstly, a shared information maximization principle is proposed to
learn more sufficient shared representations for all target tasks. It can avoid
the insufficiency issue arising from representation compression in the
multi-task paradigm. Secondly, a task-specific information minimization
principle is designed to mitigate the negative effect of potential redundant
features in the input for each task. It can compress task-irrelevant redundant
information and preserve necessary information relevant to the target for
multi-task prediction. Experiments on six classification benchmarks show that
our method outperforms 12 comparative multi-task methods under the same
multi-task settings, especially in data-constrained and noisy scenarios.
Extensive experiments demonstrate that the learned representations are more
sufficient, data-efficient, and robust.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, accepted to AAAI 2025 (main conference), the code is
  available at https://github.com/zerohd4869/InfoMTL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CLDyB: Towards Dynamic Benchmarking for Continual Learning with
  <span class="highlight-title">Pre-train</span>ed Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengzhuang Chen, Yikai Liao, Xiaoxiao Sun, Kede Ma, Ying Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of the foundation model era has sparked significant research
interest in leveraging pre-trained representations for continual learning (CL),
yielding a series of top-performing CL methods on standard evaluation
benchmarks. Nonetheless, there are growing concerns regarding potential data
contamination during the pre-training stage. Furthermore, standard evaluation
benchmarks, which are typically static, fail to capture the complexities of
real-world CL scenarios, resulting in saturated performance. To address these
issues, we describe CL on dynamic benchmarks (CLDyB), a general computational
framework based on Markov decision processes for evaluating CL methods
reliably. CLDyB dynamically identifies inherently difficult and
algorithm-dependent tasks for the given CL methods, and determines challenging
task orders using Monte Carlo tree search. Leveraging CLDyB, we first conduct a
joint evaluation of multiple state-of-the-art CL methods, leading to a set of
commonly challenging and generalizable task sequences where existing CL methods
tend to perform poorly. We then conduct separate evaluations of individual CL
methods using CLDyB, discovering their respective strengths and weaknesses. The
source code and generated task sequences are publicly accessible at
https://github.com/szc12153/CLDyB.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Joint Masked Reconstruction and Contrastive Learning for Mining
  Interactions Between Proteins 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04650v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04650v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiang Li, Xiaoping Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protein-protein interaction (PPI) prediction is an instrumental means in
elucidating the mechanisms underlying cellular operations, holding significant
practical implications for the realms of pharmaceutical development and
clinical treatment. Presently, the majority of research methods primarily
concentrate on the analysis of amino acid sequences, while investigations
predicated on protein structures remain in the nascent stages of exploration.
Despite the emergence of several structure-based algorithms in recent years,
these are still confronted with inherent challenges: (1) the extraction of
intrinsic structural information of proteins typically necessitates the
expenditure of substantial computational resources; (2) these models are overly
reliant on seen protein data, struggling to effectively unearth interaction
cues between unknown proteins. To further propel advancements in this domain,
this paper introduces a novel PPI prediction method jointing masked
reconstruction and contrastive learning, termed JmcPPI. This methodology
dissects the PPI prediction task into two distinct phases: during the residue
structure encoding phase, JmcPPI devises two feature reconstruction tasks and
employs graph attention mechanism to capture structural information between
residues; during the protein interaction inference phase, JmcPPI perturbs the
original PPI graph and employs a multi-graph contrastive learning strategy to
thoroughly mine extrinsic interaction information of novel proteins. Extensive
experiments conducted on three widely utilized PPI datasets demonstrate that
JmcPPI surpasses existing optimal baseline models across various data partition
schemes. The associated code can be accessed via
https://github.com/lijfrank-open/JmcPPI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transferable Foundation Models for Geometric Tasks on Point Cloud
  Representations: Geometric Neural Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Blaine Quackenbush, Paul J. Atzberger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce methods for obtaining pretrained Geometric Neural Operators
(GNPs) that can serve as basal foundation models for use in obtaining geometric
features. These can be used within data processing pipelines for machine
learning tasks and numerical methods. We show how our GNPs can be trained to
learn robust latent representations for the differential geometry of
point-clouds to provide estimates of metric, curvature, and other shape-related
features. We demonstrate how our pre-trained GNPs can be used (i) to estimate
the geometric properties of surfaces of arbitrary shape and topologies with
robustness in the presence of noise, (ii) to approximate solutions of geometric
partial differential equations (PDEs) on manifolds, and (iii) to solve
equations for shape deformations such as curvature driven flows. We also
release a package of the codes and weights for using our pre-trained GNPs for
processing point cloud representations. This allows for incorporating our
pre-trained GNPs as components for reuse within existing and new data
processing pipelines. The GNPs also can be used as part of numerical solvers
involving geometry or as part of methods for performing inference and other
geometric tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulating the Real World: A Unified <span class="highlight-title">Survey</span> of Multimodal Generative
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04641v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04641v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuqi Hu, Longguang Wang, Xian Liu, Ling-Hao Chen, Yuwei Guo, Yukai Shi, Ce Liu, Anyi Rao, Zeyu Wang, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and replicating the real world is a critical challenge in
Artificial General Intelligence (AGI) research. To achieve this, many existing
approaches, such as world models, aim to capture the fundamental principles
governing the physical world, enabling more accurate simulations and meaningful
interactions. However, current methods often treat different modalities,
including 2D (images), videos, 3D, and 4D representations, as independent
domains, overlooking their interdependencies. Additionally, these methods
typically focus on isolated dimensions of reality without systematically
integrating their connections. In this survey, we present a unified survey for
multimodal generative models that investigate the progression of data
dimensionality in real-world simulation. Specifically, this survey starts from
2D generation (appearance), then moves to video (appearance+dynamics) and 3D
generation (appearance+geometry), and finally culminates in 4D generation that
integrate all dimensions. To the best of our knowledge, this is the first
attempt to systematically unify the study of 2D, video, 3D and 4D generation
within a single framework. To guide future research, we provide a comprehensive
review of datasets, evaluation metrics and future directions, and fostering
insights for newcomers. This survey serves as a bridge to advance the study of
multimodal generative models and real-world simulation within a unified
framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Repository for the related papers at
  https://github.com/ALEEEHU/World-Simulator</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing SAM with Efficient <span class="highlight-title">Prompt</span>ing and Preference Optimization for
  Semi-supervised Medical Image Segmentation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aishik Konwer, Zhijian Yang, Erhan Bas, Cao Xiao, Prateek Prasanna, Parminder Bhatia, Taha Kass-Hout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundational models such as the Segment Anything Model (SAM) are gaining
traction in medical imaging segmentation, supporting multiple downstream tasks.
However, such models are supervised in nature, still relying on large annotated
datasets or prompts supplied by experts. Conventional techniques such as active
learning to alleviate such limitations are limited in scope and still
necessitate continuous human involvement and complex domain knowledge for label
refinement or establishing reward ground truth. To address these challenges, we
propose an enhanced Segment Anything Model (SAM) framework that utilizes
annotation-efficient prompts generated in a fully unsupervised fashion, while
still capturing essential semantic, location, and shape information through
contrastive language-image pretraining and visual question answering. We adopt
the direct preference optimization technique to design an optimal policy that
enables the model to generate high-fidelity segmentations with simple ratings
or rankings provided by a virtual annotator simulating the human annotation
process. State-of-the-art performance of our framework in tasks such as lung
segmentation, breast tumor segmentation, and organ segmentation across various
modalities, including X-ray, ultrasound, and abdominal CT, justifies its
effectiveness in low-annotation data scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ No Forgetting Learning: Memory-free Continual Learning <span class="chip">ICCV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Ali Vahedifar, Qi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Continual Learning (CL) remains a central challenge in deep learning, where
models must sequentially acquire new knowledge while mitigating Catastrophic
Forgetting (CF) of prior tasks. Existing approaches often struggle with
efficiency and scalability, requiring extensive memory or model buffers. This
work introduces ``No Forgetting Learning" (NFL), a memory-free CL framework
that leverages knowledge distillation to maintain stability while preserving
plasticity. Memory-free means the NFL does not rely on any memory buffer.
Through extensive evaluations of three benchmark datasets, we demonstrate that
NFL achieves competitive performance while utilizing approximately 14.75 times
less memory than state-of-the-art methods. Furthermore, we introduce a new
metric to better assess CL's plasticity-stability trade-off.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is submitted to ICCV 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models
  via Watermarking <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijie Xu, Aiwei Liu, Xuming Hu, Lijie Wen, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As open-source large language models (LLMs) like Llama3 become more capable,
it is crucial to develop watermarking techniques to detect their potential
misuse. Existing watermarking methods either add watermarks during LLM
inference, which is unsuitable for open-source LLMs, or primarily target
classification LLMs rather than recent generative LLMs. Adapting these
watermarks to open-source LLMs for misuse detection remains an open challenge.
This work defines two misuse scenarios for open-source LLMs: intellectual
property (IP) violation and LLM Usage Violation. Then, we explore the
application of inference-time watermark distillation and backdoor watermarking
in these contexts. We propose comprehensive evaluation methods to assess the
impact of various real-world further fine-tuning scenarios on watermarks and
the effect of these watermarks on LLM performance. Our experiments reveal that
backdoor watermarking could effectively detect IP Violation, while
inference-time watermark distillation is applicable in both scenarios but less
robust to further fine-tuning and has a more significant impact on LLM
performance compared to backdoor watermarking. Exploring more advanced
watermarking methods for open-source LLMs to detect their misuse should be an
important future direction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the 1st Workshop on GenAI Watermarking, collocated with
  ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IDInit: A Universal and Stable Initialization Method for Neural Network
  Training <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04626v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04626v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Pan, Chaozheng Wang, Zekai Wu, Qifan Wang, Min Zhang, Zenglin Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks have achieved remarkable accomplishments in practice.
The success of these networks hinges on effective initialization methods, which
are vital for ensuring stable and rapid convergence during training. Recently,
initialization methods that maintain identity transition within layers have
shown good efficiency in network training. These techniques (e.g., Fixup) set
specific weights to zero to achieve identity control. However, settings of
remaining weight (e.g., Fixup uses random values to initialize non-zero
weights) will affect the inductive bias that is achieved only by a zero weight,
which may be harmful to training. Addressing this concern, we introduce fully
identical initialization (IDInit), a novel method that preserves identity in
both the main and sub-stem layers of residual networks. IDInit employs a padded
identity-like matrix to overcome rank constraints in non-square weight
matrices. Furthermore, we show the convergence problem of an identity matrix
can be solved by stochastic gradient descent. Additionally, we enhance the
universality of IDInit by processing higher-order weights and addressing dead
neuron problems. IDInit is a straightforward yet effective initialization
method, with improved convergence, stability, and performance across various
settings, including large-scale datasets and deep models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Best of Both Worlds: Integrating Language Models and Diffusion
  Models for Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aoxiong Yin, Kai Shen, Yichong Leng, Xu Tan, Xinyu Zhou, Juncheng Li, Siliang Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-video (T2V) generation have been driven by two
competing paradigms: autoregressive language models and diffusion models.
However, each paradigm has intrinsic limitations: language models struggle with
visual quality and error accumulation, while diffusion models lack semantic
understanding and causal modeling. In this work, we propose LanDiff, a hybrid
framework that synergizes the strengths of both paradigms through
coarse-to-fine generation. Our architecture introduces three key innovations:
(1) a semantic tokenizer that compresses 3D visual features into compact 1D
discrete representations through efficient semantic compression, achieving a
$\sim$14,000$\times$ compression ratio; (2) a language model that generates
semantic tokens with high-level semantic relationships; (3) a streaming
diffusion model that refines coarse semantics into high-fidelity videos.
Experiments show that LanDiff, a 5B model, achieves a score of 85.43 on the
VBench T2V benchmark, surpassing the state-of-the-art open-source models
Hunyuan Video (13B) and other commercial models such as Sora, Keling, and
Hailuo. Furthermore, our model also achieves state-of-the-art performance in
long video generation, surpassing other open-source models in this field. Our
demo can be viewed at https://landiff.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fusion of Various Optimization Based Feature Smoothing Methods for
  Wearable and Non-invasive Blood Glucose Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03770v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03770v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiting Wei, Bingo Wing-Kuen Ling, Danni Chen, Yuheng Dai, Qing Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the wearable and non-invasive blood glucose estimation approach has
been proposed. However, due to the unreliability of the acquisition device, the
presence of the noise and the variations of the acquisition environments, the
obtained features and the reference blood glucose values are highly unreliable.
To address this issue, this paper proposes a polynomial fitting approach to
smooth the obtained features or the reference blood glucose values. First, the
blood glucose values are estimated based on the individual optimization
approaches. Second, the absolute difference values between the estimated blood
glucose values and the actual blood glucose values based on each optimization
approach are computed. Third, these absolute difference values for each
optimization approach are sorted in the ascending order. Fourth, for each
sorted blood glucose value, the optimization method corresponding to the
minimum absolute difference value is selected. Fifth, the accumulate
probability of each selected optimization method is computed. If the accumulate
probability of any selected optimization method at a point is greater than a
threshold value, then the accumulate probabilities of these three selected
optimization methods at that point are reset to zero. A range of the sorted
blood glucose values are defined as that with the corresponding boundaries
points being the previous reset point and this reset point. Hence, after
performing the above procedures for all the sorted reference blood glucose
values in the validation set, the regions of the sorted reference blood glucose
values and the corresponding optimization methods in these regions are
determined. The computer numerical simulation results show that our proposed
method yields the mean absolute relative deviation (MARD) at 0.0930 and the
percentage of the test data falling in the zone A of the Clarke error grid at
94.1176%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This version corrects several typos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HybridNorm: Towards Stable and Efficient <span class="highlight-title">Transformer</span> Training via Hybrid
  Normalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijian Zhuo, Yutao Zeng, Ya Wang, Sijun Zhang, Jian Yang, Xiaoqing Li, Xun Zhou, Jinwen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers have become the de facto architecture for a wide range of
machine learning tasks, particularly in large language models (LLMs). Despite
their remarkable performance, challenges remain in training deep transformer
networks, especially regarding the location of layer normalization. While
Pre-Norm structures facilitate easier training due to their more prominent
identity path, they often yield suboptimal performance compared to Post-Norm.
In this paper, we propose $\textbf{HybridNorm}$, a straightforward yet
effective hybrid normalization strategy that integrates the advantages of both
Pre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV
normalization within the attention mechanism and Post-Norm in the feed-forward
network (FFN) of each transformer block. This design not only stabilizes
training but also enhances performance, particularly in the context of LLMs.
Comprehensive experiments in both dense and sparse architectures show that
HybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,
achieving state-of-the-art results across various benchmarks. These findings
highlight the potential of HybridNorm as a more stable and effective technique
for improving the training and performance of deep transformer models. %Code
will be made publicly available. Code is available at
https://github.com/BryceZhuo/HybridNorm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Solutions for the Three-Body Problem Through Physics-Informed
  Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04585v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04585v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Santos Pereira, Luís Tripa, Nélson Lima, Francisco Caldas, Cláudia Soares
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  First formulated by Sir Isaac Newton in his work "Philosophiae Naturalis
Principia Mathematica", the concept of the Three-Body Problem was put forth as
a study of the motion of the three celestial bodies within the Earth-Sun-Moon
system. In a generalized definition, it seeks to predict the motion for an
isolated system composed of three point masses freely interacting under
Newton's law of universal attraction. This proves to be analogous to a
multitude of interactions between celestial bodies, and thus, the problem finds
applicability within the studies of celestial mechanics. Despite numerous
attempts by renowned physicists to solve it throughout the last three
centuries, no general closed-form solutions have been reached due to its
inherently chaotic nature for most initial conditions. Current state-of-the-art
solutions are based on two approaches, either numerical high-precision
integration or machine learning-based. Notwithstanding the breakthroughs of
neural networks, these present a significant limitation, which is their
ignorance of any prior knowledge of the chaotic systems presented. Thus, in
this work, we propose a novel method that utilizes Physics-Informed Neural
Networks (PINNs). These deep neural networks are able to incorporate any prior
system knowledge expressible as an Ordinary Differential Equation (ODE) into
their learning processes as a regularizing agent. Our findings showcase that
PINNs surpass current state-of-the-art machine learning methods with comparable
prediction quality. Despite a better prediction quality, the usability of
numerical integrators suffers due to their prohibitively high computational
cost. These findings confirm that PINNs are both effective and time-efficient
open-form solvers of the Three-Body Problem that capitalize on the extensive
knowledge we hold of classical mechanics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 25 figures, 3 tables. 75th International Astronautical
  Congress (IAC), Milan, Italy, 14-18 October</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PSDNorm: Test-Time Temporal Normalization for Deep Learning on EEG
  Signals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Théo Gnassounou, Antoine Collas, Rémi Flamary, Alexandre Gramfort
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distribution shift poses a significant challenge in machine learning,
particularly in biomedical applications such as EEG signals collected across
different subjects, institutions, and recording devices. While existing
normalization layers, Batch-Norm, LayerNorm and InstanceNorm, help address
distribution shifts, they fail to capture the temporal dependencies inherent in
temporal signals. In this paper, we propose PSDNorm, a layer that leverages
Monge mapping and temporal context to normalize feature maps in deep learning
models. Notably, the proposed method operates as a test-time domain adaptation
technique, addressing distribution shifts without additional training.
Evaluations on 10 sleep staging datasets using the U-Time model demonstrate
that PSDNorm achieves state-of-the-art performance at test time on datasets not
seen during training while being 4x more data-efficient than the best baseline.
Additionally, PSDNorm provides a significant improvement in robustness,
achieving markedly higher F1 scores for the 20% hardest subjects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-augmented Learning of Geodesic Distances in Irregular Domains
  through Soner Boundary Conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rafael I. Cabral Muchacho, Florian T. Pokorny
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Geodesic distances play a fundamental role in robotics, as they efficiently
encode global geometric information of the domain. Recent methods use neural
networks to approximate geodesic distances by solving the Eikonal equation
through physics-informed approaches. While effective, these approaches often
suffer from unstable convergence during training in complex environments. We
propose a framework to learn geodesic distances in irregular domains by using
the Soner boundary condition, and systematically evaluate the impact of data
losses on training stability and solution accuracy. Our experiments demonstrate
that incorporating data losses significantly improves convergence robustness,
reducing training instabilities and sensitivity to initialization. These
findings suggest that hybrid data-physics approaches can effectively enhance
the reliability of learning-based geodesic distance solvers with sparse data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta Learning not to Learn: Robustly Informing Meta-Learning under
  Nuisance-Varying Families 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04570v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04570v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Louis McConnell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In settings where both spurious and causal predictors are available, standard
neural networks trained under the objective of empirical risk minimization
(ERM) with no additional inductive biases tend to have a dependence on a
spurious feature. As a result, it is necessary to integrate additional
inductive biases in order to guide the network toward generalizable hypotheses.
Often these spurious features are shared across related tasks, such as
estimating disease prognoses from image scans coming from different hospitals,
making the challenge of generalization more difficult. In these settings, it is
important that methods are able to integrate the proper inductive biases to
generalize across both nuisance-varying families as well as task families.
Motivated by this setting, we present RIME (Robustly Informed Meta lEarning), a
new method for meta learning under the presence of both positive and negative
inductive biases (what to learn and what not to learn). We first develop a
theoretical causal framework showing why existing approaches at knowledge
integration can lead to worse performance on distributionally robust
objectives. We then show that RIME is able to simultaneously integrate both
biases, reaching state of the art performance under distributionally robust
objectives in informed meta-learning settings under nuisance-varying families.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compositional Causal Reasoning Evaluation in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacqueline R. M. A. Maasch, Alihan Hüyük, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal reasoning and compositional reasoning are two core aspirations in
generative AI. Measuring the extent of these behaviors requires principled
evaluation methods. We explore a unified perspective that considers both
behaviors simultaneously, termed compositional causal reasoning (CCR): the
ability to infer how causal measures compose and, equivalently, how causal
quantities propagate through graphs. We instantiate a framework for the
systematic evaluation of CCR for the average treatment effect and the
probability of necessity and sufficiency. As proof of concept, we demonstrate
the design of CCR tasks for language models in the LLama, Phi, and GPT
families. On a math word problem, our framework revealed a range of
taxonomically distinct error patterns. Additionally, CCR errors increased with
the complexity of causal paths for all models except o1.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Federated Dynamic Modeling and Learning for Spatiotemporal Data
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04528v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04528v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thien Pham, Angelo Furno, Faïcel Chamroukhi, Latifa Oukhellou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an advanced Federated Learning (FL) framework for
forecasting complex spatiotemporal data, improving upon recent state-of-the-art
models. In the proposed approach, the original Gated Recurrent Unit (GRU)
module within previous Dynamic Spatial--Temporal Graph Convolutional Recurrent
Network (DSTGCRN) modeling is first replaced with a Long Short-Term Memory
(LSTM) network, enabling the resulting model to more effectively capture
long-term dependencies inherent to time series data. The resulting architecture
significantly improves the model's capacity to handle complex temporal patterns
in diverse forecasting applications. Furthermore, the proposed FL framework
integrates a novel Client-Side Validation (CSV) mechanism, introducing a
critical validation step at the client level before incorporating aggregated
parameters from the central server into local models. This ensures that only
the most effective updates are adopted, improving both the robustness and
accuracy of the forecasting model across clients. The efficiency of our
approach is demonstrated through extensive experiments on real-world
applications, including public datasets for multimodal transport demand
forecasting and private datasets for Origin-Destination (OD) matrix forecasting
in urban areas. The results demonstrate substantial improvements over
conventional methods, highlighting the framework's ability to capture complex
spatiotemporal dependencies while preserving data privacy. This work not only
provides a scalable and privacy-preserving solution for real-time,
region-specific forecasting and management but also underscores the potential
of leveraging distributed data sources in a FL context. We provide our
algorithms as open-source on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging priors on distribution functions for multi-arm bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04518v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04518v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sumit Vashishtha, Odalric-Ambrym Maillard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Dirichlet Process Posterior Sampling (DPPS), a Bayesian
non-parametric algorithm for multi-arm bandits based on Dirichlet Process (DP)
priors. Like Thompson-sampling, DPPS is a probability-matching algorithm, i.e.,
it plays an arm based on its posterior-probability of being optimal. Instead of
assuming a parametric class for the reward generating distribution of each arm,
and then putting a prior on the parameters, in DPPS the reward generating
distribution is directly modeled using DP priors. DPPS provides a principled
approach to incorporate prior belief about the bandit environment, and in the
noninformative limit of the DP posteriors (i.e. Bayesian Bootstrap), we recover
Non Parametric Thompson Sampling (NPTS), a popular non-parametric bandit
algorithm, as a special case of DPPS. We employ stick-breaking representation
of the DP priors, and show excellent empirical performance of DPPS in
challenging synthetic and real world bandit environments. Finally, using an
information-theoretic analysis, we show non-asymptotic optimality of DPPS in
the Bayesian regret setup.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saif Anwar, Nathan Griffiths, Thomas Popham, Abhir Bhalerao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent improvements in the expressive power of spatio-temporal models have
led to performance gains in many real-world applications, such as traffic
forecasting and social network modelling. However, understanding the
predictions from a model is crucial to ensure reliability and trustworthiness,
particularly for high-risk applications, such as healthcare and transport. Few
existing methods are able to generate explanations for models trained on
continuous-time dynamic graph data and, of these, the computational complexity
and lack of suitable explanation objectives pose challenges. In this paper, we
propose $\textbf{S}$patio-$\textbf{T}$emporal E$\textbf{X}$planation
$\textbf{Search}$ (STX-Search), a novel method for generating instance-level
explanations that is applicable to static and dynamic temporal graph
structures. We introduce a novel search strategy and objective function, to
find explanations that are highly faithful and interpretable. When compared
with existing methods, STX-Search produces explanations of higher fidelity
whilst optimising explanation size to maintain interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Morse Transform for Drug Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04507v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04507v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander M. Tanaka, Aras T. Asaad, Richard Cooper, Vidit Nanda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a new ligand-based virtual screening (LBVS) framework that uses
piecewise linear (PL) Morse theory to predict ligand binding potential. We
model ligands as simplicial complexes via a pruned Delaunay triangulation, and
catalogue the critical points across multiple directional height functions.
This produces a rich feature vector, consisting of crucial topological features
-- peaks, troughs, and saddles -- that characterise ligand surfaces relevant to
binding interactions. Unlike contemporary LBVS methods that rely on
computationally-intensive deep neural networks, we require only a lightweight
classifier. The Morse theoretic approach achieves state-of-the-art performance
on standard datasets while offering an interpretable feature vector and
scalable method for ligand prioritization in early-stage drug discovery.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 5 main figures, 2 main tables, 6 supplementary figures and
  4 supplementary tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Object Placement Programs for Indoor Scene Synthesis with
  Iterative Self Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrian Chang, Kai Wang, Yuanbo Li, Manolis Savva, Angel X. Chang, Daniel Ritchie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data driven and autoregressive indoor scene synthesis systems generate indoor
scenes automatically by suggesting and then placing objects one at a time.
Empirical observations show that current systems tend to produce incomplete
next object location distributions. We introduce a system which addresses this
problem. We design a Domain Specific Language (DSL) that specifies functional
constraints. Programs from our language take as input a partial scene and
object to place. Upon execution they predict possible object placements. We
design a generative model which writes these programs automatically. Available
3D scene datasets do not contain programs to train on, so we build upon
previous work in unsupervised program induction to introduce a new program
bootstrapping algorithm. In order to quantify our empirical observations we
introduce a new evaluation procedure which captures how well a system models
per-object location distributions. We ask human annotators to label all the
possible places an object can go in a scene and show that our system produces
per-object location distributions more consistent with human annotators. Our
system also generates indoor scenes of comparable quality to previous systems
and while previous systems degrade in performance when training data is sparse,
our system does not degrade to the same degree.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 20 figures Subjects: Graphics (cs.GR), Computer Vision and
  Pattern Recognition (cs.CV), Machine Learning (cs.LG)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accurate predictive model of band gap with selected important features
  based on explainable machine learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joohwi Lee, Kaito Miyamoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly advancing field of materials informatics, nonlinear machine
learning models have demonstrated exceptional predictive capabilities for
material properties. However, their black-box nature limits interpretability,
and they may incorporate features that do not contribute to, or even
deteriorate, model performance. This study employs explainable ML (XML)
techniques, including permutation feature importance and the SHapley Additive
exPlanation, applied to a pristine support vector regression model designed to
predict band gaps at the GW level using 18 input features. Guided by
XML-derived individual feature importance, a simple framework is proposed to
construct reduced-feature predictive models. Model evaluations indicate that an
XML-guided compact model, consisting of the top five features, achieves
comparable accuracy to the pristine model on in-domain datasets while
demonstrating superior generalization with lower prediction errors on
out-of-domain data. Additionally, the study underscores the necessity for
eliminating strongly correlated features to prevent misinterpretation and
overestimation of feature importance before applying XML. This study highlights
XML's effectiveness in developing simplified yet highly accurate machine
learning models by clarifying feature roles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 4 figures, SI is included</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InfoSEM: A Deep Generative Model with Informative Priors for Gene
  Regulatory Network Inference <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04483v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04483v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyu Cui, Song-Jun Xu, Artem Moskalev, Shuwei Li, Tommaso Mansi, Mangal Prakash, Rui Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inferring Gene Regulatory Networks (GRNs) from gene expression data is
crucial for understanding biological processes. While supervised models are
reported to achieve high performance for this task, they rely on costly ground
truth (GT) labels and risk learning gene-specific biases, such as class
imbalances of GT interactions, rather than true regulatory mechanisms. To
address these issues, we introduce InfoSEM, an unsupervised generative model
that leverages textual gene embeddings as informative priors, improving GRN
inference without GT labels. InfoSEM can also integrate GT labels as an
additional prior when available, avoiding biases and further enhancing
performance. Additionally, we propose a biologically motivated benchmarking
framework that better reflects real-world applications such as biomarker
discovery and reveals learned biases of existing supervised methods. InfoSEM
outperforms existing models by 38.5% across four datasets using textual
embeddings prior and further boosts performance by 11.1% when integrating
labeled data as priors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 AI4NA Oral, ICLR 2025 MLGenX Spotlight, ICLR 2025 LMRL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generalized Interpolating Discrete Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitri von Rütte, Janis Fluri, Yuhui Ding, Antonio Orvieto, Bernhard Schölkopf, Thomas Hofmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While state-of-the-art language models achieve impressive results through
next-token prediction, they have inherent limitations such as the inability to
revise already generated tokens. This has prompted exploration of alternative
approaches such as discrete diffusion. However, masked diffusion, which has
emerged as a popular choice due to its simplicity and effectiveness,
reintroduces this inability to revise words. To overcome this, we generalize
masked diffusion and derive the theoretical backbone of a family of general
interpolating discrete diffusion (GIDD) processes offering greater flexibility
in the design of the noising processes. Leveraging a novel diffusion ELBO, we
achieve compute-matched state-of-the-art performance in diffusion language
modeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining
masking and uniform noise, leading to improved sample quality and unlocking the
ability for the model to correct its own mistakes, an area where autoregressive
models notoriously have struggled. Our code and models are open-source:
https://github.com/dvruette/gidd/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Poisoning Bayesian Inference via Data Deletion and Replication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthieu Carreau, Roi Naveiro, William N. Caballero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research in adversarial machine learning (AML) has shown that statistical
models are vulnerable to maliciously altered data. However, despite advances in
Bayesian machine learning models, most AML research remains concentrated on
classical techniques. Therefore, we focus on extending the white-box model
poisoning paradigm to attack generic Bayesian inference, highlighting its
vulnerability in adversarial contexts. A suite of attacks are developed that
allow an attacker to steer the Bayesian posterior toward a target distribution
through the strategic deletion and replication of true observations, even when
only sampling access to the posterior is available. Analytic properties of
these algorithms are proven and their performance is empirically examined in
both synthetic and real-world scenarios. With relatively little effort, the
attacker is able to substantively alter the Bayesian's beliefs and, by
accepting more risk, they can mold these beliefs to their will. By carefully
constructing the adversarial posterior, surgical poisoning is achieved such
that only targeted inferences are corrupted and others are minimally disturbed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Know Thy Judge: On the Robustness Meta-Evaluation of LLM Safety Judges <span class="chip">ICLR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisco Eiras, Eliott Zemour, Eric Lin, Vaikkunth Mugunthan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM) based judges form the underpinnings of key safety
evaluation processes such as offline benchmarking, automated red-teaming, and
online guardrailing. This widespread requirement raises the crucial question:
can we trust the evaluations of these evaluators? In this paper, we highlight
two critical challenges that are typically overlooked: (i) evaluations in the
wild where factors like prompt sensitivity and distribution shifts can affect
performance and (ii) adversarial attacks that target the judge. We highlight
the importance of these through a study of commonly used safety judges, showing
that small changes such as the style of the model output can lead to jumps of
up to 0.24 in the false negative rate on the same dataset, whereas adversarial
attacks on the model generation can fool some judges into misclassifying 100%
of harmful generations as safe ones. These findings reveal gaps in commonly
used meta-evaluation benchmarks and weaknesses in the robustness of current LLM
judges, indicating that low attack success under certain judges could create a
false sense of security.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the ICBINB Workshop at ICLR'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04472v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04472v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Shen, Jian Zhang, Jieyun Huang, Shuming Shi, Wenjing Zhang, Jiangze Yan, Ning Wang, Kai Wang, Shiguo Lian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in slow-thinking reasoning models have shown exceptional
performance in complex reasoning tasks. However, these models often exhibit
overthinking-generating redundant reasoning steps for simple problems, leading
to excessive computational resource usage. While current mitigation strategies
uniformly reduce reasoning tokens, they risk degrading performance on
challenging tasks that require extended reasoning. This paper introduces
Difficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models
to autonomously adjust the length of Chain-of-Thought(CoT) based on problem
difficulty. We first propose a Token Length Budget (TLB) metric to quantify
difficulty, then leveraging length-aware reward shaping and length preference
optimization to implement DAST. DAST penalizes overlong responses for simple
tasks while incentivizing sufficient reasoning for complex problems.
Experiments on diverse datasets and model scales demonstrate that DAST
effectively mitigates overthinking (reducing token usage by over 30\% on
average) while preserving reasoning accuracy on complex problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>working in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An artificially intelligent magnetic resonance spectroscopy
  quantification method: Comparison between QNet and LCModel on the cloud
  computing platform CloudBrain-MRS 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meijin Lin, Lin Guo, Dicheng Chen, Jianshu Chen, Zhangren Tu, Xu Huang, Jianhua Wang, Ji Qi, Yuan Long, Zhiguo Huang, Di Guo, Xiaobo Qu, Haiwei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objctives: This work aimed to statistically compare the metabolite
quantification of human brain magnetic resonance spectroscopy (MRS) between the
deep learning method QNet and the classical method LCModel through an
easy-to-use intelligent cloud computing platform CloudBrain-MRS. Materials and
Methods: In this retrospective study, two 3 T MRI scanners Philips Ingenia and
Achieva collected 61 and 46 in vivo 1H magnetic resonance (MR) spectra of
healthy participants, respectively, from the brain region of pregenual anterior
cingulate cortex from September to October 2021. The analyses of Bland-Altman,
Pearson correlation and reasonability were performed to assess the degree of
agreement, linear correlation and reasonability between the two quantification
methods. Results: Fifteen healthy volunteers (12 females and 3 males, age
range: 21-35 years, mean age/standard deviation = 27.4/3.9 years) were
recruited. The analyses of Bland-Altman, Pearson correlation and reasonability
showed high to good consistency and very strong to moderate correlation between
the two methods for quantification of total N-acetylaspartate (tNAA), total
choline (tCho), and inositol (Ins) (relative half interval of limits of
agreement = 3.04%, 9.3%, and 18.5%, respectively; Pearson correlation
coefficient r = 0.775, 0.927, and 0.469, respectively). In addition,
quantification results of QNet are more likely to be closer to the previous
reported average values than those of LCModel. Conclusion: There were high or
good degrees of consistency between the quantification results of QNet and
LCModel for tNAA, tCho, and Ins, and QNet generally has more reasonable
quantification than LCModel.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PALo: Learning Posture-Aware Locomotion for Quadruped Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Miao, Jun Sun, Hang Lai, Xinpeng Di, Jiahang Cao, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of embodied intelligence, locomotion control of
quadruped robots on complex terrains has become a research hotspot. Unlike
traditional locomotion control approaches focusing solely on velocity tracking,
we pursue to balance the agility and robustness of quadruped robots on diverse
and complex terrains. To this end, we propose an end-to-end deep reinforcement
learning framework for posture-aware locomotion named PALo, which manages to
handle simultaneous linear and angular velocity tracking and real-time
adjustments of body height, pitch, and roll angles. In PALo, the locomotion
control problem is formulated as a partially observable Markov decision
process, and an asymmetric actor-critic architecture is adopted to overcome the
sim-to-real challenge. Further, by incorporating customized training curricula,
PALo achieves agile posture-aware locomotion control in simulated environments
and successfully transfers to real-world settings without fine-tuning, allowing
real-time control of the quadruped robot's locomotion and body posture across
challenging terrains. Through in-depth experimental analysis, we identify the
key components of PALo that contribute to its performance, further validating
the effectiveness of the proposed method. The results of this study provide new
possibilities for the low-level locomotion control of quadruped robots in
higher dimensional command spaces and lay the foundation for future research on
upper-level modules for embodied intelligence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reproducibility Assessment of Magnetic Resonance Spectroscopy of
  Pregenual Anterior Cingulate Cortex across Sessions and Vendors via the Cloud
  Computing Platform CloudBrain-MRS 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04453v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04453v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runhan Chen, Meijin Lin, Jianshu Chen, Liangjie Lin, Jiazheng Wang, Xiaoqing Li, Jianhua Wang, Xu Huang, Ling Qian, Shaoxing Liu, Yuan Long, Di Guo, Xiaobo Qu, Haiwei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given the need to elucidate the mechanisms underlying illnesses and their
treatment, as well as the lack of harmonization of acquisition and
post-processing protocols among different magnetic resonance system vendors,
this work is to determine if metabolite concentrations obtained from different
sessions, machine models and even different vendors of 3 T scanners can be
highly reproducible and be pooled for diagnostic analysis, which is very
valuable for the research of rare diseases. Participants underwent magnetic
resonance imaging (MRI) scanning once on two separate days within one week (one
session per day, each session including two proton magnetic resonance
spectroscopy (1H-MRS) scans with no more than a 5-minute interval between scans
(no off-bed activity)) on each machine. were analyzed for reliability of
within- and between- sessions using the coefficient of variation (CV) and
intraclass correlation coefficient (ICC), and for reproducibility of across the
machines using correlation coefficient. As for within- and between- session,
all CV values for a group of all the first or second scans of a session, or for
a session were almost below 20%, and most of the ICCs for metabolites range
from moderate (0.4-0.59) to excellent (0.75-1), indicating high data
reliability. When it comes to the reproducibility across the three scanners,
all Pearson correlation coefficients across the three machines approached 1
with most around 0.9, and majority demonstrated statistical significance
(P<0.01). Additionally, the intra-vendor reproducibility was greater than the
inter-vendor ones.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Privacy Preserving and Robust Aggregation for Cross-Silo Federated
  Learning in Non-IID Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04451v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04451v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marco Arazzi, Mert Cihangiroglu, Antonino Nocera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Averaging remains the most widely used aggregation strategy in
federated learning due to its simplicity and scalability. However, its
performance degrades significantly in non-IID data settings, where client
distributions are highly imbalanced or skewed. Additionally, it relies on
clients transmitting metadata, specifically the number of training samples,
which introduces privacy risks and may conflict with regulatory frameworks like
the European GDPR. In this paper, we propose a novel aggregation strategy that
addresses these challenges by introducing class-aware gradient masking. Unlike
traditional approaches, our method relies solely on gradient updates,
eliminating the need for any additional client metadata, thereby enhancing
privacy protection. Furthermore, our approach validates and dynamically weights
client contributions based on class-specific importance, ensuring robustness
against non-IID distributions, convergence prevention, and backdoor attacks.
Extensive experiments on benchmark datasets demonstrate that our method not
only outperforms FedAvg and other widely accepted aggregation strategies in
non-IID settings but also preserves model integrity in adversarial scenarios.
Our results establish the effectiveness of gradient masking as a practical and
secure solution for federated learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Graph-Partitioning Based Continuous Optimization Approach to
  Semi-supervised Clustering Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04447v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04447v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Liu, Xin Liu, Michael K. Ng, Zaikun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semi-supervised clustering is a basic problem in various applications. Most
existing methods require knowledge of the ideal cluster number, which is often
difficult to obtain in practice. Besides, satisfying the must-link constraints
is another major challenge for these methods. In this work, we view the
semi-supervised clustering task as a partitioning problem on a graph associated
with the given dataset, where the similarity matrix includes a scaling
parameter to reflect the must-link constraints. Utilizing a relaxation
technique, we formulate the graph partitioning problem into a continuous
optimization model that does not require the exact cluster number, but only an
overestimate of it. We then propose a block coordinate descent algorithm to
efficiently solve this model, and establish its convergence result. Based on
the obtained solution, we can construct the clusters that theoretically meet
the must-link constraints under mild assumptions. Furthermore, we verify the
effectiveness and efficiency of our proposed method through comprehensive
numerical experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FORTALESA: Fault-Tolerant Reconfigurable Systolic Array for DNN
  Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Natalia Cherezova, Artur Jutman, Maksim Jenihhin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of Deep Neural Networks (DNNs) in mission- and safety-critical
applications brings their reliability to the front. High performance demands of
DNNs require the use of specialized hardware accelerators. Systolic array
architecture is widely used in DNN accelerators due to its parallelism and
regular structure. This work presents a run-time reconfigurable systolic array
architecture with three execution modes and four implementation options. All
four implementations are evaluated in terms of resource utilization,
throughput, and fault tolerance improvement. The proposed architecture is used
for reliability enhancement of DNN inference on systolic array through
heterogeneous mapping of different network layers to different execution modes.
The approach is supported by a novel reliability assessment method based on
fault propagation analysis. It is used for the exploration of the appropriate
execution mode-layer mapping for DNN inference. The proposed architecture
efficiently protects registers and MAC units of systolic array PEs from
transient and permanent faults. The reconfigurability feature enables a speedup
of up to $3\times$, depending on layer vulnerability. Furthermore, it requires
$6\times$ less resources compared to static redundancy and $2.5\times$ less
resources compared to the previously proposed solution for transient faults.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Determinant Estimation under Memory Constraints and Neural Scaling Laws 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04424v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04424v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siavash Ameli, Chris van der Heide, Liam Hodgkinson, Fred Roosta, Michael W. Mahoney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Calculating or accurately estimating log-determinants of large positive
semi-definite matrices is of fundamental importance in many machine learning
tasks. While its cubic computational complexity can already be prohibitive, in
modern applications, even storing the matrices themselves can pose a memory
bottleneck. To address this, we derive a novel hierarchical algorithm based on
block-wise computation of the LDL decomposition for large-scale log-determinant
calculation in memory-constrained settings. In extreme cases where matrices are
highly ill-conditioned, accurately computing the full matrix itself may be
infeasible. This is particularly relevant when considering kernel matrices at
scale, including the empirical Neural Tangent Kernel (NTK) of neural networks
trained on large datasets. Under the assumption of neural scaling laws in the
test error, we show that the ratio of pseudo-determinants satisfies a power-law
relationship, allowing us to derive corresponding scaling laws. This enables
accurate estimation of NTK log-determinants from a tiny fraction of the full
dataset; in our experiments, this results in a $\sim$100,000$\times$ speedup
with improved accuracy over competing approximations. Using these techniques,
we successfully estimate log-determinants for dense matrices of extreme sizes,
which were previously deemed intractable and inaccessible due to their enormous
scale and computational demands.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AOLO: Analysis and Optimization For Low-Carbon Oriented Wireless Large
  Language Model Services 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04418v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04418v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoqi Wang, Hongyang Du, Yuehong Gao, Dong In Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have led to their
widespread adoption and large-scale deployment across various domains. However,
their environmental impact, particularly during inference, has become a growing
concern due to their substantial energy consumption and carbon footprint.
Existing research has focused on inference computation alone, overlooking the
analysis and optimization of carbon footprint in network-aided LLM service
systems. To address this gap, we propose AOLO, a framework for analysis and
optimization for low-carbon oriented wireless LLM services. AOLO introduces a
comprehensive carbon footprint model that quantifies greenhouse gas emissions
across the entire LLM service chain, including computational inference and
wireless communication. Furthermore, we formulate an optimization problem aimed
at minimizing the overall carbon footprint, which is solved through joint
optimization of inference outputs and transmit power under
quality-of-experience and system performance constraints. To achieve this joint
optimization, we leverage the energy efficiency of spiking neural networks
(SNNs) by adopting SNN as the actor network and propose a low-carbon-oriented
optimization algorithm, i.e., SNN-based deep reinforcement learning (SDRL).
Comprehensive simulations demonstrate that SDRL algorithm significantly reduces
overall carbon footprint, achieving an 18.77% reduction compared to the
benchmark soft actor-critic, highlighting its potential for enabling more
sustainable LLM inference services.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning <span class="highlight-title">Transformer</span>-based World Models with Contrastive Predictive
  Coding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxime Burchi, Radu Timofte
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The DreamerV3 algorithm recently obtained remarkable performance across
diverse environment domains by learning an accurate world model based on
Recurrent Neural Networks (RNNs). Following the success of model-based
reinforcement learning algorithms and the rapid adoption of the Transformer
architecture for its superior training efficiency and favorable scaling
properties, recent works such as STORM have proposed replacing RNN-based world
models with Transformer-based world models using masked self-attention.
However, despite the improved training efficiency of these methods, their
impact on performance remains limited compared to the Dreamer algorithm,
struggling to learn competitive Transformer-based world models. In this work,
we show that the next state prediction objective adopted in previous approaches
is insufficient to fully exploit the representation capabilities of
Transformers. We propose to extend world model predictions to longer time
horizons by introducing TWISTER (Transformer-based World model wIth contraSTivE
Representations), a world model using action-conditioned Contrastive Predictive
Coding to learn high-level temporal feature representations and improve the
agent performance. TWISTER achieves a human-normalized mean score of 162% on
the Atari 100k benchmark, setting a new record among state-of-the-art methods
that do not employ look-ahead search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training-Free Graph Filtering via Multimodal Feature Refinement for
  Extremely Fast Multimodal Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04406v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04406v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Seung Roh, Joo-Young Kim, Jin-Duk Park, Won-Yong Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal recommender systems improve the performance of canonical
recommender systems with no item features by utilizing diverse content types
such as text, images, and videos, while alleviating inherent sparsity of
user-item interactions and accelerating user engagement. However, current
neural network-based models often incur significant computational overhead due
to the complex training process required to learn and integrate information
from multiple modalities. To overcome this limitation, we propose
MultiModal-Graph Filtering (MM-GF), a training-free method based on the notion
of graph filtering (GF) for efficient and accurate multimodal recommendations.
Specifically, MM-GF first constructs multiple similarity graphs through
nontrivial multimodal feature refinement such as robust scaling and vector
shifting by addressing the heterogeneous characteristics across modalities.
Then, MM-GF optimally fuses multimodal information using linear low-pass
filters across different modalities. Extensive experiments on real-world
benchmark datasets demonstrate that MM-GF not only improves recommendation
accuracy by up to 13.35% compared to the best competitor but also dramatically
reduces computational costs by achieving the runtime of less than 10 seconds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Temporal Analysis of NetFlow <span class="highlight-title">Dataset</span>s for Network Intrusion Detection
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04404v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04404v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Majed Luay, Siamak Layeghy, Seyedehfaezeh Hosseininoorbin, Mohanad Sarhan, Nour Moustafa, Marius Portmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the temporal analysis of NetFlow datasets for machine
learning (ML)-based network intrusion detection systems (NIDS). Although many
previous studies have highlighted the critical role of temporal features, such
as inter-packet arrival time and flow length/duration, in NIDS, the currently
available NetFlow datasets for NIDS lack these temporal features. This study
addresses this gap by creating and making publicly available a set of NetFlow
datasets that incorporate these temporal features [1]. With these temporal
features, we provide a comprehensive temporal analysis of NetFlow datasets by
examining the distribution of various features over time and presenting
time-series representations of NetFlow features. This temporal analysis has not
been previously provided in the existing literature. We also borrowed an idea
from signal processing, time frequency analysis, and tested it to see how
different the time frequency signal presentations (TFSPs) are for various
attacks. The results indicate that many attacks have unique patterns, which
could help ML models to identify them more easily.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Speculative MoE: Communication Efficient Parallel MoE Inference with
  Speculative Token and Expert Pre-scheduling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04398v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04398v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Li, Pengfei Zheng, Shuang Chen, Zewei Xu, Yunfei Du, Zhengang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MoE (Mixture of Experts) prevails as a neural architecture that can scale
modern transformer-based LLMs (Large Language Models) to unprecedented scales.
Nevertheless, large MoEs' great demands of computing power, memory capacity and
memory bandwidth make scalable serving a fundamental challenge and efficient
parallel inference has become a requisite to attain adequate throughput under
latency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference
framework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP
(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows
DeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is
implemented with costly all-to-all collectives to route token activation. Our
work aims to boost DeepSpeed-MoE by strategically reducing EP's communication
overhead with a technique named Speculative MoE. Speculative MoE has two
speculative parallelization schemes, speculative token shuffling and
speculative expert grouping, which predict outstanding tokens' expert routing
paths and pre-schedule tokens and experts across devices to losslessly trim
EP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE
into a prevailing MoE inference engine SGLang. Experiments show Speculative MoE
can significantly boost state-of-the-art MoE inference frameworks on fast
homogeneous and slow heterogeneous interconnects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Time-varying Factor Augmented Vector Autoregression with Grouped Sparse
  Autoencoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04386v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04386v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiyong Luo, Brooks Paige, Jim Griffin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent economic events, including the global financial crisis and COVID-19
pandemic, have exposed limitations in linear Factor Augmented Vector
Autoregressive (FAVAR) models for forecasting and structural analysis.
Nonlinear dimension techniques, particularly autoencoders, have emerged as
promising alternatives in a FAVAR framework, but challenges remain in
identifiability, interpretability, and integration with traditional nonlinear
time series methods. We address these challenges through two contributions.
First, we introduce a Grouped Sparse autoencoder that employs the
Spike-and-Slab Lasso prior, with parameters under this prior being shared
across variables of the same economic category, thereby achieving
semi-identifiability and enhancing model interpretability. Second, we
incorporate time-varying parameters into the VAR component to better capture
evolving economic dynamics. Our empirical application to the US economy
demonstrates that the Grouped Sparse autoencoder produces more interpretable
factors through its parsimonious structure; and its combination with
time-varying parameter VAR shows superior performance in both point and density
forecasting. Impulse response analysis reveals that monetary policy shocks
during recessions generate more moderate responses with higher uncertainty
compared to expansionary periods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dedicated Feedback and Edit Models Empower Inference-Time Scaling for
  Open-Ended General-Domain Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04378v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04378v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inference-Time Scaling has been critical to the success of recent models such
as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for
inference-time scaling require tasks to have answers that can be verified,
limiting their application to domains such as math, coding and logical
reasoning. We take inspiration from how humans make first attempts, ask for
detailed feedback from others and make improvements based on such feedback
across a wide spectrum of open-ended endeavors. To this end, we collect data
for and train dedicated Feedback and Edit Models that are capable of performing
inference-time scaling for open-ended general-domain tasks. In our setup, one
model generates an initial response, which are given feedback by a second
model, that are then used by a third model to edit the response. We show that
performance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo
can be boosted by scaling the number of initial response drafts, effective
feedback and edited responses. When scaled optimally, our setup based on 70B
models from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7
as of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and
DeepSeek R1 with 92.3.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How can representation dimension dominate structurally pruned LLMs? <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04377v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04377v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingxue Xu, Lisa Alazraki, Danilo P. Mandic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pruning assumes a subnetwork exists in the original deep neural network,
which can achieve comparative model performance with less computation than the
original. However, it is unclear how the model performance varies with the
different subnetwork extractions. In this paper, we choose the representation
dimension (or embedding dimension, model dimension, the dimension of the
residual stream in the relevant literature) as the entry point to this issue.
We investigate the linear transformations in the LLM transformer blocks and
consider a specific structured pruning approach, SliceGPT, to extract the
subnetworks of different representation dimensions. We mechanistically analyse
the activation flow during the model forward passes, and find the
representation dimension dominates the linear transformations, model
predictions, and, finally, the model performance. Explicit analytical relations
are given to calculate the pruned model performance (perplexity and accuracy)
without actual evaluation, and are empirically validated with
Llama-3-8B-Instruct and Phi-3-mini-4k-Instruct.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Workshop on Sparsity in LLMs (SLLM)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ When Can You Get Away with Low Memory Adam? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01843v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01843v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dayal Singh Kalra, John Kirchenbauer, Maissam Barkeshli, Tom Goldstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adam is the go-to optimizer for training modern machine learning models, but
it requires additional memory to maintain the moving averages of the gradients
and their squares. While various low-memory optimizers have been proposed that
sometimes match the performance of Adam, their lack of reliability has left
Adam as the default choice. In this work, we apply a simple layer-wise
Signal-to-Noise Ratio (SNR) analysis to quantify when second-moment tensors can
be effectively replaced by their means across different dimensions. Our SNR
analysis reveals how architecture, training hyperparameters, and dataset
properties impact compressibility along Adam's trajectory, naturally leading to
$\textit{SlimAdam}$, a memory-efficient Adam variant. $\textit{SlimAdam}$
compresses the second moments along dimensions with high SNR when feasible, and
leaves when compression would be detrimental. Through experiments across a
diverse set of architectures and training scenarios, we show that
$\textit{SlimAdam}$ matches Adam's performance and stability while saving up to
$98\%$ of total second moments. Code for $\textit{SlimAdam}$ is available at
https://github.com/dayal-kalra/low-memory-adam.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Acknowledgement updates and minor writing edits</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02800v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02800v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alicia Russell-Gilbert, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jabour, Thomas Arnold, Joshua Church
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection in complex industrial environments poses unique challenges,
particularly in contexts characterized by data sparsity and evolving
operational conditions. Predictive maintenance (PdM) in such settings demands
methodologies that are adaptive, transferable, and capable of integrating
domain-specific knowledge. In this paper, we present RAAD-LLM, a novel
framework for adaptive anomaly detection, leveraging large language models
(LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach
addresses the aforementioned PdM challenges. By effectively utilizing
domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time
series data without requiring fine-tuning on specific datasets. The framework's
adaptability mechanism enables it to adjust its understanding of normal
operating conditions dynamically, thus increasing detection accuracy. We
validate this methodology through a real-world application for a plastics
manufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show
significant improvements over our previous model with an accuracy increase from
70.7% to 89.1% on the real-world dataset. By allowing for the enriching of
input series data with semantics, RAAD-LLM incorporates multimodal capabilities
that facilitate more collaborative decision-making between the model and plant
operators. Overall, our findings support RAAD-LLM's ability to revolutionize
anomaly detection methodologies in PdM, potentially leading to a paradigm shift
in how anomaly detection is implemented across various industries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2411.00914</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Last Iterate Advantage: Empirical Auditing and Principled Heuristic
  Analysis of Differentially Private SGD <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06186v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06186v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Steinke, Milad Nasr, Arun Ganesh, Borja Balle, Christopher A. Choquette-Choo, Matthew Jagielski, Jamie Hayes, Abhradeep Guha Thakurta, Adam Smith, Andreas Terzis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a simple heuristic privacy analysis of noisy clipped stochastic
gradient descent (DP-SGD) in the setting where only the last iterate is
released and the intermediate iterates remain hidden. Namely, our heuristic
assumes a linear structure for the model.
  We show experimentally that our heuristic is predictive of the outcome of
privacy auditing applied to various training procedures. Thus it can be used
prior to training as a rough estimate of the final privacy leakage. We also
probe the limitations of our heuristic by providing some artificial
counterexamples where it underestimates the privacy leakage.
  The standard composition-based privacy analysis of DP-SGD effectively assumes
that the adversary has access to all intermediate iterates, which is often
unrealistic. However, this analysis remains the state of the art in practice.
While our heuristic does not replace a rigorous privacy analysis, it
illustrates the large gap between the best theoretical upper bounds and the
privacy auditing lower bounds and sets a target for further work to improve the
theoretical privacy analyses. We also empirically support our heuristic and
show existing privacy auditing attacks are bounded by our heuristic analysis in
both vision and language tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Some Targets Are Harder to Identify than Others: Quantifying the
  Target-dependent Membership Leakage <span class="chip">AISTATS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.10065v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.10065v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Achraf Azize, Debabrota Basu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In a Membership Inference (MI) game, an attacker tries to infer whether a
target point was included or not in the input of an algorithm. Existing works
show that some target points are easier to identify, while others are harder.
This paper explains the target-dependent hardness of membership attacks by
studying the powers of the optimal attacks in a fixed-target MI game. We
characterise the optimal advantage and trade-off functions of attacks against
the empirical mean in terms of the Mahalanobis distance between the target
point and the data-generating distribution. We further derive the impacts of
two privacy defences, i.e. adding Gaussian noise and sub-sampling, and that of
target misspecification on optimal attacks. As by-products of our novel
analysis of the Likelihood Ratio (LR) test, we provide a new covariance attack
which generalises and improves the scalar product attack. Also, we propose a
new optimal canary-choosing strategy for auditing privacy in the white-box
federated learning setting. Our experiments validate that the Mahalanobis score
explains the hardness of fixed-target MI games.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Appears in AISTATS 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AdaptBot: Combining LLM with Knowledge Graphs and Human Input for
  Generic-to-Specific Task Decomposition and Knowledge Refinement <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02067v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02067v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An embodied agent assisting humans is often asked to complete new tasks, and
there may not be sufficient time or labeled examples to train the agent to
perform these new tasks. Large Language Models (LLMs) trained on considerable
knowledge across many domains can be used to predict a sequence of abstract
actions for completing such tasks, although the agent may not be able to
execute this sequence due to task-, agent-, or domain-specific constraints. Our
framework addresses these challenges by leveraging the generic predictions
provided by LLM and the prior domain knowledge encoded in a Knowledge Graph
(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits
and uses human input as needed to refine its existing knowledge. Based on
experimental evaluation in the context of cooking and cleaning tasks in
simulation domains, we demonstrate that the interplay between LLM, KG, and
human input leads to substantial performance gains compared with just using the
LLM. Project website{\S}: https://sssshivvvv.github.io/adaptbot/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE International Conference on Robotics and Automation
  (ICRA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Systematic Weaknesses in Vision Models along Predefined
  Human-Understandable Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12360v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12360v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sujan Sai Gannamaneni, Rohil Prakash Rao, Michael Mock, Maram Akila, Stefan Wrobel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Slice discovery methods (SDMs) are prominent algorithms for finding
systematic weaknesses in DNNs. They identify top-k semantically coherent
slices/subsets of data where a DNN-under-test has low performance. For being
directly useful, slices should be aligned with human-understandable and
relevant dimensions, which, for example, are defined by safety and domain
experts as part of the operational design domain (ODD). While SDMs can be
applied effectively on structured data, their application on image data is
complicated by the lack of semantic metadata. To address these issues, we
present an algorithm that combines foundation models for zero-shot image
classification to generate semantic metadata with methods for combinatorial
search to find systematic weaknesses in images. In contrast to existing
approaches, ours identifies weak slices that are in line with pre-defined
human-understandable dimensions. As the algorithm includes foundation models,
its intermediate and final results may not always be exact. Therefore, we
include an approach to address the impact of noisy metadata. We validate our
algorithm on both synthetic and real-world datasets, demonstrating its ability
to recover human-understandable systematic weaknesses. Furthermore, using our
approach, we identify systematic weaknesses of multiple pre-trained and
publicly available state-of-the-art computer vision DNNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Back Home: A Machine Learning Approach to Seashell Classification and
  Ecosystem Restoration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04873v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04873v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Valverde, Luis Solano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Costa Rica, an average of 5 tons of seashells are extracted from
ecosystems annually. Confiscated seashells, cannot be returned to their
ecosystems due to the lack of origin recognition. To address this issue, we
developed a convolutional neural network (CNN) specifically for seashell
identification. We built a dataset from scratch, consisting of approximately
19000 images from the Pacific and Caribbean coasts. Using this dataset, the
model achieved a classification accuracy exceeding 85%. The model has been
integrated into a user-friendly application, which has classified over 36,000
seashells to date, delivering real-time results within 3 seconds per image. To
further enhance the system's accuracy, an anomaly detection mechanism was
incorporated to filter out irrelevant or anomalous inputs, ensuring only valid
seashell images are processed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tutorial on amortized optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2202.00665v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2202.00665v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brandon Amos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimization is a ubiquitous modeling tool and is often deployed in settings
which repeatedly solve similar instances of the same problem. Amortized
optimization methods use learning to predict the solutions to problems in these
settings, exploiting the shared structure between similar problem instances.
These methods have been crucial in variational inference and reinforcement
learning and are capable of solving optimization problems many orders of
magnitudes times faster than traditional optimization methods that do not use
amortization. This tutorial presents an introduction to the amortized
optimization foundations behind these advancements and overviews their
applications in variational inference, sparse coding, gradient-based
meta-learning, control, reinforcement learning, convex optimization, optimal
transport, and deep equilibrium networks. The source code for this tutorial is
available at
https://github.com/facebookresearch/amortized-optimization-tutorial.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Foundations and Trends in Machine Learning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Simple and Effective Reinforcement Learning Method for Text-to-Image
  Diffusion Fine-tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00897v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00897v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shashank Gupta, Chaitanya Ahuja, Tsung-Yu Lin, Sreya Dutta Roy, Harrie Oosterhuis, Maarten de Rijke, Satya Narayan Shukla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful
approach for aligning diffusion models with black-box objectives. Proximal
policy optimization (PPO) is the most popular choice of method for policy
optimization. While effective in terms of performance, PPO is highly sensitive
to hyper-parameters and involves substantial computational overhead. REINFORCE,
on the other hand, mitigates some computational complexities such as high
memory overhead and sensitive hyper-parameter tuning, but has suboptimal
performance due to high-variance and sample inefficiency. While the variance of
the REINFORCE can be reduced by sampling multiple actions per input prompt and
using a baseline correction term, it still suffers from sample inefficiency. To
address these challenges, we systematically analyze the
efficiency-effectiveness trade-off between REINFORCE and PPO, and propose
leave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP
combines variance reduction techniques from REINFORCE, such as sampling
multiple actions per input prompt and a baseline correction term, with the
robustness and sample efficiency of PPO via clipping and importance sampling.
Our results demonstrate that LOOP effectively improves diffusion models on
various black-box objectives, and achieves a better balance between
computational efficiency and performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Human-Feedback Efficient Reinforcement Learning for Online Diffusion
  Model Finetuning <span class="chip">ICLR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05116v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05116v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable generation through Stable Diffusion (SD) fine-tuning aims to
improve fidelity, safety, and alignment with human guidance. Existing
reinforcement learning from human feedback methods usually rely on predefined
heuristic reward functions or pretrained reward models built on large-scale
datasets, limiting their applicability to scenarios where collecting such data
is costly or difficult. To effectively and efficiently utilize human feedback,
we develop a framework, HERO, which leverages online human feedback collected
on the fly during model learning. Specifically, HERO features two key
mechanisms: (1) Feedback-Aligned Representation Learning, an online training
method that captures human feedback and provides informative learning signals
for fine-tuning, and (2) Feedback-Guided Image Generation, which involves
generating images from SD's refined initialization samples, enabling faster
convergence towards the evaluator's intent. We demonstrate that HERO is 4x more
efficient in online feedback for body part anomaly correction compared to the
best existing method. Additionally, experiments show that HERO can effectively
handle tasks like reasoning, counting, personalization, and reducing NSFW
content with only 0.5K online feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in International Conference on Learning Representations
  (ICLR) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A learning-based approach to stochastic optimal control under
  reach-avoid constraint 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.16561v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.16561v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingting Ni, Maryam Kamgarpour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop a model-free approach to optimally control stochastic, Markovian
systems subject to a reach-avoid constraint. Specifically, the state trajectory
must remain within a safe set while reaching a target set within a finite time
horizon. Due to the time-dependent nature of these constraints, we show that,
in general, the optimal policy for this constrained stochastic control problem
is non-Markovian, which increases the computational complexity. To address this
challenge, we apply the state-augmentation technique from arXiv:2402.19360,
reformulating the problem as a constrained Markov decision process (CMDP) on an
extended state space. This transformation allows us to search for a Markovian
policy, avoiding the complexity of non-Markovian policies. To learn the optimal
policy without a system model, and using only trajectory data, we develop a
log-barrier policy gradient approach. We prove that under suitable assumptions,
the policy parameters converge to the optimal parameters, while ensuring that
the system trajectories satisfy the stochastic reach-avoid constraint with high
probability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards One Model for Classical Dimensionality Reduction: A
  Probabilistic Perspective on UMAP and t-SNE 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17412v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17412v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aditya Ravuri, Neil D. Lawrence
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper shows that dimensionality reduction methods such as UMAP and
t-SNE, can be approximately recast as MAP inference methods corresponding to a
model introduced in ProbDR, that describes the graph Laplacian (an estimate of
the data precision matrix) using a Wishart distribution, with a mean given by a
non-linear covariance function evaluated on the latents. This interpretation
offers deeper theoretical and semantic insights into such algorithms, by
showing that variances corresponding to these covariances are low (potentially
misspecified), and forging a connection to Gaussian process latent variable
models by showing that well-known kernels can be used to describe covariances
implied by graph Laplacians. We also introduce tools with which similar
dimensionality reduction methods can be studied.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Protein Large Language Models: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17504v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17504v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijia Xiao, Wanjia Zhao, Junkai Zhang, Yiqiao Jin, Han Zhang, Zhicheng Ren, Renliang Sun, Haixin Wang, Guancheng Wan, Pan Lu, Xiao Luo, Yu Zhang, James Zou, Yizhou Sun, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protein-specific large language models (Protein LLMs) are revolutionizing
protein science by enabling more efficient protein structure prediction,
function annotation, and design. While existing surveys focus on specific
aspects or applications, this work provides the first comprehensive overview of
Protein LLMs, covering their architectures, training datasets, evaluation
metrics, and diverse applications. Through a systematic analysis of over 100
articles, we propose a structured taxonomy of state-of-the-art Protein LLMs,
analyze how they leverage large-scale protein sequence data for improved
accuracy, and explore their potential in advancing protein engineering and
biomedical research. Additionally, we discuss key challenges and future
directions, positioning Protein LLMs as essential tools for scientific
discovery in protein science. Resources are maintained at
https://github.com/Yijia-Xiao/Protein-LLM-Survey.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 4 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Streaming Private Continual Counting via Binning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07093v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07093v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joel Daniel Andersson, Rasmus Pagh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In differential privacy, $\textit{continual observation}$ refers to problems
in which we wish to continuously release a function of a dataset that is
revealed one element at a time. The challenge is to maintain a good
approximation while keeping the combined output over all time steps
differentially private. In the special case of $\textit{continual counting}$ we
seek to approximate a sum of binary input elements. This problem has received
considerable attention lately, in part due to its relevance in implementations
of differentially private stochastic gradient descent. $\textit{Factorization
mechanisms}$ are the leading approach to continual counting, but the best such
mechanisms do not work well in $\textit{streaming}$ settings since they require
space proportional to the size of the input. In this paper, we present a simple
approach to approximating factorization mechanisms in low space via
$\textit{binning}$, where adjacent matrix entries with similar values are
changed to be identical in such a way that a matrix-vector product can be
maintained in sublinear space. Our approach has provable sublinear space
guarantees for a class of lower triangular matrices whose entries are
monotonically decreasing away from the diagonal. We show empirically that even
with very low space usage we are able to closely match, and sometimes surpass,
the performance of asymptotically optimal factorization mechanisms. Recently,
and independently of our work, Dvijotham et al. have also suggested an approach
to implementing factorization mechanisms in a streaming setting. Their work
differs from ours in several respects: It only addresses factorization into
$\textit{Toeplitz}$ matrices, only considers $\textit{maximum}$ error, and uses
a different technique based on rational function approximation that seems less
versatile than our binning approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SaTML 2025. Final version to appear on IEEE eXplore</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $\texttt{SEM-CTRL}$: Semantically Controlled Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Albinhassan, Pranava Madhyastha, Alessandra Russo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring both syntactic and semantic correctness in Large Language Model
(LLM) outputs remains a significant challenge, despite being critical for
real-world deployment. In this paper, we introduce $\texttt{SEM-CTRL}$, a
unified approach that enforces rich context-sensitive constraints and task- and
instance-specific semantics directly on an LLM decoder. Our approach integrates
token-level MCTS, which is guided by specific syntactic and semantic
constraints. The constraints over the desired outputs are expressed using
Answer Set Grammars -- a logic-based formalism that generalizes
context-sensitive grammars while incorporating background knowledge to
represent task-specific semantics. We show that our approach guarantees correct
completions for any off-the-shelf LLM without the need for fine-tuning. We
evaluate $\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar
synthesis, combinatorial reasoning, and planning. Our results demonstrate that
$\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform
larger variants and state-of-the-art reasoning models (e.g., o1-preview) while
simultaneously guaranteeing solution correctness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Golden Ratio Weighting Prevents Model Collapse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18049v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18049v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengzhi He, Shirong Xu, Guang Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies identified an intriguing phenomenon in recursive generative
model training known as model collapse, where models trained on data generated
by previous models exhibit severe performance degradation. Addressing this
issue and developing more effective training strategies have become central
challenges in generative model research. In this paper, we investigate this
phenomenon theoretically within a novel framework, where generative models are
iteratively trained on a combination of newly collected real data and synthetic
data from the previous training step. To develop an optimal training strategy
for integrating real and synthetic data, we evaluate the performance of a
weighted training scheme in various scenarios, including Gaussian distribution
estimation and linear regression. We theoretically characterize the impact of
the mixing proportion and weighting scheme of synthetic data on the final
model's performance. Our key finding is that, across different settings, the
optimal weighting scheme under different proportions of synthetic data
asymptotically follows a unified expression, revealing a fundamental trade-off
between leveraging synthetic data and generative model performance. Notably, in
some cases, the optimal weight assigned to real data corresponds to the
reciprocal of the golden ratio. Finally, we validate our theoretical results on
extensive simulated datasets and a real tabular dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with
  Gaussian Distribution <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00153v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00153v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Probing learned concepts in large language models (LLMs) is crucial for
understanding how semantic knowledge is encoded internally. Training linear
classifiers on probing tasks is a principle approach to denote the vector of a
certain concept in the representation space. However, the single vector
identified for a concept varies with both data and training, making it less
robust and weakening its effectiveness in real-world applications. To address
this challenge, we propose an approach to approximate the subspace representing
a specific concept. Built on linear probing classifiers, we extend the concept
vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's
effectiveness through measuring its faithfulness and plausibility across
multiple LLMs with different sizes and architectures. Additionally, we use
representation intervention tasks to showcase its efficacy in real-world
applications such as emotion steering. Experimental results indicate that GCS
concept vectors have the potential to balance steering performance and
maintaining the fluency in natural language generation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Analysis Framework for Understanding Deep Neural Networks Based on
  Network Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.02436v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.02436v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchen Lin, Yong Zhang, Sihan Feng, Hong Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancing artificial intelligence demands a deeper understanding of the
mechanisms underlying deep learning. Here, we propose a straightforward
analysis framework based on the dynamics of learning models. Neurons are
categorized into two modes based on whether their transformation functions
preserve order. This categorization reveals how deep neural networks (DNNs)
maximize information extraction by rationally allocating the proportion of
neurons in different modes across deep layers. We further introduce the
attraction basins of the training samples in both the sample vector space and
the weight vector space to characterize the generalization ability of DNNs.
This framework allows us to identify optimal depth and width configurations,
providing a unified explanation for fundamental DNN behaviors such as the "flat
minima effect," "grokking," and double descent phenomena. Our analysis extends
to networks with depths up to 100 layers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing
  Heterogeneous Temporal Dynamics <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.18691v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.18691v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengjie Zhao, Cees Taal, Stephan Baggerohr, Olga Fink
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-time condition monitoring is crucial for the reliable and efficient
operation of complex systems. However, relying solely on physical sensors can
be limited due to their cost, placement constraints, or inability to directly
measure certain critical parameters. Virtual sensing addresses these
limitations by leveraging readily available sensor data and system knowledge to
estimate inaccessible parameters or infer system states. The increasing
complexity of industrial systems necessitates deployments of sensors with
diverse modalities to provide a comprehensive understanding of system states.
These sensors capture data at varying frequencies to monitor both rapid and
slowly varying system dynamics, as well as local and global state evolutions of
the systems. This leads to heterogeneous temporal dynamics, which, particularly
under varying operational end environmental conditions, pose a significant
challenge for accurate virtual sensing. To address this, we propose a
Heterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly
models signals from diverse sensors and integrates operating conditions into
the model architecture. We evaluate HTGNN using two newly released datasets: a
bearing dataset with diverse load conditions for bearing load prediction and a
year-long simulated dataset for predicting bridge live loads. Our results
demonstrate that HTGNN significantly outperforms established baseline methods
in both tasks, particularly under highly varying operating conditions. These
results highlight HTGNN's potential as a robust and accurate virtual sensing
approach for complex systems, paving the way for improved monitoring,
predictive maintenance, and enhanced system performance. Our code and data are
available under https://github.com/EPFL-IMOS/htgnn.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper extends our previous conference paper (Best Paper at
  European Conference of the PHM Society 2024,
  https://doi.org/10.36001/phme.2024.v8i1.3998). Accepted by Mechanical Systems
  and Signal Processing (MSSP)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The FFT Strikes Back: An Efficient Alternative to Self-Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18394v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18394v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob Fein-Ashley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conventional self-attention mechanisms incur quadratic complexity, limiting
their scalability on long sequences. We introduce \textbf{FFTNet}, an adaptive
spectral filtering framework that leverages the Fast Fourier Transform (FFT) to
achieve global token mixing in $\mathcal{O}(n\log n)$ time. By transforming
inputs into the frequency domain, FFTNet exploits the orthogonality and energy
preservation guaranteed by Parseval's theorem to capture long-range
dependencies efficiently. Our main theoretical contributions are 1) an adaptive
spectral filter, 2) combining local windowing with a global FFT branch, and 3)
rich nonlinearity introduction in both the frequency and token domains.
Experiments on the Long Range Arena and ImageNet benchmarks validate our
theoretical insights and demonstrate superior performance over fixed Fourier
and standard attention models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from
  Multi-Turn Jailbreaks without Compromising Usability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09990v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09990v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the rapid development of safety alignment techniques for LLMs,
defending against multi-turn jailbreaks is still a challenging task. In this
paper, we conduct a comprehensive comparison, revealing that some existing
defense methods can improve the robustness of LLMs against multi-turn
jailbreaks but compromise usability, i.e., reducing general capabilities or
causing the over-refusal problem. From the perspective of mechanism
interpretability of LLMs, we discover that these methods fail to establish a
boundary that exactly distinguishes safe and harmful feature representations.
Therefore, boundary-safe representations close to harmful representations are
inevitably disrupted, leading to a decline in usability. To address this issue,
we propose X-Boundary to push harmful representations away from boundary-safe
representations and obtain an exact distinction boundary. In this way, harmful
representations can be precisely erased without disrupting safe ones.
Experimental results show that X-Boundary achieves state-of-the-art defense
performance against multi-turn jailbreaks, while reducing the over-refusal rate
by about 20% and maintaining nearly complete general capability. Furthermore,
we theoretically prove and empirically verify that X-Boundary can accelerate
the convergence process during training. Please see our code at:
https://github.com/AI45Lab/X-Boundary.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Chunking the Critic: A <span class="highlight-title">Transformer</span>-based Soft Actor-Critic with N-Step
  Returns 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03660v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03660v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong Tian, Ge Li, Hongyi Zhou, Onur Celik, Gerhard Neumann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soft Actor-Critic (SAC) critically depends on its critic network, which
typically evaluates a single state-action pair to guide policy updates. Using
N-step returns is a common practice to reduce the bias in the target values of
the critic. However, using N-step returns can again introduce high variance and
necessitates importance sampling, often destabilizing training. Recent
algorithms have also explored action chunking-such as direct action repetition
and movement primitives-to enhance exploration. In this paper, we propose a
Transformer-based Critic Network for SAC that integrates the N-returns
framework in a stable and efficient manner. Unlike approaches that perform
chunking in the actor network, we feed chunked actions into the critic network
to explore potential performance gains. Our architecture leverages the
Transformer's ability to process sequential information, facilitating more
robust value estimation. Empirical results show that this method not only
achieves efficient, stable training but also excels in sparse
reward/multi-phase environments-traditionally a challenge for step-based
methods. These findings underscore the promise of combining Transformer-based
critics with N-returns to advance reinforcement learning performance
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning finitely correlated states: stability of the spectral
  reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.07516v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.07516v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marco Fanizza, Niklas Galke, Josep Lumbreras, Cambyse Rouzé, Andreas Winter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Matrix product operators allow efficient descriptions (or realizations) of
states on a 1D lattice. We consider the task of learning a realization of
minimal dimension from copies of an unknown state, such that the resulting
operator is close to the density matrix in trace norm. For finitely correlated
translation-invariant states on an infinite chain, a realization of minimal
dimension can be exactly reconstructed via linear algebra operations from the
marginals of a size depending on the representation dimension. We establish a
bound on the trace norm error for an algorithm that estimates a candidate
realization from estimates of these marginals and outputs a matrix product
operator, estimating the state of a chain of arbitrary length $t$. This bound
allows us to establish an $O(t^2)$ upper bound on the sample complexity of the
learning task, with an explicit dependence on the site dimension, realization
dimension and spectral properties of a certain map constructed from the state.
A refined error bound can be proven for $C^*$-finitely correlated states, which
have an operational interpretation in terms of sequential quantum channels
applied to the memory system. We can also obtain an analogous error bound for a
class of matrix product density operators on a finite chain reconstructible by
local marginals. In this case, a linear number of marginals must be estimated,
obtaining a sample complexity of $\tilde{O}(t^3)$. The learning algorithm also
works for states that are sufficiently close to a finitely correlated state,
with the potential of providing competitive algorithms for other interesting
families of states.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 7 figures. Manuscript restructured, with minor corrections
  and clarifications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Challenges and Opportunities in Generative AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.00025v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.00025v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Laura Manduchi, Kushagra Pandey, Clara Meister, Robert Bamler, Ryan Cotterell, Sina Däubener, Sophie Fellenz, Asja Fischer, Thomas Gärtner, Matthias Kirchler, Marius Kloft, Yingzhen Li, Christoph Lippert, Gerard de Melo, Eric Nalisnick, Björn Ommer, Rajesh Ranganath, Maja Rudolph, Karen Ullrich, Guy Van den Broeck, Julia E Vogt, Yixin Wang, Florian Wenzel, Frank Wood, Stephan Mandt, Vincent Fortuin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of deep generative modeling has grown rapidly in the last few
years. With the availability of massive amounts of training data coupled with
advances in scalable unsupervised learning paradigms, recent large-scale
generative models show tremendous promise in synthesizing high-resolution
images and text, as well as structured data such as videos and molecules.
However, we argue that current large-scale generative AI models exhibit several
fundamental shortcomings that hinder their widespread adoption across domains.
In this work, our objective is to identify these issues and highlight key
unresolved challenges in modern generative AI paradigms that should be
addressed to further enhance their capabilities, versatility, and reliability.
By identifying these challenges, we aim to provide researchers with insights
for exploring fruitful research directions, thus fostering the development of
more robust and accessible generative AI solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gumbel Counterfactual Generation From Language Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.07180v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.07180v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shauli Ravfogel, Anej Svete, Vésteinn Snæbjarnarson, Ryan Cotterell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and manipulating the causal generation mechanisms in language
models is essential for controlling their behavior. Previous work has primarily
relied on techniques such as representation surgery -- e.g., model ablations or
manipulation of linear subspaces tied to specific concepts -- to
\emph{intervene} on these models. To understand the impact of interventions
precisely, it is useful to examine \emph{counterfactuals} -- e.g., how a given
sentence would have appeared had it been generated by the model following a
specific intervention. We highlight that counterfactual reasoning is
conceptually distinct from interventions, as articulated in Pearl's causal
hierarchy. Based on this observation, we propose a framework for generating
true string counterfactuals by reformulating language models as a structural
equation model using the Gumbel-max trick, which we called Gumbel
counterfactual generation. This reformulation allows us to model the joint
distribution over original strings and their counterfactuals resulting from the
same instantiation of the sampling noise. We develop an algorithm based on
hindsight Gumbel sampling that allows us to infer the latent noise variables
and generate counterfactuals of observed strings. Our experiments demonstrate
that the approach produces meaningful counterfactuals while at the same time
showing that commonly used intervention techniques have considerable undesired
side effects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed
  GFlowNets <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07775v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07775v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Liu, Tim Z. Xiao, Weiyang Liu, <span class="highlight-author">Yoshua Bengio</span>, Dinghuai Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While one commonly trains large diffusion models by collecting datasets on
target downstream tasks, it is often desired to align and finetune pretrained
diffusion models with some reward functions that are either designed by experts
or learned from small-scale datasets. Existing post-training methods for reward
finetuning of diffusion models typically suffer from lack of diversity in
generated samples, lack of prior preservation, and/or slow convergence in
finetuning. Inspired by recent successes in generative flow networks
(GFlowNets), a class of probabilistic models that sample with the unnormalized
density of a reward function, we propose a novel GFlowNet method dubbed
Nabla-GFlowNet (abbreviated as \methodname), the first GFlowNet method that
leverages the rich signal in reward gradients, together with an objective
called \graddb plus its variant \resgraddb designed for prior-preserving
diffusion finetuning. We show that our proposed method achieves fast yet
diversity- and prior-preserving finetuning of Stable Diffusion, a large-scale
text-conditioned image diffusion model, on different realistic reward
functions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report (35 pages, 31 figures), Accepted at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Procedural Knowledge in <span class="highlight-title">Pretrain</span>ing Drives Reasoning in Large Language
  Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12580v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12580v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The capabilities and limitations of Large Language Models have been sketched
out in great detail in recent years, providing an intriguing yet conflicting
picture. On the one hand, LLMs demonstrate a general ability to solve problems.
On the other hand, they show surprising reasoning gaps when compared to humans,
casting doubt on the robustness of their generalisation strategies. The sheer
volume of data used in the design of LLMs has precluded us from applying the
method traditionally used to measure generalisation: train-test set separation.
To overcome this, we study what kind of generalisation strategies LLMs employ
when performing reasoning tasks by investigating the pretraining data they rely
on. For two models of different sizes (7B and 35B) and 2.5B of their
pretraining tokens, we identify what documents influence the model outputs for
three simple mathematical reasoning tasks and contrast this to the data that
are influential for answering factual questions. We find that, while the models
rely on mostly distinct sets of data for each factual question, a document
often has a similar influence across different reasoning questions within the
same task, indicating the presence of procedural knowledge. We further find
that the answers to factual questions often show up in the most influential
data. However, for reasoning questions the answers usually do not show up as
highly influential, nor do the answers to the intermediate reasoning steps.
When we characterise the top ranked documents for the reasoning questions
qualitatively, we confirm that the influential documents often contain
procedural knowledge, like demonstrating how to obtain a solution using
formulae or code. Our findings indicate that the approach to reasoning the
models use is unlike retrieval, and more like a generalisable strategy that
synthesises procedural knowledge from documents doing a similar form of
reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning from negative feedback, or positive feedback or both 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04166v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04166v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abbas Abdolmaleki, Bilal Piot, Bobak Shahriari, Jost Tobias Springenberg, Tim Hertweck, Rishabh Joshi, Junhyuk Oh, Michael Bloesch, Thomas Lampe, Nicolas Heess, Jonas Buchli, Martin Riedmiller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing preference optimization methods often assume scenarios where paired
preference feedback (preferred/positive vs. dis-preferred/negative examples) is
available. This requirement limits their applicability in scenarios where only
unpaired feedback--for example, either positive or negative--is available. To
address this, we introduce a novel approach that decouples learning from
positive and negative feedback. This decoupling enables control over the
influence of each feedback type and, importantly, allows learning even when
only one feedback type is present. A key contribution is demonstrating stable
learning from negative feedback alone, a capability not well-addressed by
current methods. Our approach builds upon the probabilistic framework
introduced in (Dayan and Hinton, 1997), which uses expectation-maximization
(EM) to directly optimize the probability of positive outcomes (as opposed to
classic expected reward maximization). We address a key limitation in current
EM-based methods: they solely maximize the likelihood of positive examples,
while neglecting negative ones. We show how to extend EM algorithms to
explicitly incorporate negative examples, leading to a theoretically grounded
algorithm that offers an intuitive and versatile way to learn from both
positive and negative feedback. We evaluate our approach for training language
models based on human feedback as well as training policies for sequential
decision-making problems, where learned value functions are available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor
  Scene Generation <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhifei Yang, Keyang Lu, Chao Zhang, Jiaxing Qi, Hanqi Jiang, Ruifei Ma, Shenglin Yin, Yifan Xu, Mingzhe Xing, Zhen Xiao, Jieyi Long, Xiangde Liu, Guangyao Zhai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable 3D scene generation has extensive applications in virtual
reality and interior design, where the generated scenes should exhibit high
levels of realism and controllability in terms of geometry. Scene graphs
provide a suitable data representation that facilitates these applications.
However, current graph-based methods for scene generation are constrained to
text-based inputs and exhibit insufficient adaptability to flexible user
inputs, hindering the ability to precisely control object geometry. To address
this issue, we propose MMGDreamer, a dual-branch diffusion model for scene
generation that incorporates a novel Mixed-Modality Graph, visual enhancement
module, and relation predictor. The mixed-modality graph allows object nodes to
integrate textual and visual modalities, with optional relationships between
nodes. It enhances adaptability to flexible user inputs and enables meticulous
control over the geometry of objects in the generated scenes. The visual
enhancement module enriches the visual fidelity of text-only nodes by
constructing visual representations using text embeddings. Furthermore, our
relation predictor leverages node representations to infer absent relationships
between nodes, resulting in more coherent scene layouts. Extensive experimental
results demonstrate that MMGDreamer exhibits superior control of object
geometry, achieving state-of-the-art scene generation performance. Project
page: https://yangzhifeio.github.io/project/MMGDreamer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2025 Main Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Magnetic Field Data Calibration with <span class="highlight-title">Transformer</span> Model Using Physical
  Constraints: A Scalable Method for Satellite Missions, Illustrated by
  Tianwen-1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.00020v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.00020v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Beibei Li, Yutian Chi, Yuming Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study introduces a novel approach that integrates the magnetic field
data correction from the Tianwen-1 Mars mission with a neural network
architecture constrained by physical principles derived from Maxwell's equation
equations. By employing a Transformer based model capable of efficiently
handling sequential data, the method corrects measurement anomalies caused by
satellite dynamics, instrument interference, and environmental noise. As a
result, it significantly improves both the accuracy and the physical
consistency of the calibrated data. Compared to traditional methods that
require long data segments and manual intervention often taking weeks or even
months to complete this new approach can finish calibration in just minutes to
hours, and predictions are made within seconds. This innovation not only
accelerates the process of space weather modeling and planetary magnetospheric
studies but also provides a robust framework for future planetary exploration
and solar wind interaction research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D
  Medical Image Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13524v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13524v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Dai, Jun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient evaluation of three-dimensional (3D) medical images is crucial for
diagnostic and therapeutic practices in healthcare. Recent years have seen a
substantial uptake in applying deep learning and computer vision to analyse and
interpret medical images. Traditional approaches, such as convolutional neural
networks (CNNs) and vision transformers (ViTs), face significant computational
challenges, prompting the need for architectural advancements. Recent efforts
have led to the introduction of novel architectures like the ``Mamba'' model as
alternative solutions to traditional CNNs or ViTs. The Mamba model excels in
the linear processing of one-dimensional data with low computational demands.
However, Mamba's potential for 3D medical image analysis remains underexplored
and could face significant computational challenges as the dimension increases.
This manuscript presents MobileViM, a streamlined architecture for efficient
segmentation of 3D medical images. In the MobileViM network, we invent a new
dimension-independent mechanism and a dual-direction traversing approach to
incorporate with a vision-Mamba-based framework. MobileViM also features a
cross-scale bridging technique to improve efficiency and accuracy across
various medical imaging modalities. With these enhancements, MobileViM achieves
segmentation speeds exceeding 90 frames per second (FPS) on a single graphics
processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster
than the state-of-the-art deep learning models for processing 3D images with
the same computational resources. In addition, experimental evaluations
demonstrate that MobileViM delivers superior performance, with Dice similarity
scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,
ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses
existing models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The corresponding author disagrees with the manuscript submitted to
  arXiv</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Poisoning Attacks to Locally Differentially Private Range Query
  Protocols 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03454v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03454v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ting-Wei Liao, Chih-Hsun Lin, Yu-Lin Tsai, Takao Murakami, Chia-Mu Yu, Jun Sakuma, Chun-Ying Huang, Hiroaki Kikuchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Local Differential Privacy (LDP) has been widely adopted to protect user
privacy in decentralized data collection. However, recent studies have revealed
that LDP protocols are vulnerable to data poisoning attacks, where malicious
users manipulate their reported data to distort aggregated results. In this
work, we present the first study on data poisoning attacks targeting LDP range
query protocols, focusing on both tree-based and grid-based approaches. We
identify three key challenges in executing such attacks, including crafting
consistent and effective fake data, maintaining data consistency across levels
or grids, and preventing server detection. To address the first two challenges,
we propose novel attack methods that are provably optimal, including a
tree-based attack and a grid-based attack, designed to manipulate range query
results with high effectiveness. \textbf{Our key finding is that the common
post-processing procedure, Norm-Sub, in LDP range query protocols can help the
attacker massively amplify their attack effectiveness.} In addition, we study a
potential countermeasure, but also propose an adaptive attack capable of
evading this defense to address the third challenge. We evaluate our methods
through theoretical analysis and extensive experiments on synthetic and
real-world datasets. Our results show that the proposed attacks can
significantly amplify estimations for arbitrary range queries by manipulating a
small fraction of users, providing 5-10x more influence than a normal user to
the estimation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Efficient Learning Method to Connect Observables 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01684v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01684v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Yu, Takayuki Miyagi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Constructing fast and accurate surrogate models is a key ingredient for
making robust predictions in many topics. We introduce a new model, the
Multiparameter Eigenvalue Problem (MEP) emulator. The new method connects
emulators and can make predictions directly from observables to observables. We
present that the MEP emulator can be trained with data from Eigenvector
Continuation (EC) and Parametric Matrix Model (PMM) emulators. A simple
simulation on a one-dimensional lattice confirms the performance of the MEP
emulator. Using $^{28}$O as an example, we also demonstrate that the predictive
probability distribution of the target observables can be easily obtained
through the new emulator.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5+2 pages, 4 figures, updated acknowledgment</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.08010v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.08010v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiao Wen, Arthur Jacot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We describe the emergence of a Convolution Bottleneck (CBN) structure in
CNNs, where the network uses its first few layers to transform the input
representation into a representation that is supported only along a few
frequencies and channels, before using the last few layers to map back to the
outputs. We define the CBN rank, which describes the number and type of
frequencies that are kept inside the bottleneck, and partially prove that the
parameter norm required to represent a function $f$ scales as depth times the
CBN rank $f$. We also show that the parameter norm depends at next order on the
regularity of $f$. We show that any network with almost optimal parameter norm
will exhibit a CBN structure in both the weights and - under the assumption
that the network is stable under large learning rate - the activations, which
motivates the common practice of down-sampling; and we verify that the CBN
results still hold with down-sampling. Finally we use the CBN structure to
interpret the functions learned by CNNs on a number of tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky
  ResNets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17573v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17573v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arthur Jacot, Alexandre Kaiser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study Leaky ResNets, which interpolate between ResNets and Fully-Connected
nets depending on an 'effective depth' hyper-parameter $\tilde{L}$. In the
infinite depth limit, we study 'representation geodesics' $A_{p}$: continuous
paths in representation space (similar to NeuralODEs) from input $p=0$ to
output $p=1$ that minimize the parameter norm of the network. We give a
Lagrangian and Hamiltonian reformulation, which highlight the importance of two
terms: a kinetic energy which favors small layer derivatives
$\partial_{p}A_{p}$ and a potential energy that favors low-dimensional
representations, as measured by the 'Cost of Identity'. The balance between
these two forces offers an intuitive understanding of feature learning in
ResNets. We leverage this intuition to explain the emergence of a bottleneck
structure, as observed in previous work: for large $\tilde{L}$ the potential
energy dominates and leads to a separation of timescales, where the
representation jumps rapidly from the high dimensional inputs to a
low-dimensional representation, move slowly inside the space of low-dimensional
representations, before jumping back to the potentially high-dimensional
outputs. Inspired by this phenomenon, we train with an adaptive layer step-size
to adapt to the separation of timescales.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How DNNs break the Curse of Dimensionality: Compositionality and
  Symmetry Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05664v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05664v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arthur Jacot, Seok Hoan Choi, Yuxiao Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We show that deep neural networks (DNNs) can efficiently learn any
composition of functions with bounded $F_{1}$-norm, which allows DNNs to break
the curse of dimensionality in ways that shallow networks cannot. More
specifically, we derive a generalization bound that combines a covering number
argument for compositionality, and the $F_{1}$-norm (or the related Barron
norm) for large width adaptivity. We show that the global minimizer of the
regularized loss of DNNs can fit for example the composition of two functions
$f^{*}=h\circ g$ from a small number of observations, assuming $g$ is
smooth/regular and reduces the dimensionality (e.g. $g$ could be the quotient
map of the symmetries of $f^{*}$), so that $h$ can be learned in spite of its
low regularity. The measures of regularity we consider is the Sobolev norm with
different levels of differentiability, which is well adapted to the $F_{1}$
norm. We compute scaling laws empirically and observe phase transitions
depending on whether $g$ or $h$ is harder to learn, as predicted by our theory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CATCH: Channel-Aware multivariate Time Series Anomaly Detection via
  Frequency Patching <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12261v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12261v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingjian Wu, Xiangfei Qiu, Zhengyu Li, Yihang Wang, Jilin Hu, Chenjuan Guo, Hui Xiong, Bin Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection in multivariate time series is challenging as heterogeneous
subsequence anomalies may occur. Reconstruction-based methods, which focus on
learning normal patterns in the frequency domain to detect diverse abnormal
subsequences, achieve promising results, while still falling short on capturing
fine-grained frequency characteristics and channel correlations. To contend
with the limitations, we introduce CATCH, a framework based on frequency
patching. We propose to patchify the frequency domain into frequency bands,
which enhances its ability to capture fine-grained frequency characteristics.
To perceive appropriate channel correlations, we propose a Channel Fusion
Module (CFM), which features a patch-wise mask generator and a masked-attention
mechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM
is encouraged to iteratively discover appropriate patch-wise channel
correlations, and to cluster relevant channels while isolating adverse effects
from irrelevant channels. Extensive experiments on 10 real-world datasets and
12 synthetic datasets demonstrate that CATCH achieves state-of-the-art
performance. We make our code and datasets available at
https://github.com/decisionintelligence/CATCH.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AfroBench: How Good are Large Language Models on African Languages? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07978v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07978v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo, Kelechi Ogueji, Jimmy Lin, Pontus Stenetorp, David Ifeoluwa Adelani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large-scale multilingual evaluations, such as MEGA, often include only a
handful of African languages due to the scarcity of high-quality evaluation
data and the limited discoverability of existing African datasets. This lack of
representation hinders comprehensive LLM evaluation across a diverse range of
languages and tasks. To address these challenges, we introduce AfroBench -- a
multi-task benchmark for evaluating the performance of LLMs across 64 African
languages, 15 tasks and 22 datasets. AfroBench consists of nine natural
language understanding datasets, six text generation datasets, six knowledge
and question answering tasks, and one mathematical reasoning task. We present
results comparing the performance of prompting LLMs to fine-tuned baselines
based on BERT and T5-style models. Our results suggest large gaps in
performance between high-resource languages, such as English, and African
languages across most tasks; but performance also varies based on the
availability of monolingual data resources. Our findings confirm that
performance on African languages continues to remain a hurdle for current LLMs,
underscoring the need for additional efforts to close this gap.
  https://mcgill-nlp.github.io/AfroBench/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust Amortized Bayesian Inference with Self-Consistency Losses on
  Unlabeled Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.13483v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.13483v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aayush Mishra, Daniel Habermann, Marvin Schmitt, Stefan T. Radev, Paul-Christian Bürkner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural amortized Bayesian inference (ABI) can solve probabilistic inverse
problems orders of magnitude faster than classical methods. However, neural ABI
is not yet sufficiently robust for widespread and safe applicability. In
particular, when performing inference on observations outside of the scope of
the simulated data seen during training, for example, because of model
misspecification, the posterior approximations are likely to become highly
biased. Due to the bad pre-asymptotic behavior of current neural posterior
estimators in the out-of-simulation regime, the resulting estimation biases
cannot be fixed in acceptable time by just simulating more training data. In
this proof-of-concept paper, we propose a semi-supervised approach that enables
training not only on (labeled) simulated data generated from the model, but
also on unlabeled data originating from any source, including real-world data.
To achieve the latter, we exploit Bayesian self-consistency properties that can
be transformed into strictly proper losses without requiring knowledge of true
parameter values, that is, without requiring data labels. The results of our
initial experiments show remarkable improvements in the robustness of ABI on
out-of-simulation data. Even if the observed data is far away from both labeled
and unlabeled training data, inference remains highly accurate. If our findings
also generalize to other scenarios and model classes, we believe that our new
method represents a major breakthrough in neural ABI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>added acknowledgements</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Vietnamese VQA through Curriculum Learning on Raw and
  Augmented Text Representations <span class="chip">AAAI-25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03285v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03285v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khoi Anh Nguyen, Linh Yen Vu, Thang Dinh Duong, Thuan Nguyen Duong, Huy Thanh Nguyen, Vinh Quang Dinh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Question Answering (VQA) is a multimodal task requiring reasoning
across textual and visual inputs, which becomes particularly challenging in
low-resource languages like Vietnamese due to linguistic variability and the
lack of high-quality datasets. Traditional methods often rely heavily on
extensive annotated datasets, computationally expensive pipelines, and large
pre-trained models, specifically in the domain of Vietnamese VQA, limiting
their applicability in such scenarios. To address these limitations, we propose
a training framework that combines a paraphrase-based feature augmentation
module with a dynamic curriculum learning strategy. Explicitly, augmented
samples are considered "easy" while raw samples are regarded as "hard". The
framework then utilizes a mechanism that dynamically adjusts the ratio of easy
to hard samples during training, progressively modifying the same dataset to
increase its difficulty level. By enabling gradual adaptation to task
complexity, this approach helps the Vietnamese VQA model generalize well, thus
improving overall performance. Experimental results show consistent
improvements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,
highlighting both the potential and challenges of our approach in advancing VQA
for Vietnamese language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and
  Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting new obfuscated malware variants: A lightweight and
  interpretable machine learning approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07918v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07918v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oladipo A. Madamidola, Felix Ngobigha, Adnane Ez-zizi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning has been successfully applied in developing malware
detection systems, with a primary focus on accuracy, and increasing attention
to reducing computational overhead and improving model interpretability.
However, an important question remains underexplored: How well can machine
learning-based models detect entirely new forms of malware not present in the
training data? In this study, we present a machine learning-based system for
detecting obfuscated malware that is not only highly accurate, lightweight and
interpretable, but also capable of successfully adapting to new types of
malware attacks. Our system is capable of detecting 15 malware subtypes despite
being exclusively trained on one malware subtype, namely the Transponder from
the Spyware family. This system was built after training 15 distinct random
forest-based models, each on a different malware subtype from the
CIC-MalMem-2022 dataset. These models were evaluated against the entire range
of malware subtypes, including all unseen malware subtypes. To maintain the
system's streamlined nature, training was confined to the top five most
important features, which also enhanced interpretability. The
Transponder-focused model exhibited high accuracy, exceeding 99.8%, with an
average processing speed of 5.7 microseconds per file. We also illustrate how
the Shapley additive explanations technique can facilitate the interpretation
of the model predictions. Our research contributes to advancing malware
detection methodologies, pioneering the feasibility of detecting obfuscated
malware by exclusively training a model on a single or a few carefully selected
malware subtypes and applying it to detect unseen subtypes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages (excluding Appendix), 5 figures and 5 tables. Now published
  in Intelligent Systems with Applications
  (https://doi.org/10.1016/j.iswa.2024.200472)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nature Language Model: Deciphering the Language of Nature for Scientific
  Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07527v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07527v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Ran Bi, Kehan Wu, Wei Zhang, Kaiyuan Gao, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models have revolutionized natural language processing and
artificial intelligence, significantly enhancing how machines comprehend and
generate human languages. Inspired by the success of these foundation models,
researchers have developed foundation models for individual scientific domains,
including small molecules, materials, proteins, DNA, RNA and even cells.
However, these models are typically trained in isolation, lacking the ability
to integrate across different scientific domains. Recognizing that entities
within these domains can all be represented as sequences, which together form
the "language of nature", we introduce Nature Language Model (NatureLM), a
sequence-based science foundation model designed for scientific discovery.
Pre-trained with data from multiple scientific domains, NatureLM offers a
unified, versatile model that enables various applications including: (i)
generating and optimizing small molecules, proteins, RNA, and materials using
text instructions; (ii) cross-domain generation/design, such as
protein-to-molecule and protein-to-RNA generation; and (iii) top performance
across different domains, matching or surpassing state-of-the-art specialist
models. NatureLM offers a promising generalist approach for various scientific
tasks, including drug discovery (hit generation/optimization, ADMET
optimization, synthesis), novel material design, and the development of
therapeutic proteins or nucleotides. We have developed NatureLM models in
different sizes (1 billion, 8 billion, and 46.7 billion parameters) and
observed a clear improvement in performance as the model size increases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>93 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep unrolling for learning optimal spatially varying regularisation
  parameters for Total Generalised Variation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thanh Trung Vu, Andreas Kofler, Kostas Papafitsoros
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We extend a recently introduced deep unrolling framework for learning
spatially varying regularisation parameters in inverse imaging problems to the
case of Total Generalised Variation (TGV). The framework combines a deep
convolutional neural network (CNN) inferring the two spatially varying TGV
parameters with an unrolled algorithmic scheme that solves the corresponding
variational problem. The two subnetworks are jointly trained end-to-end in a
supervised fashion and as such the CNN learns to compute those parameters that
drive the reconstructed images as close to the ground truth as possible.
Numerical results in image denoising and MRI reconstruction show a significant
qualitative and quantitative improvement compared to the best TGV scalar
parameter case as well as to other approaches employing spatially varying
parameters computed by unsupervised methods. We also observe that the inferred
spatially varying parameter maps have a consistent structure near the image
edges, asking for further theoretical investigations. In particular, the
parameter that weighs the first-order TGV term has a triple-edge structure with
alternating high-low-high values whereas the one that weighs the second-order
term attains small values in a large neighbourhood around the edges.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">1</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SMTPD: A New Benchmark for Temporal Prediction of Social Media
  Popularity <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04446v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04446v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijie Xu, Bolun Zheng, Wei Zhu, Hangjia Pan, Yuchen Yao, Ning Xu, Anan Liu, Quan Zhang, Chenggang Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media popularity prediction task aims to predict the popularity of
posts on social media platforms, which has a positive driving effect on
application scenarios such as content optimization, digital marketing and
online advertising. Though many studies have made significant progress, few of
them pay much attention to the integration between popularity prediction with
temporal alignment. In this paper, with exploring YouTube's multilingual and
multi-modal content, we construct a new social media temporal popularity
prediction benchmark, namely SMTPD, and suggest a baseline framework for
temporal popularity prediction. Through data analysis and experiments, we
verify that temporal alignment and early popularity play crucial roles in
social media popularity prediction for not only deepening the understanding of
temporal dynamics of popularity in social media but also offering a suggestion
about developing more effective prediction models in this field. Code is
available at https://github.com/zhuwei321/SMTPD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accept by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-05T00:00:00Z">2025-03-05</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">19</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Preliminary Report: Enhancing Role Differentiation in Conversational HCI
  Through Chromostereopsis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03968v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03968v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Grella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose leveraging chromostereopsis, a perceptual phenomenon inducing
depth perception through color contrast, as a novel approach to visually
differentiating conversational roles in text-based AI interfaces. This method
aims to implicitly communicate role hierarchy and add a subtle sense of
physical space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preliminary Report, 8 pages, 1 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Acquisition of Shared Grammatical Representations in Bilingual
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03962v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03962v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Catherine Arnett, Tyler A. Chang, James A. Michaelov, Benjamin K. Bergen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While crosslingual transfer is crucial to contemporary language models'
multilingual capabilities, how it occurs is not well understood. In this paper,
we ask what happens to a monolingual language model when it begins to be
trained on a second language. Specifically, we train small bilingual models for
which we control the amount of data for each language and the order of language
exposure. To find evidence of shared multilingual representations, we turn to
structural priming, a method used to study grammatical representations in
humans. We first replicate previous crosslingual structural priming results and
find that after controlling for training data quantity and language exposure,
there are asymmetrical effects across language pairs and directions. We argue
that this asymmetry may shape hypotheses about human structural priming
effects. We also find that structural priming effects are less robust for less
similar language pairs, highlighting potential limitations of crosslingual
transfer learning and shared representations for typologically diverse
languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performance Comparison of Large Language Models on Advanced Calculus
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03960v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03960v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        In Hak Moon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an in-depth analysis of the performance of seven
different Large Language Models (LLMs) in solving a diverse set of math
advanced calculus problems. The study aims to evaluate these models' accuracy,
reliability, and problem-solving capabilities, including ChatGPT 4o, Gemini
Advanced with 1.5 Pro, Copilot Pro, Claude 3.5 Sonnet, Meta AI, Mistral AI, and
Perplexity. The assessment was conducted through a series of thirty-two test
problems, encompassing a total of 320 points. The problems covered various
topics, from vector calculations and geometric interpretations to integral
evaluations and optimization tasks. The results highlight significant trends
and patterns in the models' performance, revealing both their strengths and
weaknesses - for instance, models like ChatGPT 4o and Mistral AI demonstrated
consistent accuracy across various problem types, indicating their robustness
and reliability in mathematical problem-solving, while models such as Gemini
Advanced with 1.5 Pro and Meta AI exhibited specific weaknesses, particularly
in complex problems involving integrals and optimization, suggesting areas for
targeted improvements. The study also underscores the importance of
re-prompting in achieving accurate solutions, as seen in several instances
where models initially provided incorrect answers but corrected them upon
re-prompting. Overall, this research provides valuable insights into the
current capabilities and limitations of LLMs in the domain of math calculus,
with the detailed analysis of each model's performance on specific problems
offering a comprehensive understanding of their strengths and areas for
improvement, contributing to the ongoing development and refinement of LLM
technology. The findings are particularly relevant for educators, researchers,
and developers seeking to leverage LLMs for educational and practical
applications in mathematics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tec-Habilidad: Skill Classification for Bridging Education and
  Employment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03932v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03932v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabur Butt, Hector G. Ceballos, Diana P. Madera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Job application and assessment processes have evolved significantly in recent
years, largely due to advancements in technology and changes in the way
companies operate. Skill extraction and classification remain an important
component of the modern hiring process as it provides a more objective way to
evaluate candidates and automatically align their skills with the job
requirements. However, to effectively evaluate the skills, the skill extraction
tools must recognize varied mentions of skills on resumes, including direct
mentions, implications, synonyms, acronyms, phrases, and proficiency levels,
and differentiate between hard and soft skills. While tools like LLMs (Large
Model Models) help extract and categorize skills from job applications, there's
a lack of comprehensive datasets for evaluating the effectiveness of these
models in accurately identifying and classifying skills in Spanish-language job
applications. This gap hinders our ability to assess the reliability and
precision of the models, which is crucial for ensuring that the selected
candidates truly possess the required skills for the job. In this paper, we
develop a Spanish language dataset for skill extraction and classification,
provide annotation methodology to distinguish between knowledge, skill, and
abilities, and provide deep learning baselines to advance robust solutions for
skill classification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Federated Fine-tuning for Heterogeneous Data: An Automatic
  Rank Learning Approach via Two-Level LoRA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03920v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03920v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Hao, Yuman Wu, Ali Payani, Myungjin Lee, Mingrui Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the task of personalized federated fine-tuning with heterogeneous
data in the context of language models, where clients collaboratively fine-tune
a language model (e.g., BERT, GPT) without sharing their local data, achieving
personalization simultaneously. While recent efforts have applied
parameter-efficient fine-tuning techniques like low-rank adaptation (LoRA) in
federated settings, they typically use single or multiple independent low-rank
adapters with predefined maximal and minimal ranks, which may not be optimal
for diverse data sources over clients.
  To address this issue, we propose PF2LoRA, a new personalized federated
fine-tuning algorithm built on a novel \emph{automatic rank learning approach
via two-level LoRA}. Given the pretrained language model whose weight is
frozen, our algorithm aims to learn two levels of adaptation simultaneously:
the first level aims to learn a common adapter for all clients, while the
second level fosters individual client personalization. A key advantage of
PF2LoRA is its ability to adaptively determine a suitable rank based on an
individual client's data, rather than relying on a predefined rank that is
agnostic to data heterogeneity. We present a synthetic example that highlights
how PF2LoRA automatically learns the ground-truth rank for each client,
tailoring the adaptation to match the properties of their individual data.
Notably, this approach introduces minimal additional memory overhead, as the
second-level adaptation comprises a small number of parameters compared to the
first level. Our experiments on natural language understanding and generation
tasks demonstrate that PF2LoRA significantly outperforms existing federated
fine-tuning methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEWIS (LayEr WIse Sparsity) -- A Training Free Guided Model Merging
  Approach <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03874v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03874v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hetarth Chopra, Vidhi Rambhia, Vikram Adve
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As specialized large language models (LLMs) become increasingly prevalent,
model merging methods are being used to combine them to create a single
multi-task model without requiring any additional data or training. However,
these approaches fall short when the objective of merging is to increase the
downstream model's performance on a particular task-specific benchmark. In this
work, we propose LEWIS (Layer Wise Sparsity), a guided model-merging framework
that uses activation-based layer importance to dynamically adjust layer-wise
task-vector sparsity required for the merge process. LEWIS uses a calibration
dataset to prioritize critical layers during the task-vector pruning process
required for model merging. This approach guides existing merging methods by
preserving essential layer-wise task-specific knowledge while ensuring the
merged model performs the best at benchmarks resembling the calibration
dataset. Our experiments demonstrate the effectiveness of LEWIS with
performance improvements of code instruction-following and math-solving models
created through model merging up to 4 percent and 11.3 percent, respectively,
outperforming unguided data-less model merging approaches that use
uniform-sparsity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025 Workshop: SLLM (Sparsity in Large Language
  Models)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream
  Impact of Language Model Design Decisions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03862v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03862v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emmy Liu, Amanda Bertsch, Lintang Sutawika, Lindia Tjuatja, Patrick Fernandes, Lara Marinov, Michael Chen, Shreya Singhal, Carolin Lawrence, Aditi Raghunathan, Kiril Gashteovski, Graham Neubig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Improvements in language model capabilities are often attributed to
increasing model size or training data, but in some cases smaller models
trained on curated data or with different architectural decisions can
outperform larger ones trained on more tokens. What accounts for this? To
quantify the impact of these design choices, we meta-analyze 92 open-source
pretrained models across a wide array of scales, including state-of-the-art
open-weights models as well as less performant models and those with less
conventional design decisions. We find that by incorporating features besides
model size and number of training tokens, we can achieve a relative 3-28%
increase in ability to predict downstream performance compared with using scale
alone. Analysis of model design decisions reveal insights into data
composition, such as the trade-off between language and code tasks at 15-25\%
code, as well as the better performance of some architectural decisions such as
choosing rotary over learned embeddings. Broadly, our framework lays a
foundation for more systematic investigation of how model development choices
shape final capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vision-Language Models Struggle to Align Entities across Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iñigo Alonso, Ander Salaberria, Gorka Azkune, Jeremy Barnes, Oier Lopez de Lacalle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-modal entity linking refers to the ability to align entities and their
attributes across different modalities. While cross-modal entity linking is a
fundamental skill needed for real-world applications such as multimodal code
generation, fake news detection, or scene understanding, it has not been
thoroughly studied in the literature. In this paper, we introduce a new task
and benchmark to address this gap. Our benchmark, MATE, consists of 5.5k
evaluation instances featuring visual scenes aligned with their textual
representations. To evaluate cross-modal entity linking performance, we design
a question-answering task that involves retrieving one attribute of an object
in one modality based on a unique attribute of that object in another modality.
We evaluate state-of-the-art Vision-Language Models (VLMs) and humans on this
task, and find that VLMs struggle significantly compared to humans,
particularly as the number of objects in the scene increases. Our analysis also
shows that, while chain-of-thought prompting can improve VLM performance,
models remain far from achieving human-level proficiency. These findings
highlight the need for further research in cross-modal entity linking and show
that MATE is a strong benchmark to support that progress.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Data Efficiency via Curating LLM-Driven Rating Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10877v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10877v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinlong Pang, Jiaheng Wei, Ankit Parag Shah, Zhaowei Zhu, Yaxuan Wang, Chen Qian, Yang Liu, Yujia Bao, Wei Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction tuning is critical for adapting large language models (LLMs) to
downstream tasks, and recent studies have demonstrated that small amounts of
human-curated data can outperform larger datasets, challenging traditional data
scaling laws. While LLM-based data quality rating systems offer a
cost-effective alternative to human annotation, they often suffer from
inaccuracies and biases, even in powerful models like GPT-4. In this work, we
introduce DS2, a Diversity-aware Score curation method for Data Selection. By
systematically modeling error patterns through a score transition matrix, DS2
corrects LLM-based scores and promotes diversity in the selected data samples.
Our approach shows that a curated subset (just 3.3% of the original dataset)
outperforms full-scale datasets (300k samples) across various machine-alignment
benchmarks, and matches or surpasses human-aligned datasets such as LIMA with
the same sample size (1k samples). These findings challenge conventional data
scaling assumptions, highlighting that redundant, low-quality samples can
degrade performance and reaffirming that "more can be less."
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLARE: Fusing Language Models and Collaborative Architectures for
  Recommender Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11699v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11699v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liam Hebert, Marialena Kyriakidi, Hubert Pham, Krishna Sayana, James Pine, Sukhdeep Sodhi, Ambarish Jash
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent proposals in recommender systems represent items with their textual
description, using a large language model. They show better results on standard
benchmarks compared to an item ID-only model, such as Bert4Rec. In this work,
we revisit the often-used Bert4Rec baseline and show that with further tuning,
Bert4Rec significantly outperforms previously reported numbers, and in some
datasets, is competitive with state-of-the-art models.
  With revised baselines for item ID-only models, this paper also establishes
new competitive results for architectures that combine IDs and textual
descriptions. We demonstrate this with Flare (Fusing Language models and
collaborative Architectures for Recommender Enhancement). Flare is a novel
hybrid sequence recommender that integrates a language model with a
collaborative filtering model using a Perceiver network.
  Prior studies focus evaluation on datasets with limited-corpus size, but many
commercially-applicable recommender systems common on the web must handle
larger corpora. We evaluate Flare on a more realistic dataset with a
significantly larger item vocabulary, introducing new baselines for this
setting. This paper also showcases Flare's inherent ability to support
critiquing, enabling users to provide feedback and refine recommendations. We
leverage critiquing as an evaluation method to assess the model's language
understanding and its transferability to the recommendation task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Illusion of State in State-Space Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08819v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08819v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Merrill, Jackson Petty, Ashish Sabharwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-space models (SSMs) have emerged as a potential alternative
architecture for building large language models (LLMs) compared to the
previously ubiquitous transformer architecture. One theoretical weakness of
transformers is that they cannot express certain kinds of sequential
computation and state tracking (Merrill & Sabharwal, 2023), which SSMs are
explicitly designed to address via their close architectural similarity to
recurrent neural networks (RNNs). But do SSMs truly have an advantage (over
transformers) in expressive power for state tracking? Surprisingly, the answer
is no. Our analysis reveals that the expressive power of SSMs is limited very
similarly to transformers: SSMs cannot express computation outside the
complexity class $\mathsf{TC}^0$. In particular, this means they cannot solve
simple state-tracking problems like permutation composition. It follows that
SSMs are provably unable to accurately track chess moves with certain notation,
evaluate code, or track entities in a long narrative. To supplement our formal
analysis, we report experiments showing that Mamba-style SSMs indeed struggle
with state tracking. Thus, despite its recurrent formulation, the "state" in an
SSM is an illusion: SSMs have similar expressiveness limitations to
non-recurrent models like transformers, which may fundamentally limit their
ability to solve real-world state-tracking problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at ICML 2024. 9 pages + appendices</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LoLCATs: On Low-Rank Linearizing of Large Language Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10254v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10254v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Zhang, Simran Arora, Rahul Chalamala, Alan Wu, Benjamin Spector, Aaryan Singhal, Krithik Ramesh, Christopher Ré
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent works show we can linearize large language models (LLMs) -- swapping
the quadratic attentions of popular Transformer-based LLMs with subquadratic
analogs, such as linear attention -- avoiding the expensive pretraining costs.
However, linearizing LLMs often significantly degrades model quality, still
requires training over billions of tokens, and remains limited to smaller 1.3B
to 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer
(LoLCATs), a simple two-step method that improves LLM linearizing quality with
orders of magnitudes less memory and compute. We base these steps on two
findings. First, we can replace an LLM's softmax attentions with
closely-approximating linear attentions, simply by training the linear
attentions to match their softmax counterparts with an output MSE loss
("attention transfer"). Then, this enables adjusting for approximation errors
and recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATs
significantly improves linearizing quality, training efficiency, and
scalability. We significantly reduce the linearizing quality gap and produce
state-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leading
to 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so with
only 0.2% of past methods' model parameters and 0.4% of their training tokens.
Finally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50x
larger than prior work). When compared with prior approaches under the same
compute budgets, LoLCATs significantly improves linearizing quality, closing
the gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8%
and 78.1% on 5-shot MMLU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>58 pages, 25 figures, 26 tables, ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GenCeption: Evaluate Vision LLMs with Unlabeled Unimodal Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14973v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14973v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lele Cao, Valentin Buchner, Zineb Senane, Fangkai Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) are typically assessed using
expensive annotated multimodal benchmarks, which often lag behind the rapidly
evolving demands of MLLM evaluation. This paper outlines and validates
GenCeption, a novel, annotation-free evaluation method that requires only
unimodal data to measure inter-modality semantic coherence and inversely
assesses MLLMs' tendency to hallucinate. This approach eliminates the need for
costly data annotation, minimizes the risk of training data contamination, is
expected to result in slower benchmark saturation, and avoids the illusion of
emerging abilities. Inspired by the DrawCeption game, GenCeption begins with a
non-textual sample and proceeds through iterative description and generation
steps. The semantic drift across iterations is quantified using the GC@T
metric. While GenCeption is principally applicable to MLLMs across various
modalities, this paper focuses on its implementation and validation for Vision
LLMs (VLLMs). Based on the GenCeption method, we establish the MMECeption
benchmark for evaluating VLLMs, and compare the performance of several popular
VLLMs and human annotators. Our empirical results validate GenCeption's
effectiveness, demonstrating strong correlations with established VLLM
benchmarks. VLLMs still significantly lag behind human performance and struggle
especially with text-intensive tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published by Computer Speech & Language
  (https://doi.org/10.1016/j.csl.2025.101785). Source code and Leaderboard:
  https://github.com/llcresearch/GenCeption</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Better Open-Ended Text Generation: A Multicriteria Evaluation
  Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.18653v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.18653v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Esteban Garces Arias, Hannah Blocher, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open-ended text generation has become a prominent task in natural language
processing due to the rise of powerful (large) language models. However,
evaluating the quality of these models and the employed decoding strategies
remains challenging because of trade-offs among widely used metrics such as
coherence, diversity, and perplexity. Decoding methods often excel in some
metrics while underperforming in others, complicating the establishment of a
clear ranking. In this paper, we present novel ranking strategies within this
multicriteria framework. Specifically, we employ benchmarking approaches based
on partial orderings and present a new summary metric designed to balance
existing automatic indicators, providing a more holistic evaluation of text
generation quality. Our experiments demonstrate that the proposed methods offer
a robust way to compare decoding strategies, and serve as valuable tools in
guiding model selection for open-ended text generation tasks. Finally, we
suggest future directions for improving evaluation methodologies in text
generation. Our codebase, datasets, and models are publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A generative approach to LLM harmfulness detection with special red flag
  tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16366v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16366v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sophie Xhonneux, David Dobre, Mehrnaz Mofakhami, Leo Schwinn, Gauthier Gidel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most safety training methods for large language models (LLMs) based on
fine-tuning rely on dramatically changing the output distribution of the model
when faced with a harmful request, shifting it from an unsafe answer to a
refusal to respond. These methods inherently compromise model capabilities and
might make auto-regressive models vulnerable to attacks that make likely an
initial token of affirmative response. To avoid that, we propose to expand the
model's vocabulary with a special token we call red flag token (<rf>) and
propose to fine-tune the model to generate this token at any time harmful
content is generated or about to be generated. This novel safety training
method effectively augments LLMs into generative classifiers of harmfulness at
all times during the conversation. This method offers several advantages: it
enables the model to explicitly learn the concept of harmfulness while
marginally affecting the generated distribution, thus maintaining the model's
utility. It also evaluates each generated answer rather than just the input
prompt and provides a stronger defence against sampling-based attacks. In
addition, it simplifies the evaluation of the model's robustness and reduces
correlated failures when combined with a classifier. We further show an
increased robustness to long contexts, and supervised fine-tuning attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Augmentation: Dropout as Augmentation for <span class="highlight-title">Self-Supervised</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.14537v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.14537v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rickard Brüel-Gabrielsson, Tongzhou Wang, Manel Baradad, Justin Solomon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite dropout's ubiquity in machine learning, its effectiveness as a form
of data augmentation remains under-explored. We address two key questions: (i)
When is dropout effective as an augmentation strategy? (ii) Is dropout uniquely
effective under these conditions? To explore these questions, we propose Deep
Augmentation, a network- and modality-agnostic method that applies dropout or
PCA transformations to targeted layers in neural networks. Through extensive
experiments on contrastive learning tasks in NLP, computer vision, and graph
learning, we find that uniformly applying dropout across layers does not
consistently improve performance. Instead, dropout proves most beneficial in
deeper layers and can be matched by alternative augmentations (e.g., PCA). We
also show that a stop-gradient operation is critical for ensuring dropout
functions effectively as an augmentation, and that performance trends invert
when moving from contrastive tasks to supervised tasks. Our analysis suggests
that Deep Augmentation helps mitigate inter-layer co-adaptation -- a notable
issue in self-supervised learning due to the absence of labeled data. Drawing
on these insights, we outline a procedure for selecting the optimal
augmentation layer and demonstrate that Deep Augmentation can outperform
traditional input-level augmentations. This simple yet powerful approach can be
seamlessly integrated into a wide range of architectures and modalities,
yielding notable gains in both performance and generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Helix: Serving Large Language Models over Heterogeneous GPUs and Network
  via Max-Flow <span class="chip">ASPLOS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01566v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01566v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixuan Mei, Yonghao Zhuang, Xupeng Miao, Juncheng Yang, Zhihao Jia, Rashmi Vinayak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Helix, a distributed system for high-throughput,
low-latency large language model (LLM) serving in heterogeneous GPU clusters.
The key idea behind Helix is to formulate inference computation of LLMs over
heterogeneous GPUs and network connections as a max-flow problem on directed,
weighted graphs, whose nodes represent GPU instances and edges capture both GPU
and network heterogeneity through their capacities. Helix then uses a mixed
integer linear programming (MILP) algorithm to discover highly optimized
strategies to serve LLMs on heterogeneous GPUs. This approach allows Helix to
jointly optimize model placement and request scheduling, two highly entangled
tasks in heterogeneous LLM serving. Our evaluation on several heterogeneous
clusters ranging from 24 to 42 GPU nodes shows that Helix improves serving
throughput by up to 3.3x and reduces prompting and decoding latency by up to
66% and 24%, respectively, compared to existing approaches. Helix is available
at https://github.com/Thesys-lab/Helix-ASPLOS25.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ASPLOS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Your Finetuned Large Language Model is Already a Powerful
  Out-of-distribution Detector 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08679v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08679v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andi Zhang, Tim Z. Xiao, Weiyang Liu, Robert Bamler, Damon Wischik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We revisit the likelihood ratio between a pretrained large language model
(LLM) and its finetuned variant as a criterion for out-of-distribution (OOD)
detection. The intuition behind such a criterion is that, the pretrained LLM
has the prior knowledge about OOD data due to its large amount of training
data, and once finetuned with the in-distribution data, the LLM has sufficient
knowledge to distinguish their difference. Leveraging the power of LLMs, we
show that, the likelihood ratio can serve as an effective OOD detection
criterion. Moreover, we apply the proposed LLM-based likelihood ratio to detect
OOD questions in question-answering (QA) systems, which can be used to improve
the performance of specialized LLMs for general questions. Given that
likelihood can be easily obtained by the loss functions within contemporary
neural network frameworks, it is straightforward to implement this approach in
practice. Since both the pretrained LLMs and its various finetuned models are
widely available from online platforms such as Hugging Face, our proposed
criterion can be effortlessly incorporated for OOD detection without the need
for further training. We conduct comprehensive evaluation across on multiple
settings, including far OOD, near OOD, spam detection, and QA scenarios, to
demonstrate the effectiveness of the method. Code can be found at
https://github.com/andiac/LLMOODratio
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05881v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05881v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Utsav Singh, Pramit Bhattacharyya, Vinay P. Namboodiri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing interactive systems that utilize natural language instructions to
solve complex robotic control tasks has long been a goal of the robotics
community. While Large Language Models (LLMs) excel at logical reasoning,
in-context learning, and code generation, translating high-level instructions
into low-level robotic actions still remains challenging. Furthermore, solving
such tasks often requires acquiring policies to execute diverse subtasks and
integrating them to achieve the final objective. Hierarchical Reinforcement
Learning (HRL) offers a promising solution for solving such tasks by enabling
temporal abstraction and improved exploration. However, HRL suffers from
non-stationarity caused by the changing lower-level behaviour, which hinders
effective policy learning. We propose LGR2, a novel HRL framework that
mitigates non-stationarity in HRL by using language-guided higher-level rewards
that remain unaffected by the changing lower-level policy behaviour. To analyze
the efficacy of our approach, we perform empirical analysis to demonstrate that
LGR2 effectively mitigates non-stationarity in HRL and attains success rates
exceeding 70% in challenging, sparsely-rewarded robotic navigation and
manipulation environments, where other baselines typically fail to show
significant progress. Finally, we perform real-world robotic experiments on
complex tasks and demonstrate that LGR2 consistently outperforms the baselines.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">11</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Addressing Overprescribing Challenges: Fine-Tuning Large Language Models
  for Medication Recommendation Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Zhao, Chenxiao Fan, Chongming Gao, Fuli Feng, Xiangnan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medication recommendation systems have garnered attention within healthcare
for their potential to deliver personalized and efficacious drug combinations
based on patient's clinical data. However, existing methodologies encounter
challenges in adapting to diverse Electronic Health Records (EHR) systems and
effectively utilizing unstructured data, resulting in limited generalization
capabilities and suboptimal performance. Recently, interest is growing in
harnessing Large Language Models (LLMs) in the medical domain to support
healthcare professionals and enhance patient care. Despite the emergence of
medical LLMs and their promising results in tasks like medical question
answering, their practical applicability in clinical settings, particularly in
medication recommendation, often remains underexplored.
  In this study, we evaluate both general-purpose and medical-specific LLMs for
medication recommendation tasks. Our findings reveal that LLMs frequently
encounter the challenge of overprescribing, leading to heightened clinical
risks and diminished medication recommendation accuracy. To address this issue,
we propose Language-Assisted Medication Recommendation (LAMO), which employs a
parameter-efficient fine-tuning approach to tailor open-source LLMs for optimal
performance in medication recommendation scenarios. LAMO leverages the wealth
of clinical information within clinical notes, a resource often underutilized
in traditional methodologies. As a result of our approach, LAMO outperforms
previous state-of-the-art methods by over 10% in internal validation accuracy.
Furthermore, temporal and external validations demonstrate LAMO's robust
generalization capabilities across various temporal and hospital contexts.
Additionally, an out-of-distribution medication recommendation experiment
demonstrates LAMO's remarkable accuracy even with medications outside the
training data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Intrinsic and Extrinsic Factor Disentanglement for Recommendation in
  Various Context Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Su, Wei Jiang, Fangquan Lin, Cheng Yang, Sarah M. Erfani, Junhao Gan, Yunxiang Zhao, Ruixuan Li, Rui Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recommender systems, the patterns of user behaviors (e.g., purchase,
click) may vary greatly in different contexts (e.g., time and location). This
is because user behavior is jointly determined by two types of factors:
intrinsic factors, which reflect consistent user preference, and extrinsic
factors, which reflect external incentives that may vary in different contexts.
Differentiating between intrinsic and extrinsic factors helps learn user
behaviors better. However, existing studies have only considered
differentiating them from a single, pre-defined context (e.g., time or
location), ignoring the fact that a user's extrinsic factors may be influenced
by the interplay of various contexts at the same time. In this paper, we
propose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a
generic framework that differentiates intrinsic from extrinsic factors
considering various contexts simultaneously, enabling more accurate
differentiation of factors and hence the improvement of recommendation
accuracy. IEDR contains a context-invariant contrastive learning component to
capture intrinsic factors, and a disentanglement component to extract extrinsic
factors under the interplay of various contexts. The two components work
together to achieve effective factor learning. Extensive experiments on
real-world datasets demonstrate IEDR's effectiveness in learning disentangled
factors and significantly improving recommendation accuracy by up to 4% in
NDCG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 13 figures, 11 tables. Accepted by Transactions of
  Information Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Predict-Then-Optimize Customer Allocation Framework for Online Fund
  Recommendation <span class="chip">DASFAA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03165v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03165v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xing Tang, Yunpeng Weng, Fuyuan Lyu, Dugang Liu, Xiuqiang He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid growth of online investment platforms, funds can be
distributed to individual customers online. The central issue is to match funds
with potential customers under constraints. Most mainstream platforms adopt the
recommendation formulation to tackle the problem. However, the traditional
recommendation regime has its inherent drawbacks when applying the
fund-matching problem with multiple constraints. In this paper, we model the
fund matching under the allocation formulation. We design PTOFA, a
Predict-Then-Optimize Fund Allocation framework. This data-driven framework
consists of two stages, i.e., prediction and optimization, which aim to predict
expected revenue based on customer behavior and optimize the impression
allocation to achieve the maximum revenue under the necessary constraints,
respectively. Extensive experiments on real-world datasets from an industrial
online investment platform validate the effectiveness and efficiency of our
solution. Additionally, the online A/B tests demonstrate PTOFA's effectiveness
in the real-world fund recommendation scenario.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by DASFAA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLARE: Fusing Language Models and Collaborative Architectures for
  Recommender Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11699v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11699v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liam Hebert, Marialena Kyriakidi, Hubert Pham, Krishna Sayana, James Pine, Sukhdeep Sodhi, Ambarish Jash
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent proposals in recommender systems represent items with their textual
description, using a large language model. They show better results on standard
benchmarks compared to an item ID-only model, such as Bert4Rec. In this work,
we revisit the often-used Bert4Rec baseline and show that with further tuning,
Bert4Rec significantly outperforms previously reported numbers, and in some
datasets, is competitive with state-of-the-art models.
  With revised baselines for item ID-only models, this paper also establishes
new competitive results for architectures that combine IDs and textual
descriptions. We demonstrate this with Flare (Fusing Language models and
collaborative Architectures for Recommender Enhancement). Flare is a novel
hybrid sequence recommender that integrates a language model with a
collaborative filtering model using a Perceiver network.
  Prior studies focus evaluation on datasets with limited-corpus size, but many
commercially-applicable recommender systems common on the web must handle
larger corpora. We evaluate Flare on a more realistic dataset with a
significantly larger item vocabulary, introducing new baselines for this
setting. This paper also showcases Flare's inherent ability to support
critiquing, enabling users to provide feedback and refine recommendations. We
leverage critiquing as an evaluation method to assess the model's language
understanding and its transferability to the recommendation task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01776v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01776v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tiansheng Wen, Yifei Wang, Zequn Zeng, Zhong Peng, Yudi Su, Xinyang Liu, Bo Chen, Hongwei Liu, Stefanie Jegelka, Chenyu You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many large-scale systems rely on high-quality deep representations
(embeddings) to facilitate tasks like retrieval, search, and generative
modeling. Matryoshka Representation Learning (MRL) recently emerged as a
solution for adaptive embedding lengths, but it requires full model retraining
and suffers from noticeable performance degradations at short lengths. In this
paper, we show that sparse coding offers a compelling alternative for achieving
adaptive representation with minimal overhead and higher fidelity. We propose
Contrastive Sparse Representation (CSR), a method that sparsifies pre-trained
embeddings into a high-dimensional but selectively activated feature space. By
leveraging lightweight autoencoding and task-aware contrastive objectives, CSR
preserves semantic quality while allowing flexible, cost-effective inference at
different sparsity levels. Extensive experiments on image, text, and multimodal
benchmarks demonstrate that CSR consistently outperforms MRL in terms of both
accuracy and retrieval speed-often by large margins-while also cutting training
time to a fraction of that required by MRL. Our results establish sparse coding
as a powerful paradigm for adaptive representation learning in real-world
applications where efficiency and fidelity are both paramount. Code is
available at https://github.com/neilwen987/CSR_Adaptive_Rep
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A novel sparse coding framework designed for learning adaptive
  representation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Content Relevance: Evaluating Instruction Following in Retrieval
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.23841v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.23841v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianqun Zhou, Yuanlei Zheng, Wei Chen, Qianqian Zheng, Hui Su, Wei Zhang, Rui Meng, Xiaoyu Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction-following capabilities in LLMs have progressed significantly,
enabling more complex user interactions through detailed prompts. However,
retrieval systems have not matched these advances, most of them still relies on
traditional lexical and semantic matching techniques that fail to fully capture
user intent. Recent efforts have introduced instruction-aware retrieval models,
but these primarily focus on intrinsic content relevance, which neglects the
importance of customized preferences for broader document-level attributes.
This study evaluates the instruction-following capabilities of various
retrieval models beyond content relevance, including LLM-based dense retrieval
and reranking models. We develop InfoSearch, a novel retrieval evaluation
benchmark spanning six document-level attributes: Audience, Keyword, Format,
Language, Length, and Source, and introduce novel metrics -- Strict Instruction
Compliance Ratio (SICR) and Weighted Instruction Sensitivity Evaluation (WISE)
to accurately assess the models' responsiveness to instructions. Our findings
indicate that although fine-tuning models on instruction-aware retrieval
datasets and increasing model size enhance performance, most models still fall
short of instruction compliance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Use of Air Quality Sensor Network Data for Real-time Pollution-Aware POI
  Suggestion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09155v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09155v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giuseppe Fasano, Yashar Deldjoo, Tommaso di Noia, Bianca Lau, Sina Adham-Khiabani, Eric Morris, Xia Liu, Ganga Chinna Rao Devarapu, Liam O'Faolain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This demo paper introduces AirSense-R, a privacy-preserving mobile
application that delivers real-time, pollution-aware recommendations for urban
points of interest (POIs). By merging live air quality data from AirSENCE
sensor networks in Bari (Italy) and Cork (Ireland) with user preferences, the
system enables health-conscious decision-making. It employs collaborative
filtering for personalization, federated learning for privacy, and a prediction
engine to detect anomalies and interpolate sparse sensor data. The proposed
solution adapts dynamically to urban air quality while safeguarding user
privacy. The code and demonstration video are available at
https://github.com/AirtownApp/Airtown-Application.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01711v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01711v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Ming He, Jianping Fan, Xiao Zhang, Jun Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized product search aims to retrieve and rank items that match users'
preferences and search intent. Despite their effectiveness, existing approaches
typically assume that users' query fully captures their real motivation.
However, our analysis of a real-world e-commerce platform reveals that users
often engage in relevant consultations before searching, indicating they refine
intents through consultations based on motivation and need. The implied
motivation in consultations is a key enhancing factor for personalized search.
This unexplored area comes with new challenges including aligning contextual
motivations with concise queries, bridging the category-text gap, and filtering
noise within sequence history. To address these, we propose a Motivation-Aware
Personalized Search (MAPS) method. It embeds queries and consultations into a
unified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)
to prioritize critical semantics, and introduces dual alignment: (1)
contrastive learning aligns consultations, reviews, and product features; (2)
bidirectional attention integrates motivation-aware embeddings with user
preferences. Extensive experiments on real and synthetic data show MAPS
outperforms existing methods in both retrieval and ranking tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>added project repository & dataset URL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MCiteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02589v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02589v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Caiyu Hu, Yikai Zhang, Tinghui Zhu, Yiwei Ye, Yanghua Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse
modalities but frequently suffer from hallucination. A promising solution to
mitigate this issue is to generate text with citations, providing a transparent
chain for verification. However, existing work primarily focuses on generating
citations for text-only content, overlooking the challenges and opportunities
of multimodal contexts. To address this gap, we introduce MCiteBench, the first
benchmark designed to evaluate and analyze the multimodal citation text
generation ability of MLLMs. Our benchmark comprises data derived from academic
papers and review-rebuttal interactions, featuring diverse information sources
and multimodal content. We comprehensively evaluate models from multiple
dimensions, including citation quality, source reliability, and answer
accuracy. Through extensive experiments, we observe that MLLMs struggle with
multimodal citation text generation. We also conduct deep analyses of models'
performance, revealing that the bottleneck lies in attributing the correct
sources rather than understanding the multimodal content.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Long-Sequence Recommendation Models Need Decoupled Embeddings <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02604v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02604v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ningya Feng, Junwei Pan, Jialong Wu, Baixu Chen, Ximei Wang, Qian Li, Xian Hu, Jie Jiang, Mingsheng Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lifelong user behavior sequences are crucial for capturing user interests and
predicting user responses in modern recommendation systems. A two-stage
paradigm is typically adopted to handle these long sequences: a subset of
relevant behaviors is first searched from the original long sequences via an
attention mechanism in the first stage and then aggregated with the target item
to construct a discriminative representation for prediction in the second
stage. In this work, we identify and characterize, for the first time, a
neglected deficiency in existing long-sequence recommendation models: a single
set of embeddings struggles with learning both attention and representation,
leading to interference between these two processes. Initial attempts to
address this issue with some common methods (e.g., linear projections -- a
technique borrowed from language processing) proved ineffective, shedding light
on the unique challenges of recommendation models. To overcome this, we propose
the Decoupled Attention and Representation Embeddings (DARE) model, where two
distinct embedding tables are initialized and learned separately to fully
decouple attention and representation. Extensive experiments and analysis
demonstrate that DARE provides more accurate searches of correlated behaviors
and outperforms baselines with AUC gains up to 0.9% on public datasets and
notable improvements on Tencent's advertising platform. Furthermore, decoupling
embedding spaces allows us to reduce the attention embedding dimension and
accelerate the search procedure by 50% without significant performance impact,
enabling more efficient, high-performance online serving. Code in PyTorch for
experiments, including model analysis, is available at
https://github.com/thuml/DARE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025. First three authors contributed equally. Code is available
  at https://github.com/thuml/DARE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query
  Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02603v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02603v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulong Hui, Yihao Liu, Yao Lu, Huanchen Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) encounter challenges in efficiently processing
long-text queries, as seen in applications like enterprise document analysis
and financial report comprehension. While conventional solutions employ
long-context processing or Retrieval-Augmented Generation (RAG), they suffer
from prohibitive input expenses or incomplete information. Recent advancements
adopt context compression and dynamic retrieval loops, but still sacrifice
critical details or incur iterative costs. To address these limitations, we
propose OkraLong, a novel framework that flexibly optimizes the entire
processing workflow. Unlike prior static or coarse-grained adaptive strategies,
OkraLong adopts fine-grained orchestration through three synergistic
components: analyzer, organizer and executor. The analyzer characterizes the
task states, which guide the organizer in dynamically scheduling the workflow.
The executor carries out the execution and generates the final answer.
Experimental results demonstrate that OkraLong not only enhances answer
accuracy but also achieves cost-effectiveness across a variety of datasets.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ More than Memes: A Multimodal Topic Modeling Approach to Conspiracy
  Theories on Telegram 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08642v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08642v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elisabeth Steffen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To address the increasing prevalence of (audio-)visual data on social media,
and to capture the evolving and dynamic nature of this communication,
researchers have begun to explore the potential of unsupervised approaches for
analyzing multimodal online content. However, existing research often neglects
visual content beyond memes, and in addition lacks methods to compare topic
models across modalities. Our study addresses these gaps by applying multimodal
topic modeling for analyzing conspiracy theories in German-language Telegram
channels. We use BERTopic with CLIP for the analysis of textual and visual data
in a corpus of ~40, 000 Telegram messages posted in October 2023 in 571
German-language Telegram channels known for disseminating conspiracy theories.
Through this dataset, we provide insights into unimodal and multimodal topic
models by analyzing symmetry and intersections of topics across modalities. We
demonstrate the variety of textual and visual content shared in the channels
discovered through the topic modeling, and propose a conceptual framework for
the analysis of textual and visual discursive strategies in the communication
of conspiracy theories. We apply the framework in a case study of the topic
group Israel Gaza.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Undetectable Watermark for Generative Image Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07369v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07369v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sam Gunn, Xuandong Zhao, Dawn Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the first undetectable watermarking scheme for generative image
models. Undetectability ensures that no efficient adversary can distinguish
between watermarked and un-watermarked images, even after making many adaptive
queries. In particular, an undetectable watermark does not degrade image
quality under any efficiently computable metric. Our scheme works by selecting
the initial latents of a diffusion model using a pseudorandom error-correcting
code (Christ and Gunn, 2024), a strategy which guarantees undetectability and
robustness. We experimentally demonstrate that our watermarks are
quality-preserving and robust using Stable Diffusion 2.1. Our experiments
verify that, in contrast to every prior scheme we tested, our watermark does
not degrade image quality. Our experiments also demonstrate robustness:
existing watermark removal attacks fail to remove our watermark from images
without significantly degrading the quality of the images. Finally, we find
that we can robustly encode 512 bits in our watermark, and up to 2500 bits when
the images are not subjected to watermark removal attacks. Our code is
available at https://github.com/XuandongZhao/PRC-Watermark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-04T00:00:00Z">2025-03-04</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">28</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semi-Supervised In-Context Learning: A Baseline Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03062v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03062v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyao Gu, Henry Peng Zou, Yankai Chen, Aiwei Liu, Weizhi Zhang, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most existing work in data selection for In-Context Learning (ICL) has
focused on constructing demonstrations from ground truth annotations, with
limited attention given to selecting reliable self-generated annotations. In
this work, we propose a three-step semi-supervised ICL framework: annotation
generation, demonstration selection, and semi-supervised inference. Our
baseline, Naive-SemiICL, which prompts select high-confidence self-generated
demonstrations for ICL prompting, outperforms a 16-shot baseline by an average
of 9.94% across 16 datasets. We further introduce IterPSD, an annotation
approach that refines pseudo-demonstrations iteratively, achieving up to 6.8%
additional gains in classification tasks. Lastly, we reveal a scaling law for
semi-supervised ICL, where models achieve optimal performance with over 1,000
demonstrations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders
  Vs. Classic Encoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02993v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02993v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Souvika Sarkar, Md. Najib Hasan, Santu Karmaker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bangla, a language spoken by over 300 million native speakers and ranked as
the sixth most spoken language worldwide, presents unique challenges in natural
language processing (NLP) due to its complex morphological characteristics and
limited resources. While recent Large Decoder Based models (LLMs), such as GPT,
LLaMA, and DeepSeek, have demonstrated excellent performance across many NLP
tasks, their effectiveness in Bangla remains largely unexplored. In this paper,
we establish the first benchmark comparing decoder-based LLMs with classic
encoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC)
task in Bangla. Our evaluation of 32 state-of-the-art models reveals that,
existing so-called powerful encoders and decoders still struggle to achieve
high accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more
research and resources for Bangla NLP.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ExpertGenQA: Open-ended QA generation in Specialized Domains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02948v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02948v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haz Sameen Shahgir, Chansong Lim, Jia Chen, Evangelos E. Papalexakis, Yue Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating high-quality question-answer pairs for specialized technical
domains remains challenging, with existing approaches facing a tradeoff between
leveraging expert examples and achieving topical diversity. We present
ExpertGenQA, a protocol that combines few-shot learning with structured topic
and style categorization to generate comprehensive domain-specific QA pairs.
Using U.S. Federal Railroad Administration documents as a test bed, we
demonstrate that ExpertGenQA achieves twice the efficiency of baseline few-shot
approaches while maintaining $94.4\%$ topic coverage. Through systematic
evaluation, we show that current LLM-based judges and reward models exhibit
strong bias toward superficial writing styles rather than content quality. Our
analysis using Bloom's Taxonomy reveals that ExpertGenQA better preserves the
cognitive complexity distribution of expert-written questions compared to
template-based approaches. When used to train retrieval models, our generated
queries improve top-1 accuracy by $13.02\%$ over baseline performance,
demonstrating their effectiveness for downstream applications in technical
domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing open-domain question answering with graph-based retrieval
  augmented generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02922v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02922v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joyce Cahoon, Prerna Singh, Nick Litombe, Jonathan Larson, Ha Trinh, Yiwen Zhu, Andreas Mueller, Fotis Psallidas, Carlo Curino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we benchmark various graph-based retrieval-augmented generation
(RAG) systems across a broad spectrum of query types, including OLTP-style
(fact-based) and OLAP-style (thematic) queries, to address the complex demands
of open-domain question answering (QA). Traditional RAG methods often fall
short in handling nuanced, multi-document synthesis tasks. By structuring
knowledge as graphs, we can facilitate the retrieval of context that captures
greater semantic depth and enhances language model operations. We explore
graph-based RAG methodologies and introduce TREX, a novel, cost-effective
alternative that combines graph-based and vector-based retrieval techniques.
Our benchmarking across four diverse datasets highlights the strengths of
different RAG methodologies, demonstrates TREX's ability to handle multiple
open-domain QA types, and reveals the limitations of current evaluation
methods.
  In a real-world technical support case study, we demonstrate how TREX
solutions can surpass conventional vector-based RAG in efficiently synthesizing
data from heterogeneous sources. Our findings underscore the potential of
augmenting large language models with advanced retrieval and orchestration
capabilities, advancing scalable, graph-based AI solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot Complex Question-Answering on Long Scientific Documents <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanting Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development in Transformer-based language models, the reading
comprehension tasks on short documents and simple questions have been largely
addressed. Long documents, specifically the scientific documents that are
densely packed with knowledge discovered and developed by humans, remain
relatively unexplored. These documents often come with a set of complex and
more realistic questions, adding to their complexity. We present a zero-shot
pipeline framework that enables social science researchers to perform
question-answering tasks that are complex yet of predetermined question formats
on full-length research papers without requiring machine learning expertise.
Our approach integrates pre-trained language models to handle challenging
scenarios including multi-span extraction, multi-hop reasoning, and long-answer
generation. Evaluating on MLPsych, a novel dataset of social psychology papers
with annotated complex questions, we demonstrate that our framework achieves
strong performance through combination of extractive and generative models.
This work advances document understanding capabilities for social sciences
while providing practical tools for researchers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>AAAI 2025 Workshop on Document Understanding and Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Robust Expert Finding in Community Question Answering Platforms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maddalena Amendola, Andrea Passarella, Raffaele Perego
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces TUEF, a topic-oriented user-interaction model for fair
Expert Finding in Community Question Answering (CQA) platforms. The Expert
Finding task in CQA platforms involves identifying proficient users capable of
providing accurate answers to questions from the community. To this aim, TUEF
improves the robustness and credibility of the CQA platform through a more
precise Expert Finding component. The key idea of TUEF is to exploit diverse
types of information, specifically, content and social information, to identify
more precisely experts thus improving the robustness of the task. We assess
TUEF through reproducible experiments conducted on a large-scale dataset from
StackOverflow. The results consistently demonstrate that TUEF outperforms
state-of-the-art competitors while promoting transparent expert identification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are some books better than others? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hannes Rosenbusch, Luke Korthals
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scholars, awards committees, and laypeople frequently discuss the merit of
written works. Literary professionals and journalists differ in how much
perspectivism they concede in their book reviews. Here, we quantify how
strongly book reviews are determined by the actual book contents vs.
idiosyncratic reader tendencies. In our analysis of 624,320 numerical and
textual book reviews, we find that the contents of professionally published
books are not predictive of a random reader's reading enjoyment. Online reviews
of popular fiction and non-fiction books carry up to ten times more information
about the reviewer than about the book. For books of a preferred genre, readers
might be less likely to give low ratings, but still struggle to converge in
their relative assessments. We find that book evaluations generalize more
across experienced review writers than casual readers. When discussing specific
issues with a book, one review text had poor predictability of issues brought
up in another review of the same book. We conclude that extreme perspectivism
is a justifiable position when researching literary quality, bestowing literary
awards, and designing recommendation systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Generation In Large Model Era: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiyan Xu, Jinghao Zhang, Alireza Salemi, Xinting Hu, Wenjie Wang, Fuli Feng, Hamed Zamani, Xiangnan He, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the era of large models, content generation is gradually shifting to
Personalized Generation (PGen), tailoring content to individual preferences and
needs. This paper presents the first comprehensive survey on PGen,
investigating existing research in this rapidly growing field. We conceptualize
PGen from a unified perspective, systematically formalizing its key components,
core objectives, and abstract workflows. Based on this unified perspective, we
propose a multi-level taxonomy, offering an in-depth review of technical
advancements, commonly used datasets, and evaluation metrics across multiple
modalities, personalized contexts, and tasks. Moreover, we envision the
potential applications of PGen and highlight open challenges and promising
directions for future exploration. By bridging PGen research across multiple
modalities, this survey serves as a valuable resource for fostering knowledge
sharing and interdisciplinary collaboration, ultimately contributing to a more
personalized digital landscape.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Long Sequential Low-rank Adaptive Attention for Click-through
  rate Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Song, Xiaochen Li, Jinxin Hu, Hong Wen, Zulong Chen, Yu Zhang, Xiaoyi Zeng, Zhang Jing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the context of burgeoning user historical behavior data, Accurate
click-through rate(CTR) prediction requires effective modeling of lengthy user
behavior sequences. As the volume of such data keeps swelling, the focus of
research has shifted towards developing effective long-term behavior modeling
methods to capture latent user interests. Nevertheless, the complexity
introduced by large scale data brings about computational hurdles. There is a
pressing need to strike a balance between achieving high model performance and
meeting the strict response time requirements of online services. While
existing retrieval-based methods (e.g., similarity filtering or attention
approximation) achieve practical runtime efficiency, they inherently compromise
information fidelity through aggressive sequence truncation or attention
sparsification. This paper presents a novel attention mechanism. It overcomes
the shortcomings of existing methods while ensuring computational efficiency.
This mechanism learn compressed representation of sequence with length $L$ via
low-rank projection matrices (rank $r \ll L$), reducing attention complexity
from $O(L)$ to $O(r)$. It also integrates a uniquely designed loss function to
preserve nonlinearity of attention. In the inference stage, the mechanism
adopts matrix absorption and prestorage strategies. These strategies enable it
to effectively satisfy online constraints. Comprehensive offline and online
experiments demonstrate that the proposed method outperforms current
state-of-the-art solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sparse Meets Dense: Unified Generative Recommendations with Cascaded
  Sparse-Dense Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02453v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02453v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Yang, Zhi Ji, Zhaopeng Li, Yi Li, Zhonglin Mo, Yue Ding, Kai Chen, Zijian Zhang, Jie Li, Shuanglong Li, Lin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models have recently gained attention in recommendation systems by
directly predicting item identifiers from user interaction sequences. However,
existing methods suffer from significant information loss due to the separation
of stages such as quantization and sequence modeling, hindering their ability
to achieve the modeling precision and accuracy of sequential dense retrieval
techniques. Integrating generative and dense retrieval methods remains a
critical challenge. To address this, we introduce the Cascaded Organized
Bi-Represented generAtive retrieval (COBRA) framework, which innovatively
integrates sparse semantic IDs and dense vectors through a cascading process.
Our method alternates between generating these representations by first
generating sparse IDs, which serve as conditions to aid in the generation of
dense vectors. End-to-end training enables dynamic refinement of dense
representations, capturing both semantic insights and collaborative signals
from user-item interactions. During inference, COBRA employs a coarse-to-fine
strategy, starting with sparse ID generation and refining them into dense
vectors via the generative model. We further propose BeamFusion, an innovative
approach combining beam search with nearest neighbor scores to enhance
inference flexibility and recommendation diversity. Extensive experiments on
public datasets and offline tests validate our method's robustness. Online A/B
tests on a real-world advertising platform with over 200 million daily users
demonstrate substantial improvements in key metrics, highlighting COBRA's
practical advantages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hierarchical Re-ranker Retriever (HRR) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashish Singh, Priti Mohapatra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieving the right level of context for a given query is a perennial
challenge in information retrieval - too large a chunk dilutes semantic
specificity, while chunks that are too small lack broader context. This paper
introduces the Hierarchical Re-ranker Retriever (HRR), a framework designed to
achieve both fine-grained and high-level context retrieval for large language
model (LLM) applications. In HRR, documents are split into sentence-level and
intermediate-level (512 tokens) chunks to maximize vector-search quality for
both short and broad queries. We then employ a reranker that operates on these
512-token chunks, ensuring an optimal balance neither too coarse nor too fine
for robust relevance scoring. Finally, top-ranked intermediate chunks are
mapped to parent chunks (2048 tokens) to provide an LLM with sufficiently large
context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PersonaX: A Recommendation Agent Oriented User Modeling Framework for
  Long Behavior Sequence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02398v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02398v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunxiao Shi, Wujiang Xu, Zeqi Zhang, Xing Zi, Qiang Wu, Min Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation agents leverage large language models for user modeling LLM UM
to construct textual personas guiding alignment with real users. However
existing LLM UM methods struggle with long user generated content UGC due to
context limitations and performance degradation. To address this sampling
strategies prioritize relevance or recency are often applied yet they
inevitably neglect the diverse user interests embedded within the discarded
behaviors resulting in incomplete modeling and degraded profiling quality.
Furthermore relevance based sampling requires real time retrieval forcing the
user modeling process to operate online which introduces significant latency
overhead. In this paper we propose PersonaX an agent agnostic LLM UM framework
that tackles these challenges through sub behavior sequence SBS selection and
offline multi persona construction. PersonaX extracts compact SBS segments
offline to capture diverse user interests generating fine grained textual
personas that are cached for efficient online retrieval. This approach ensures
that the user persona used for prompting remains highly relevant to the current
context while eliminating the need for online user modeling. For SBS selection
we ensure both efficiency length less than five and high representational
quality by balancing prototypicality and diversity within the sampled data.
Extensive experiments validate the effectiveness and versatility of PersonaX in
high quality user profiling. Utilizing only 30 to 50 percent of the behavioral
data with a sequence length of 480 integrating PersonaX with AgentCF yields an
absolute performance improvement of 3 to 11 percent while integration with
Agent4Rec results in a gain of 10 to 50 percent. PersonaX as an agent agnostic
framework sets a new benchmark for scalable user modeling paving the way for
more accurate and efficient LLM driven recommendation agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>draft paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Explainable Doctor Recommendation with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyang Zeng, Dongyuan Li, Yuqing Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of internet medicine provides patients with unprecedented
convenience in searching and communicating with doctors relevant to their
diseases and desired treatments online. However, the current doctor
recommendation systems fail to fully ensure the professionalism and
interpretability of the recommended results. In this work, we formulate doctor
recommendation as a ranking task and develop a large language model (LLM)-based
pointwise ranking framework. Our framework ranks doctors according to their
relevance regarding specific diseases-treatment pairs in a zero-shot setting.
The advantage of our framework lies in its ability to generate precise and
explainable doctor ranking results. Additionally, we construct DrRank, a new
expertise-driven doctor ranking dataset comprising over 38 disease-treatment
pairs. Experiment results on the DrRank dataset demonstrate that our framework
significantly outperforms the strongest cross-encoder baseline, achieving a
notable gain of +5.45 in the NDCG@10 score while maintaining affordable latency
consumption. Furthermore, we comprehensively present the fairness analysis
results of our framework from three perspectives of different diseases, patient
gender, and geographical regions. Meanwhile, the interpretability of our
framework is rigorously verified by three human experts, providing further
evidence of the reliability of our proposed framework for doctor
recommendation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 6 figures, Journal of Biomedical and Health Informatics
  (JBHI) under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tailoring Table Retrieval from a Field-aware Hybrid Matching Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02251v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02251v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Da Li, Keping Bi, Jiafeng Guo, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Table retrieval, essential for accessing information through tabular data, is
less explored compared to text retrieval. The row/column structure and distinct
fields of tables (including titles, headers, and cells) present unique
challenges. For example, different table fields have varying matching
preferences: cells may favor finer-grained (word/phrase level) matching over
broader (sentence/passage level) matching due to their fragmented and detailed
nature, unlike titles. This necessitates a table-specific retriever to
accommodate the various matching needs of each table field. Therefore, we
introduce a Table-tailored HYbrid Matching rEtriever (THYME), which approaches
table retrieval from a field-aware hybrid matching perspective. Empirical
results on two table retrieval benchmarks, NQ-TABLES and OTT-QA, show that
THYME significantly outperforms state-of-the-art baselines. Comprehensive
analyses confirm the differing matching preferences across table fields and
validate the design of THYME.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Simplified Retriever to Improve Accuracy of Phenotype Normalizations
  by Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13744v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13744v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel B. Hier, Thanh Son Do, Tayo Obafemi-Ajayi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown improved accuracy in phenotype term
normalization tasks when augmented with retrievers that suggest candidate
normalizations based on term definitions. In this work, we introduce a
simplified retriever that enhances LLM accuracy by searching the Human
Phenotype Ontology (HPO) for candidate matches using contextual word embeddings
from BioBERT without the need for explicit term definitions. Testing this
method on terms derived from the clinical synopses of Online Mendelian
Inheritance in Man (OMIM), we demonstrate that the normalization accuracy of a
state-of-the-art LLM increases from a baseline of 62.3% without augmentation to
90.3% with retriever augmentation. This approach is potentially generalizable
to other biomedical term normalization tasks and offers an efficient
alternative to more complex retrieval methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published by Frontiers in Digital Health</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comparative Evaluation of Quantification Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2103.03223v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2103.03223v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Schumacher, Markus Strohmaier, Florian Lemmerich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quantification represents the problem of estimating the distribution of class
labels on unseen data. It also represents a growing research field in
supervised machine learning, for which a large variety of different algorithms
has been proposed in recent years. However, a comprehensive empirical
comparison of quantification methods that supports algorithm selection is not
available yet. In this work, we close this research gap by conducting a
thorough empirical performance comparison of 24 different quantification
methods on overall more than 40 data sets, considering binary as well as
multiclass quantification settings. We observe that no single algorithm
generally outperforms all competitors, but identify a group of methods
including the threshold selection-based Median Sweep and TSMax methods, the DyS
framework including the HDy method, Forman's mixture model, and Friedman's
method that performs best in the binary setting. For the multiclass setting, we
observe that a different, broad group of algorithms yields good performance,
including the HDx method, the Generalized Probabilistic Adjusted Count, the
readme method, the energy distance minimization method, the EM algorithm for
quantification, and Friedman's method. We also find that tuning the underlying
classifiers has in most cases only a limited impact on the quantification
performance. More generally, we find that the performance on multiclass
quantification is inferior to the results obtained in the binary setting. Our
results can guide practitioners who intend to apply quantification algorithms
and help researchers to identify opportunities for future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>41 pages, 18 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive <span class="highlight-title">Survey</span> on Composed Image Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18495v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18495v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuemeng Song, Haoqiang Lin, Haokun Wen, Bohan Hou, Mingzhu Xu, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Composed Image Retrieval (CIR) is an emerging yet challenging task that
allows users to search for target images using a multimodal query, comprising a
reference image and a modification text specifying the user's desired changes
to the reference image. Given its significant academic and practical value, CIR
has become a rapidly growing area of interest in the computer vision and
machine learning communities, particularly with the advances in deep learning.
To the best of our knowledge, there is currently no comprehensive review of CIR
to provide a timely overview of this field. Therefore, we synthesize insights
from over 120 publications in top conferences and journals, including ACM TOIS,
SIGIR, and CVPR In particular, we systematically categorize existing supervised
CIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive
review, we also briefly discuss approaches for tasks closely related to CIR,
such as attribute-based CIR and dialog-based CIR. Additionally, we summarize
benchmark datasets for evaluation and analyze existing supervised and zero-shot
CIR methods by comparing experimental results across multiple datasets.
Furthermore, we present promising future directions in this field, offering
practical insights for researchers interested in further exploration. The
curated collection of related works is maintained and continuously updated in
https://github.com/haokunwen/Awesome-Composed-Image-Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GENET: Unleashing the Power of Side Information for Recommendation via
  Hypergraph <span class="highlight-title">Pre-train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.13121v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.13121v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Li, Qi'ao Zhao, Chen Lin, Zhenjie Zhang, Xiaomin Zhu, Jinsong Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation with side information has drawn significant research interest
due to its potential to mitigate user feedback sparsity. However, existing
models struggle with generalization across diverse domains and types of side
information. In particular, three challenges have not been addressed, and they
are (1) the diverse formats of side information, including text sequences. (2)
The diverse semantics of side information that describes items and users from
multi-level in a context different from recommendation systems. (3) The diverse
correlations in side information to measure similarity over multiple objects
beyond pairwise relations. In this paper, we introduce GENET (Generalized
hypErgraph pretraiNing on sidE informaTion), which pre-trains user and item
representations on feedback-irrelevant side information and fine-tunes the
representations on user feedback data. GENET leverages pre-training as a means
to prevent side information from overshadowing critical ID features and
feedback signals. It employs a hypergraph framework to accommodate various
types of diverse side information. During pre-training, GENET integrates tasks
for hyperlink prediction and self-supervised contrast to capture fine-grained
semantics at both local and global levels. Additionally, it introduces a unique
strategy to enhance pre-training robustness by perturbing positive samples
while maintaining high-order relations. Extensive experiments demonstrate that
GENET exhibits strong generalization capabilities, outperforming the SOTA
method by up to 38% in TOP-N recommendation and Sequential recommendation tasks
on various datasets with different side information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Matching to Generation: A <span class="highlight-title">Survey</span> on Generative Information
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14851v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14851v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yuyao Zhang, Peitian Zhang, Yutao Zhu, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information Retrieval (IR) systems are crucial tools for users to access
information, which have long been dominated by traditional methods relying on
similarity matching. With the advancement of pre-trained language models,
generative information retrieval (GenIR) emerges as a novel paradigm,
attracting increasing attention. Based on the form of information provided to
users, current research in GenIR can be categorized into two aspects:
\textbf{(1) Generative Document Retrieval} (GR) leverages the generative
model's parameters for memorizing documents, enabling retrieval by directly
generating relevant document identifiers without explicit indexing. \textbf{(2)
Reliable Response Generation} employs language models to directly generate
information users seek, breaking the limitations of traditional IR in terms of
document granularity and relevance matching while offering flexibility,
efficiency, and creativity to meet practical needs. This paper aims to
systematically review the latest research progress in GenIR. We will summarize
the advancements in GR regarding model training and structure, document
identifier, incremental learning, etc., as well as progress in reliable
response generation in aspects of internal knowledge memorization, external
knowledge augmentation, etc. We also review the evaluation, challenges and
future developments in GenIR systems. This review aims to offer a comprehensive
reference for researchers, encouraging further development in the GenIR field.
Github Repository: https://github.com/RUC-NLPIR/GenIR-Survey
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pattern-wise Transparent Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11480v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11480v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kun Ma, Cong Xu, Zeyuan Chen, Wei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A transparent decision-making process is essential for developing reliable
and trustworthy recommender systems. For sequential recommendation, it means
that the model can identify key items that account for its recommendation
results. However, achieving both interpretability and recommendation
performance simultaneously is challenging, especially for models that take the
entire sequence of items as input without screening. In this paper, we propose
an interpretable framework (named PTSR) that enables a pattern-wise transparent
decision-making process without extra features. It breaks the sequence of items
into multi-level patterns that serve as atomic units throughout the
recommendation process. The contribution of each pattern to the outcome is
quantified in the probability space. With a carefully designed score correction
mechanism, the pattern contribution can be implicitly learned in the absence of
ground-truth key patterns. The final recommended items are those that most key
patterns strongly endorse. Extensive experiments on five public datasets
demonstrate remarkable recommendation performance, while statistical analysis
and case studies validate the model interpretability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by IEEE TKDE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VideoRAG: Retrieval-Augmented Generation over Video Corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soyeong Jeong, Kangsan Kim, Jinheon Baek, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the
factual accuracy of models by retrieving external knowledge relevant to queries
and incorporating it into the generation process. However, existing approaches
primarily focus on text, with some recent advancements considering images, and
they largely overlook videos, a rich source of multimodal knowledge capable of
representing contextual details more effectively than any other modality. While
very recent studies explore the use of videos in response generation, they
either predefine query-associated videos without retrieval or convert videos
into textual descriptions losing multimodal richness. To tackle these, we
introduce VideoRAG, a framework that not only dynamically retrieves videos
based on their relevance with queries but also utilizes both visual and textual
information. The operation of VideoRAG is powered by recent Large Video
Language Models (LVLMs), which enable the direct processing of video content to
represent it for retrieval and the seamless integration of retrieved videos
jointly with queries for response generation. Also, inspired by that the
context size of LVLMs may not be sufficient to process all frames in extremely
long videos and not all frames are equally important, we introduce a video
frame selection mechanism to extract the most informative subset of frames,
along with a strategy to extract textual information from videos (as it can aid
the understanding of video content) when their subtitles are not available. We
experimentally validate the effectiveness of VideoRAG, showcasing that it is
superior to relevant baselines. Code is available at
https://github.com/starsuzi/VideoRAG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scholar Name Disambiguation with Search-enhanced LLM Across Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.17102v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.17102v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renyu Zhao, Yunxin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of scholar name disambiguation is crucial in various real-world
scenarios, including bibliometric-based candidate evaluation for awards,
application material anti-fraud measures, and more. Despite significant
advancements, current methods face limitations due to the complexity of
heterogeneous data, often necessitating extensive human intervention. This
paper proposes a novel approach by leveraging search-enhanced language models
across multiple languages to improve name disambiguation. By utilizing the
powerful query rewriting, intent recognition, and data indexing capabilities of
search engines, our method can gather richer information for distinguishing
between entities and extracting profiles, resulting in a more comprehensive
data dimension. Given the strong cross-language capabilities of large language
models(LLMs), optimizing enhanced retrieval methods with this technology offers
substantial potential for high-efficiency information retrieval and
utilization. Our experiments demonstrate that incorporating local languages
significantly enhances disambiguation performance, particularly for scholars
from diverse geographic regions. This multi-lingual, search-enhanced
methodology offers a promising direction for more efficient and accurate active
scholar name disambiguation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hierarchical Causal <span class="highlight-title">Transformer</span> with Heterogeneous Information for
  Expandable Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01469v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01469v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Deng, Haibo Xing, Kanefumi Matsuyama, Yulei Huang, Jinxin Hu, Hong Wen, Jia Xu, Zulong Chen, Yu Zhang, Xiaoyi Zeng, Jing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation systems leveraging transformer architectures have
demonstrated exceptional capabilities in capturing user behavior patterns. At
the core of these systems lies the critical challenge of constructing effective
item representations. Traditional approaches employ feature fusion through
simple concatenation or basic neural architectures to create uniform
representation sequences. However, these conventional methods fail to address
the intrinsic diversity of item attributes, thereby constraining the
transformer's capacity to discern fine-grained patterns and hindering model
extensibility. Although recent research has begun incorporating user-related
heterogeneous features into item sequences, the equally crucial item-side
heterogeneous feature continue to be neglected. To bridge this methodological
gap, we present HeterRec - an innovative framework featuring two novel
components: the Heterogeneous Token Flattening Layer (HTFL) and Hierarchical
Causal Transformer (HCT). HTFL pioneers a sophisticated tokenization mechanism
that decomposes items into multi-dimensional token sets and structures them
into heterogeneous sequences, enabling scalable performance enhancement through
model expansion. The HCT architecture further enhances pattern discovery
through token-level and item-level attention mechanisms. furthermore, we
develop a Listwise Multi-step Prediction (LMP) objective function to optimize
learning process. Rigorous validation, including real-world industrial
platforms, confirms HeterRec's state-of-the-art performance in both effective
and efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Accuracy Assessment of OpenAlex and Clarivate Scholar ID with an
  LLM-Assisted Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11610v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11610v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renyu Zhao, Yunxin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In quantitative SciSci (science of science) studies, accurately identifying
individual scholars is paramount for scientific data analysis. However, the
variability in how names are represented-due to commonality, abbreviations, and
different spelling conventions-complicates this task. While identifier systems
like ORCID are being developed, many scholars remain unregistered, and numerous
publications are not included. Scholarly databases such as Clarivate and
OpenAlex have introduced their own ID systems as preliminary name
disambiguation solutions. This study evaluates the effectiveness of these
systems across different groups to determine their suitability for various
application scenarios. We sampled authors from the top quartile (Q1) of Web of
Science (WOS) journals based on country, discipline, and number of
corresponding author papers. For each group, we selected 100 scholars and
meticulously annotated all their papers using a Search-enhanced Large Language
Model method. Using these annotations, we identified the corresponding IDs in
OpenAlex and Clarivate, extracted all associated papers, filtered for Q1 WOS
journals, and calculated precision and recall by comparing against the
annotated dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hashtag Re-Appropriation for Audience Control on Recommendation-Driven
  Social Media Xiaohongshu (rednote) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18210v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18210v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruyuan Wan, Lingbo Tong, Tiffany Knearem, Toby Jia-Jun Li, Ting-Hao 'Kenneth' Huang, Qunfang Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Algorithms have played a central role in personalized recommendations on
social media. However, they also present significant obstacles for content
creators trying to predict and manage their audience reach. This issue is
particularly challenging for marginalized groups seeking to maintain safe
spaces. Our study explores how women on Xiaohongshu (rednote), a
recommendation-driven social platform, proactively re-appropriate hashtags
(e.g., #Baby Supplemental Food) by using them in posts unrelated to their
literal meaning. The hashtags were strategically chosen from topics that would
be uninteresting to the male audience they wanted to block. Through a
mixed-methods approach, we analyzed the practice of hashtag re-appropriation
based on 5,800 collected posts and interviewed 24 active users from diverse
backgrounds to uncover users' motivations and reactions towards the
re-appropriation. This practice highlights how users can reclaim agency over
content distribution on recommendation-driven platforms, offering insights into
self-governance within algorithmic-centered power structures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lightweight yet Efficient: An External Attentive Graph Convolutional
  Network with Positional <span class="highlight-title">Prompt</span>s for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15331v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15331v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinyu Zhang, Chao Li, Zhongying Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-based Sequential Recommender systems (GSRs) have gained significant
research attention due to their ability to simultaneously handle user-item
interactions and sequential relationships between items. Current GSRs often
utilize composite or in-depth structures for graph encoding (e.g., the Graph
Transformer). Nevertheless, they have high computational complexity, hindering
the deployment on resource-constrained edge devices. Moreover, the relative
position encoding in Graph Transformer has difficulty in considering the
complicated positional dependencies within sequence. To this end, we propose an
External Attentive Graph convolutional network with Positional prompts for
Sequential recommendation, namely EA-GPS. Specifically, we first introduce an
external attentive graph convolutional network that linearly measures the
global associations among nodes via two external memory units. Then, we present
a positional prompt-based decoder that explicitly treats the absolute item
positions as external prompts. By introducing length-adaptive sequential
masking and a soft attention network, such a decoder facilitates the model to
capture the long-term positional dependencies and contextual relationships
within sequences. Extensive experimental results on five real-world datasets
demonstrate that the proposed EA-GPS outperforms the state-of-the-art methods.
Remarkably, it achieves the superior performance while maintaining a smaller
parameter size and lower training overhead. The implementation of this work is
publicly available at https://github.com/ZZY-GraphMiningLab/EA-GPS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 8 figures, journal paper, accepted by TOIS at 20th
  February, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11841v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11841v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Tang, Yongliang Shen, Hang Zhang, Zeqi Tan, Wenqi Zhang, Zhibiao Huang, Kaitao Song, Weiming Lu, Yueting Zhuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model-based explainable recommendation (LLM-based ER) systems
show promise in generating human-like explanations for recommendations.
However, they face challenges in modeling user-item collaborative preferences,
personalizing explanations, and handling sparse user-item interactions. To
address these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated
Mixture of Experts framework for explainable recommendation. GaVaMoE introduces
two key components: (1) a rating reconstruction module that employs Variational
Autoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex
user-item collaborative preferences, serving as a pre-trained multi-gating
mechanism; and (2) a set of fine-grained expert models coupled with the
multi-gating mechanism for generating highly personalized explanations. The VAE
component models latent factors in user-item interactions, while the GMM
clusters users with similar behaviors. Each cluster corresponds to a gate in
the multi-gating mechanism, routing user-item pairs to appropriate expert
models. This architecture enables GaVaMoE to generate tailored explanations for
specific user types and preferences, mitigating data sparsity by leveraging
user similarities. Extensive experiments on three real-world datasets
demonstrate that GaVaMoE significantly outperforms existing methods in
explanation quality, personalization, and consistency. Notably, GaVaMoE
exhibits robust performance in scenarios with sparse user-item interactions,
maintaining high-quality explanations even for users with limited historical
data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and
  Reranking <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.01007v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.01007v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tarun Suresh, Revanth Gangi Reddy, Yifei Xu, Zach Nussbaum, Andriy Mulyar, Brandon Duderstadt, Heng Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective code retrieval plays a crucial role in advancing code generation,
bug fixing, and software maintenance, particularly as software systems increase
in complexity. While current code embedding models have demonstrated promise in
retrieving code snippets for small-scale, well-defined tasks, they often
underperform in more demanding real-world applications such as bug localization
within GitHub repositories. We hypothesize that a key issue is their reliance
on noisy and inconsistent datasets for training, which impedes their ability to
generalize to more complex retrieval scenarios. To address these limitations,
we introduce CoRNStack, a large-scale, high-quality contrastive training
dataset for code that spans multiple programming languages. This dataset is
curated using consistency filtering to eliminate noisy positives and is further
enriched with mined hard negatives, thereby facilitating more effective
learning. We demonstrate that contrastive training of embedding models using
CoRNStack leads to state-of-the-art performance across a variety of code
retrieval tasks. Furthermore, the dataset can be leveraged for training code
reranking models, a largely underexplored area compared to text reranking. Our
finetuned code reranking model significantly improves the ranking quality over
the retrieved results. Finally, by employing our code retriever and reranker
together, we demonstrate significant improvements in function localization for
GitHub issues, an important component of real-world software development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at ICLR 2025. First and second author
  had equal contribution</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multimodal Symphony: Integrating Taste and Sound through Generative AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02823v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02823v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Spanio, Massimiliano Zampini, Antonio Rodà, Franco Pierucci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent decades, neuroscientific and psychological research has traced
direct relationships between taste and auditory perceptions. This article
explores multimodal generative models capable of converting taste information
into music, building on this foundational research. We provide a brief review
of the state of the art in this field, highlighting key findings and
methodologies. We present an experiment in which a fine-tuned version of a
generative music model (MusicGEN) is used to generate music based on detailed
taste descriptions provided for each musical piece. The results are promising:
according the participants' ($n=111$) evaluation, the fine-tuned model produces
music that more coherently reflects the input taste descriptions compared to
the non-fine-tuned model. This study represents a significant step towards
understanding and developing embodied interactions between AI, sound, and
taste, opening new possibilities in the field of generative AI. We release our
dataset, code and pre-trained model at: https://osf.io/xs5jy/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 6 figures (2 + 2 figures with 2 subfigures each)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 2DGS-Avatar: Animatable High-fidelity Clothed Avatar via 2D Gaussian
  Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qipeng Yan, Mingyang Sun, Lihua Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-time rendering of high-fidelity and animatable avatars from monocular
videos remains a challenging problem in computer vision and graphics. Over the
past few years, the Neural Radiance Field (NeRF) has made significant progress
in rendering quality but behaves poorly in run-time performance due to the low
efficiency of volumetric rendering. Recently, methods based on 3D Gaussian
Splatting (3DGS) have shown great potential in fast training and real-time
rendering. However, they still suffer from artifacts caused by inaccurate
geometry. To address these problems, we propose 2DGS-Avatar, a novel approach
based on 2D Gaussian Splatting (2DGS) for modeling animatable clothed avatars
with high-fidelity and fast training performance. Given monocular RGB videos as
input, our method generates an avatar that can be driven by poses and rendered
in real-time. Compared to 3DGS-based methods, our 2DGS-Avatar retains the
advantages of fast training and rendering while also capturing detailed,
dynamic, and photo-realistic appearances. We conduct abundant experiments on
popular datasets such as AvatarRex and THuman4.0, demonstrating impressive
performance in both qualitative and quantitative metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICVRV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio-Reasoner: Improving Reasoning Capability in Large Audio Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02318v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02318v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhifei Xie, Mingbao Lin, Zihang Liu, Pengcheng Wu, Shuicheng Yan, Chunyan Miao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in multimodal reasoning have largely overlooked the audio
modality. We introduce Audio-Reasoner, a large-scale audio language model for
deep reasoning in audio tasks. We meticulously curated a large-scale and
diverse multi-task audio dataset with simple annotations. Then, we leverage
closed-source models to conduct secondary labeling, QA generation, along with
structured COT process. These datasets together form a high-quality reasoning
dataset with 1.2 million reasoning-rich samples, which we name CoTA. Following
inference scaling principles, we train Audio-Reasoner on CoTA, enabling it to
achieve great logical capabilities in audio reasoning. Experiments show
state-of-the-art performance across key benchmarks, including MMAU-mini
(+25.42%), AIR-Bench chat/foundation(+14.57%/+10.13%), and MELD (+8.01%). Our
findings stress the core of structured CoT training in advancing audio
reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report, in process</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Words or Vision: Do Vision-Language Models Have Blind Faith in Text? <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02199v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02199v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ailin Deng, Tri Cao, Zhirui Chen, Bryan Hooi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-Language Models (VLMs) excel in integrating visual and textual
information for vision-centric tasks, but their handling of inconsistencies
between modalities is underexplored. We investigate VLMs' modality preferences
when faced with visual data and varied textual inputs in vision-centered
settings. By introducing textual variations to four vision-centric tasks and
evaluating ten Vision-Language Models (VLMs), we discover a \emph{``blind faith
in text''} phenomenon: VLMs disproportionately trust textual data over visual
data when inconsistencies arise, leading to significant performance drops under
corrupted text and raising safety concerns. We analyze factors influencing this
text bias, including instruction prompts, language model size, text relevance,
token order, and the interplay between visual and textual certainty. While
certain factors, such as scaling up the language model size, slightly mitigate
text bias, others like token order can exacerbate it due to positional biases
inherited from language models. To address this issue, we explore supervised
fine-tuning with text augmentation and demonstrate its effectiveness in
reducing text bias. Additionally, we provide a theoretical analysis suggesting
that the blind faith in text phenomenon may stem from an imbalance of pure text
and multi-modal data during training. Our findings highlight the need for
balanced training and careful consideration of modality interactions in VLMs to
enhance their robustness and reliability in handling multi-modal data
inconsistencies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive <span class="highlight-title">Survey</span> on Composed Image Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18495v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18495v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuemeng Song, Haoqiang Lin, Haokun Wen, Bohan Hou, Mingzhu Xu, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Composed Image Retrieval (CIR) is an emerging yet challenging task that
allows users to search for target images using a multimodal query, comprising a
reference image and a modification text specifying the user's desired changes
to the reference image. Given its significant academic and practical value, CIR
has become a rapidly growing area of interest in the computer vision and
machine learning communities, particularly with the advances in deep learning.
To the best of our knowledge, there is currently no comprehensive review of CIR
to provide a timely overview of this field. Therefore, we synthesize insights
from over 120 publications in top conferences and journals, including ACM TOIS,
SIGIR, and CVPR In particular, we systematically categorize existing supervised
CIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive
review, we also briefly discuss approaches for tasks closely related to CIR,
such as attribute-based CIR and dialog-based CIR. Additionally, we summarize
benchmark datasets for evaluation and analyze existing supervised and zero-shot
CIR methods by comparing experimental results across multiple datasets.
Furthermore, we present promising future directions in this field, offering
practical insights for researchers interested in further exploration. The
curated collection of related works is maintained and continuously updated in
https://github.com/haokunwen/Awesome-Composed-Image-Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AdaMesh: Personalized Facial Expressions and Head Poses for Adaptive
  Speech-Driven 3D Facial Animation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07236v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07236v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liyang Chen, Weihong Bao, Shun Lei, Boshi Tang, Zhiyong Wu, Shiyin Kang, Haozhi Huang, Helen Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech-driven 3D facial animation aims at generating facial movements that
are synchronized with the driving speech, which has been widely explored
recently. Existing works mostly neglect the person-specific talking style in
generation, including facial expression and head pose styles. Several works
intend to capture the personalities by fine-tuning modules. However, limited
training data leads to the lack of vividness. In this work, we propose AdaMesh,
a novel adaptive speech-driven facial animation approach, which learns the
personalized talking style from a reference video of about 10 seconds and
generates vivid facial expressions and head poses. Specifically, we propose
mixture-of-low-rank adaptation (MoLoRA) to fine-tune the expression adapter,
which efficiently captures the facial expression style. For the personalized
pose style, we propose a pose adapter by building a discrete pose prior and
retrieving the appropriate style embedding with a semantic-aware pose style
matrix without fine-tuning. Extensive experimental results show that our
approach outperforms state-of-the-art methods, preserves the talking style in
the reference video, and generates vivid facial animation. The supplementary
video and code will be available at https://adamesh.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Multimedia</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modular Conversational Agents for <span class="highlight-title">Survey</span>s and Interviews 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.17049v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.17049v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiangbo Yu, Jinhua Zhao, Luis Miranda-Moreno, Matthew Korp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surveys and interviews are widely used for collecting insights on emerging or
hypothetical scenarios. Traditional human-led methods often face challenges
related to cost, scalability, and consistency. Recently, various domains have
begun to explore the use of conversational agents (chatbots) powered by
generative artificial intelligence (AI) technologies. However, considering
decisions in transportation investments and policies often carry significant
public and environmental stakes, surveys and interviews face unique challenges
in integrating AI agents, underscoring the need for a rigorous,
resource-efficient approach that enhances participant engagement and ensures
privacy. This paper addresses this gap by introducing a modular approach and
its resulting parameterized process for designing AI agents. We detail the
system architecture, integrating engineered prompts, specialized knowledge
bases, and customizable, goal-oriented conversational logic. We demonstrate the
adaptability, generalizability, and efficacy of our modular approach through
three empirical studies: (1) travel preference surveys, highlighting
conditional logic and multimodal (voice, text, and image generation)
capabilities; (2) public opinion elicitation on a newly constructed, novel
infrastructure project, showcasing question customization and multilingual
(English and French) capabilities; and (3) expert consultation about the impact
of technologies on future transportation systems, highlighting real-time,
clarification request capabilities for open-ended questions, resilience in
handling erratic inputs, and efficient transcript postprocessing. The results
suggest that the AI agent increases completion rates and response quality.
Furthermore, the modular approach demonstrates controllability, flexibility,
and robustness while addressing key ethical, privacy, security, and token
consumption concerns.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-03T00:00:00Z">2025-03-03</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Survey</span> Perspective: The Role of Explainable AI in Threat Intelligence <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nidhi Rastogi, Devang Dhanuka, Amulya Saxena, Pranjal Mairal, Le Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing reliance on AI-based security tools in Security Operations
Centers (SOCs) has transformed threat detection and response, yet analysts
frequently struggle with alert overload, false positives, and lack of
contextual relevance. The inability to effectively analyze AI-generated
security alerts lead to inefficiencies in incident response and reduces trust
in automated decision-making. In this paper, we show results and analysis of
our investigation of how SOC analysts navigate AI-based alerts, their
challenges with current security tools, and how explainability (XAI) integrated
into their security workflows has the potential to become an effective decision
support. In this vein, we conducted an industry survey. Using the survey
responses, we analyze how security analysts' process, retrieve, and prioritize
alerts. Our findings indicate that most analysts have not yet adopted
XAI-integrated tools, but they express high interest in attack attribution,
confidence scores, and feature contribution explanations to improve
interpretability, and triage efficiency. Based on our findings, we also propose
practical design recommendations for XAI-enhanced security alert systems,
enabling AI-based cybersecurity solutions to be more transparent,
interpretable, and actionable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, SIGIR Symposium on IR in Practice (SIRIP), 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMInit: A Free Lunch from Large Language Models for Selective
  Initialization of Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01814v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01814v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weizhi Zhang, Liangwei Yang, Wooseong Yang, Henry Peng Zou, Yuqing Liu, Ke Xu, Sourav Medya, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collaborative filtering models, particularly graph-based approaches, have
demonstrated strong performance in capturing user-item interactions for
recommendation systems. However, they continue to struggle in cold-start and
data-sparse scenarios. The emergence of large language models (LLMs) like GPT
and LLaMA presents new possibilities for enhancing recommendation performance,
especially in cold-start settings. Despite their promise, LLMs pose challenges
related to scalability and efficiency due to their high computational demands
and limited ability to model complex user-item relationships effectively. In
this work, we introduce a novel perspective on leveraging LLMs for CF model
initialization. Through experiments, we uncover an embedding collapse issue
when scaling CF models to larger embedding dimensions. To effectively harness
large-scale LLM embeddings, we propose innovative selective initialization
strategies utilizing random, uniform, and variance-based index sampling. Our
comprehensive evaluation on multiple real-world datasets demonstrates
significant performance gains across various CF models while maintaining a
lower computational cost compared to existing LLM-based recommendation
approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01763v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01763v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengliang Shi, Yuhan Wang, Lingyong Yan, Pengjie Ren, Shuaiqiang Wang, Dawei Yin, Zhaochun Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tool learning aims to augment large language models (LLMs) with diverse
tools, enabling them to act as agents for solving practical tasks. Due to the
limited context length of tool-using LLMs, adopting information retrieval (IR)
models to select useful tools from large toolsets is a critical initial step.
However, the performance of IR models in tool retrieval tasks remains
underexplored and unclear. Most tool-use benchmarks simplify this step by
manually pre-annotating a small set of relevant tools for each task, which is
far from the real-world scenarios. In this paper, we propose ToolRet, a
heterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks,
and a corpus of 43k tools, collected from existing datasets. We benchmark six
types of models on ToolRet. Surprisingly, even the models with strong
performance in conventional IR benchmarks, exhibit poor performance on ToolRet.
This low retrieval quality degrades the task pass rate of tool-use LLMs. As a
further step, we contribute a large-scale training dataset with over 200k
instances, which substantially optimizes the tool retrieval ability of IR
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAGE: A Framework of Precise Retrieval for RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintao Zhang, Guoliang Li, Jinyang Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has demonstrated significant proficiency
in conducting question-answering (QA) tasks within a specified corpus.
Nonetheless, numerous failure instances of RAG in QA still exist. These
failures are not solely attributable to the limitations of Large Language
Models (LLMs); instead, they predominantly arise from the retrieval of
inaccurate information for LLMs due to two limitations: (1) Current RAG methods
segment the corpus without considering semantics, making it difficult to find
relevant context due to impaired correlation between questions and the
segments. (2) There is a trade-off between missing essential context with fewer
context retrieved and getting irrelevant context with more context retrieved.
  In this paper, we introduce a RAG framework (SAGE), to overcome these
limitations. First, to address the segmentation issue without considering
semantics, we propose to train a semantic segmentation model. This model is
trained to segment the corpus into semantically complete chunks. Second, to
ensure that only the most relevant chunks are retrieved while the irrelevant
ones are ignored, we design a chunk selection algorithm to dynamically select
chunks based on the decreasing speed of the relevance score, leading to a more
relevant selection. Third, to further ensure the precision of the retrieved
chunks, we propose letting LLMs assess whether retrieved chunks are excessive
or lacking and then adjust the amount of context accordingly. Experiments show
that SAGE outperforms baselines by 61.25% in the quality of QA on average.
Moreover, by avoiding retrieving noisy context, SAGE lowers the cost of the
tokens consumed in LLM inference and achieves a 49.41% enhancement in cost
efficiency on average. Additionally, our work offers valuable insights for
boosting RAG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the
  Lens of Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01670v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01670v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siya Qi, Rui Cao, Yulan He, Zheng Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of large language models (LLMs), LLM-as-a-judge
has emerged as a widely adopted approach for text quality evaluation, including
hallucination evaluation. While previous studies have focused exclusively on
single-context evaluation (e.g., discourse faithfulness or world factuality),
real-world hallucinations typically involve mixed contexts, which remains
inadequately evaluated. In this study, we use summarization as a representative
task to comprehensively evaluate LLMs' capability in detecting mixed-context
hallucinations, specifically distinguishing between factual and non-factual
hallucinations. Through extensive experiments across direct generation and
retrieval-based models of varying scales, our main observations are: (1) LLMs'
intrinsic knowledge introduces inherent biases in hallucination evaluation; (2)
These biases particularly impact the detection of factual hallucinations,
yielding a significant performance bottleneck; (3) The fundamental challenge
lies in effective knowledge utilization, balancing between LLMs' intrinsic
knowledge and external context for accurate mixed-context hallucination
evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 figures for main body</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoPL: Collaborative Preference Learning for Personalizing LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01658v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01658v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngbin Choi, Seunghyuk Cho, Minjong Lee, MoonJeong Park, Yesong Ko, Jungseul Ok, Dongwoo Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalizing large language models (LLMs) is important for aligning outputs
with diverse user preferences, yet existing methods struggle with flexibility
and generalization. We propose CoPL (Collaborative Preference Learning), a
graph-based collaborative filtering framework that models user-response
relationships to enhance preference estimation, particularly in sparse
annotation settings. By integrating a mixture of LoRA experts, CoPL efficiently
fine-tunes LLMs while dynamically balancing shared and user-specific
preferences. Additionally, an optimization-free adaptation strategy enables
generalization to unseen users without fine-tuning. Experiments on
UltraFeedback-P demonstrate that CoPL outperforms existing personalized reward
models, effectively capturing both common and controversial preferences, making
it a scalable solution for personalized LLM alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13pages, 4 figures, 6tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging LLMs for Mental Health: Detection and Recommendations from
  Social Discussions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01442v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01442v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vaishali Aggarwal, Sachin Thukral, Krushil Patel, Arnab Chatterjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Textual data from social platforms captures various aspects of mental health
through discussions around and across issues, while users reach out for help
and others sympathize and offer support. We propose a comprehensive framework
that leverages Natural Language Processing (NLP) and Generative AI techniques
to identify and assess mental health disorders, detect their severity, and
create recommendations for behavior change and therapeutic interventions based
on users' posts on Reddit.
  To classify the disorders, we use rule-based labeling methods as well as
advanced pre-trained NLP models to extract nuanced semantic features from the
data. We fine-tune domain-adapted and generic pre-trained NLP models based on
predictions from specialized Large Language Models (LLMs) to improve
classification accuracy. Our hybrid approach combines the generalization
capabilities of pre-trained models with the domain-specific insights captured
by LLMs, providing an improved understanding of mental health discourse. Our
findings highlight the strengths and limitations of each model, offering
valuable insights into their practical applicability.
  This research potentially facilitates early detection and personalized care
to aid practitioners and aims to facilitate timely interventions and improve
overall well-being, thereby contributing to the broader field of mental health
surveillance and digital health analytics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures, 3 tables, to be published in WI-IAT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Streaming Piano Transcription Based on Consistent Onset and Offset
  Decoding with Sustain Pedal Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weixing Wei, Jiahao Zhao, Yulun Wu, Kazuyoshi Yoshii
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes a streaming audio-to-MIDI piano transcription approach
that aims to sequentially translate a music signal into a sequence of note
onset and offset events. The sequence-to-sequence nature of this task may call
for the computationally-intensive transformer model for better performance,
which has recently been used for offline transcription benchmarks and could be
extended for streaming transcription with causal attention mechanisms. We
assume that the performance limitation of this naive approach lies in the
decoder. Although time-frequency features useful for onset detection are
considerably different from those for offset detection, the single decoder is
trained to output a mixed sequence of onset and offset events without guarantee
of the correspondence between the onset and offset events of the same note. To
overcome this limitation, we propose a streaming encoder-decoder model that
uses a convolutional encoder aggregating local acoustic features, followed by
an autoregressive Transformer decoder detecting a variable number of onset
events and another decoder detecting the offset events for the active pitches
with validation of the sustain pedal at each time frame. Experiments using the
MAESTRO dataset showed that the proposed streaming method performed comparably
with or even better than the state-of-the-art offline methods while
significantly reducing the computational cost.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ISMIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composed Multi-modal Retrieval: A <span class="highlight-title">Survey</span> of Approaches and Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kun Zhang, Jingyu Li, Zhe Li, Jingjing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid growth of multi-modal data from social media, short video
platforms, and e-commerce, content-based retrieval has become essential for
efficiently searching and utilizing heterogeneous information. Over time,
retrieval techniques have evolved from Unimodal Retrieval (UR) to Cross-modal
Retrieval (CR) and, more recently, to Composed Multi-modal Retrieval (CMR). CMR
enables users to retrieve images or videos by integrating a reference visual
input with textual modifications, enhancing search flexibility and precision.
This paper provides a comprehensive review of CMR, covering its fundamental
challenges, technical advancements, and categorization into supervised,
zero-shot, and semi-supervised learning paradigms. We discuss key research
directions, including data augmentation, model architecture, and loss
optimization in supervised CMR, as well as transformation frameworks and
external knowledge integration in zero-shot CMR. Additionally, we highlight the
application potential of CMR in composed image retrieval, video retrieval, and
person retrieval, which have significant implications for e-commerce, online
search, and public security. Given its ability to refine and personalize search
experiences, CMR is poised to become a pivotal technology in next-generation
retrieval systems. A curated list of related works and resources is available
at: https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HI-Series Algorithms A Hybrid of Substance Diffusion Algorithm and
  Collaborative Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01305v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01305v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Peng, Ya-Hui An
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation systems face the challenge of balancing accuracy and
diversity, as traditional collaborative filtering (CF) and network-based
diffusion algorithms exhibit complementary limitations. While item-based CF
(ItemCF) enhances diversity through item similarity, it compromises accuracy.
Conversely, mass diffusion (MD) algorithms prioritize accuracy by favoring
popular items but lack diversity. To address this trade-off, we propose the
HI-series algorithms, hybrid models integrating ItemCF with diffusion-based
approaches (MD, HHP, BHC, BD) through a nonlinear combination controlled by
parameter $\epsilon$. This hybridization leverages ItemCF's diversity and MD's
accuracy, extending to advanced diffusion models (HI-HHP, HI-BHC, HI-BD) for
enhanced performance. Experiments on MovieLens, Netflix, and RYM datasets
demonstrate that HI-series algorithms significantly outperform their base
counterparts. In sparse data ($20\%$ training), HI-MD achieves a
$0.8\%$-$4.4\%$ improvement in F1-score over MD while maintaining higher
diversity (Diversity@20: 459 vs. 396 on MovieLens). For dense data ($80\%$
training), HI-BD improves F1-score by $2.3\%$-$5.2\%$ compared to BD, with
diversity gains up to $18.6\%$. Notably, hybrid models consistently enhance
novelty in sparse settings and exhibit robust parameter adaptability. The
results validate that strategic hybridization effectively breaks the
accuracy-diversity trade-off, offering a flexible framework for optimizing
recommendation systems across data sparsity levels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cancer Type, Stage and Prognosis Assessment from Pathology Reports using
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01194v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01194v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rachit Saluja, Jacob Rosenthal, Yoav Artzi, David J. Pisapia, Benjamin L. Liechty, Mert R. Sabuncu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown significant promise across various
natural language processing tasks. However, their application in the field of
pathology, particularly for extracting meaningful insights from unstructured
medical texts such as pathology reports, remains underexplored and not well
quantified. In this project, we leverage state-of-the-art language models,
including the GPT family, Mistral models, and the open-source Llama models, to
evaluate their performance in comprehensively analyzing pathology reports.
Specifically, we assess their performance in cancer type identification, AJCC
stage determination, and prognosis assessment, encompassing both information
extraction and higher-order reasoning tasks. Based on a detailed analysis of
their performance metrics in a zero-shot setting, we developed two
instruction-tuned models: Path-llama3.1-8B and Path-GPT-4o-mini-FT. These
models demonstrated superior performance in zero-shot cancer type
identification, staging, and prognosis assessment compared to the other models
evaluated.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReaderLM-v2: Small Language Model for HTML to Markdown and JSON 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feng Wang, Zesheng Shi, Bo Wang, Nan Wang, Han Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present ReaderLM-v2, a compact 1.5 billion parameter language model
designed for efficient web content extraction. Our model processes documents up
to 512K tokens, transforming messy HTML into clean Markdown or JSON formats
with high accuracy -- making it an ideal tool for grounding large language
models. The model's effectiveness results from two key innovations: (1) a
three-stage data synthesis pipeline that generates high quality, diverse
training data by iteratively drafting, refining, and critiquing web content
extraction; and (2) a unified training framework combining continuous
pre-training with multi-objective optimization. Intensive evaluation
demonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger
models by 15-20\% on carefully curated benchmarks, particularly excelling at
documents exceeding 100K tokens, while maintaining significantly lower
computational requirements.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 10-12 refs</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RAGEval: Scenario Specific RAG Evaluation <span class="highlight-title">Dataset</span> Generation Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01262v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01262v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kunlun Zhu, Yifan Luo, Dingling Xu, Yukun Yan, Zhenghao Liu, Shi Yu, Ruobing Wang, Shuo Wang, Yishan Li, Nan Zhang, Xu Han, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) is a powerful approach that enables
large language models (LLMs) to incorporate external knowledge. However,
evaluating the effectiveness of RAG systems in specialized scenarios remains
challenging due to the high costs of data construction and the lack of suitable
evaluation metrics. This paper introduces RAGEval, a framework designed to
assess RAG systems across diverse scenarios by generating high-quality
documents, questions, answers, and references through a schema-based pipeline.
With a focus on factual accuracy, we propose three novel metrics: Completeness,
Hallucination, and Irrelevance to evaluate LLM generated responses rigorously.
Experimental results show that RAGEval outperforms zero-shot and one-shot
methods in terms of clarity, safety, conformity, and richness of generated
samples. Furthermore, the use of LLMs for scoring the proposed metrics
demonstrates a high level of consistency with human evaluations. RAGEval
establishes a new paradigm for evaluating RAG systems in real-world
applications. The code and dataset are released at
https://github.com/OpenBMB/RAGEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/OpenBMB/RAGEval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ External Large Foundation Model: How to Efficiently Serve Trillions of
  Parameters for Online Ads Recommendation <span class="chip">WWW</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17494v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17494v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingfu Liang, Xi Liu, Rong Jin, Boyang Liu, Qiuling Suo, Qinghai Zhou, Song Zhou, Laming Chen, Hua Zheng, Zhiyuan Li, Shali Jiang, Jiyan Yang, Xiaozhen Xia, Fan Yang, Yasmine Badr, Ellie Wen, Shuyu Xu, Hansey Chen, Zhengyu Zhang, Jade Nie, Chunzhi Yang, Zhichen Zeng, Weilin Zhang, Xingliang Huang, Qianru Li, Shiquan Wang, Evelyn Lyu, Wenjing Lu, Rui Zhang, Wenjun Wang, Jason Rudy, Mengyue Hang, Kai Wang, Yinbin Ma, Shuaiwen Wang, Sihan Zeng, Tongyi Tang, Xiaohan Wei, Longhao Jin, Jamey Zhang, Marcus Chen, Jiayi Zhang, Angie Huang, Chi Zhang, Zhengli Zhao, Jared Yang, Qiang Jin, Xian Chen, Amit Anand Amlesahwaram, Lexi Song, Liang Luo, Yuchen Hao, Nan Xiao, Yavuz Yetim, Luoshang Pan, Gaoxiang Liu, Yuxi Hu, Yuzhen Huang, Jackie Xu, Rich Zhu, Xin Zhang, Yiqun Liu, Hang Yin, Yuxin Chen, Buyun Zhang, Xiaoyi Liu, Xingyuan Wang, Wenguang Mao, Zhijing Li, Qin Huang, Chonglin Sun, Nancy Yu, Shuo Gu, Shupin Mao, Benjamin Au, Jingzheng Qin, Peggy Yao, Jae-Woo Choi, Bin Gao, Ernest Wang, Lei Zhang, Wen-Yen Chen, Ted Lee, Jay Zha, Yi Meng, Alex Gong, Edison Gao, Alireza Vahdatpour, Yiping Han, Yantao Yao, Toshinari Kureha, Shuo Chang, Musharaf Sultan, John Bocharov, Sagar Chordia, Xiaorui Gan, Peng Sun, Rocky Liu, Bo Long, Wenlin Chen, Santanu Kolay, Huayu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ads recommendation is a prominent service of online advertising systems and
has been actively studied. Recent studies indicate that scaling-up and advanced
design of the recommendation model can bring significant performance
improvement. However, with a larger model scale, such prior studies have a
significantly increasing gap from industry as they often neglect two
fundamental challenges in industrial-scale applications. First, training and
inference budgets are restricted for the model to be served, exceeding which
may incur latency and impair user experience. Second, large-volume data arrive
in a streaming mode with data distributions dynamically shifting, as new
users/ads join and existing users/ads leave the system. We propose the External
Large Foundation Model (ExFM) framework to address the overlooked challenges.
Specifically, we develop external distillation and a data augmentation system
(DAS) to control the computational cost of training/inference while maintaining
high performance. We design the teacher in a way like a foundation model (FM)
that can serve multiple students as vertical models (VMs) to amortize its
building cost. We propose Auxiliary Head and Student Adapter to mitigate the
data distribution gap between FM and VMs caused by the streaming data issue.
Comprehensive experiments on internal industrial-scale applications and public
datasets demonstrate significant performance gain by ExFM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the ACM Web Conference (WWW) 2025 Industrial Track as
  Oral Presentation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TEARS: Textual Representations for Scrutable Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19302v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19302v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emiliano Penaloza, Olivier Gouvert, Haolun Wu, Laurent Charlin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional recommender systems rely on high-dimensional (latent) embeddings
for modeling user-item interactions, often resulting in opaque representations
that lack interpretability. Moreover, these systems offer limited control to
users over their recommendations. Inspired by recent work, we introduce TExtuAl
Representations for Scrutable recommendations (TEARS) to address these
challenges. Instead of representing a user's interests through a latent
embedding, TEARS encodes them in natural text, providing transparency and
allowing users to edit them. To do so, TEARS uses a modern LLM to generate user
summaries based on user preferences. We find the summaries capture user
preferences uniquely. Using these summaries, we take a hybrid approach where we
use an optimal transport procedure to align the summaries' representation with
the learned representation of a standard VAE for collaborative filtering. We
find this approach can surpass the performance of three popular VAE models
while providing user-controllable recommendations. We also analyze the
controllability of TEARS through three simulated user tasks to evaluate the
effectiveness of a user editing its summary.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Intelligence via Trial and Error 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18858v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18858v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingtao Zhan, Jiahao Zhao, Jiayu Li, Yiqun Liu, Bo Zhang, Qingyao Ai, Jiaxin Mao, Hongning Wang, Min Zhang, Shaoping Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intelligence is a crucial trait for species to find solutions within a
limited number of trial-and-error attempts. Building on this idea, we introduce
Survival Game as a framework to evaluate intelligence based on the number of
failed attempts in a trial-and-error process. Fewer failures indicate higher
intelligence. When the expectation and variance of failure counts are both
finite, it signals the ability to consistently find solutions to new
challenges, which we define as the Autonomous Level of intelligence. Using
Survival Game, we comprehensively evaluate existing AI systems. Our results
show that while AI systems achieve the Autonomous Level in simple tasks, they
are still far from it in more complex tasks, such as vision, search,
recommendation, and language. While scaling current AI technologies might help,
this would come at an astronomical cost. Projections suggest that achieving the
Autonomous Level for general tasks would require $10^{26}$ parameters. To put
this into perspective, loading such a massive model requires so many H100 GPUs
that their total value is $10^{7}$ times that of Apple Inc.'s market value.
Even with Moore's Law, supporting such a parameter scale would take $70$ years.
This staggering cost highlights the complexity of human tasks and the
inadequacies of current AI technologies. To further investigate this
phenomenon, we conduct a theoretical analysis of Survival Game and its
experimental results. Our findings suggest that human tasks possess a
criticality property. As a result, Autonomous Level requires a deep
understanding of the task's underlying mechanisms. Current AI systems, however,
do not fully grasp these mechanisms and instead rely on superficial mimicry,
making it difficult for them to reach an autonomous level. We believe Survival
Game can not only guide the future development of AI but also offer profound
insights into human intelligence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimize Incompatible Parameters through Compatibility-aware Knowledge
  Integration <span class="chip">AAAI'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.07596v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.07596v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheqi Lv, Keming Ye, Zishu Wei, Qi Tian, Shengyu Zhang, Wenqiao Zhang, Wenjie Wang, Kun Kuang, Tat-Seng Chua, Fei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks have become foundational to advancements in multiple
domains, including recommendation systems, natural language processing, and so
on. Despite their successes, these models often contain incompatible parameters
that can be underutilized or detrimental to model performance, particularly
when faced with specific, varying data distributions. Existing research excels
in removing such parameters or merging the outputs of multiple different
pretrained models. However, the former focuses on efficiency rather than
performance, while the latter requires several times more computing and storage
resources to support inference. In this paper, we set the goal to explicitly
improve these incompatible parameters by leveraging the complementary strengths
of different models, thereby directly enhancing the models without any
additional parameters. Specifically, we propose Compatibility-aware Knowledge
Integration (CKI), which consists of Parameter Compatibility Assessment and
Parameter Splicing, which are used to evaluate the knowledge content of
multiple models and integrate the knowledge into one model, respectively. The
integrated model can be used directly for inference or for further fine-tuning.
We conduct extensive experiments on various datasets for recommendation and
language tasks, and the results show that Compatibility-aware Knowledge
Integration can effectively optimize incompatible parameters under multiple
tasks and settings to break through the training limit of the original model
without increasing the inference cost.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial
  Intelligence</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recurrence-Enhanced Vision-and-Language <span class="highlight-title">Transformer</span>s for Robust
  Multimodal Document Retrieval <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01980v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01980v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Caffagni, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-modal retrieval is gaining increasing efficacy and interest from the
research community, thanks to large-scale training, novel architectural and
learning designs, and its application in LLMs and multimodal LLMs. In this
paper, we move a step forward and design an approach that allows for multimodal
queries, composed of both an image and a text, and can search within
collections of multimodal documents, where images and text are interleaved. Our
model, ReT, employs multi-level representations extracted from different layers
of both visual and textual backbones, both at the query and document side. To
allow for multi-level and cross-modal understanding and feature extraction, ReT
employs a novel Transformer-based recurrent cell that integrates both textual
and visual features at different layers, and leverages sigmoidal gates inspired
by the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR
benchmarks show that ReT achieves state-of-the-art performance across diverse
settings. Our source code and trained models are publicly available at
https://github.com/aimagelab/ReT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving the Efficiency of VVC using Partitioning of Reference Frames 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01415v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01415v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kamran Qureshi, Hadi Amirpour, Christian Timmerer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In response to the growing demand for high-quality videos, Versatile Video
Coding (VVC) was released in 2020, building on the hybrid coding architecture
of its predecessor, HEVC, achieving about 50% bitrate reduction for the same
visual quality. It introduces more flexible block partitioning, enhancing
compression efficiency at the cost of increased encoding complexity. To make
efficient use of VVC in practical applications, optimization is essential.
VVenC, an optimized open-source VVC encoder, introduces multiple presets to
address the trade-off between compression efficiency and encoder complexity.
Although an optimized set of encoding tools has been selected for each preset,
the rate-distortion (RD) search space in the encoder presets still poses a
challenge for efficient encoder implementations. In this paper, we propose
Early Termination using Reference Frames (ETRF), which improves the trade-off
between encoding efficiency and time complexity and positions itself as a new
preset between medium and fast presets. The CTU partitioning map of the
reference frames in lower temporal layers is employed to accelerate the
encoding of frames in higher temporal layers. The results show a reduction in
the encoding time of around 21% compared to the medium preset. Specifically,
for videos with high spatial and temporal complexities, which typically require
longer encoding times, the proposed method achieves a better trade-off between
bitrate savings and encoding time compared to the fast preset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-resolution Encoding for HTTP Adaptive Streaming using VVenC 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01404v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01404v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kamran Qureshi, Hadi Amirpour, Christian Timmerer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  HTTP Adaptive Streaming (HAS) is a widely adopted method for delivering video
content over the Internet, requiring each video to be encoded at multiple
bitrates and resolution pairs, known as representations, to adapt to various
network conditions and device capabilities. This multi-bitrate encoding
introduces significant challenges due to the computational and time-intensive
nature of encoding multiple representations. Conventional approaches often
encode these videos independently without leveraging similarities between
different representations of the same input video. This paper proposes an
accelerated multi-resolution encoding strategy that utilizes representations of
lower resolutions as references to speed up the encoding of higher resolutions
when using Versatile Video Coding (VVC); specifically in VVenC, an optimized
open-source software implementation. For multi-resolution encoding, a
mid-bitrate representation serves as the reference, allowing interpolated
encoded partition data to efficiently guide the partitioning process in higher
resolutions. The proposed approach uses shared encoding information to reduce
redundant calculations, optimizing partitioning decisions. Experimental results
demonstrate that the proposed technique achieves a reduction of up to 17%
compared to medium preset in encoding time across videos of varying
complexities with minimal BDBR/BDT of 0.12 compared to the fast preset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CorrNetDroid: Android Malware Detector leveraging a Correlation-based
  Feature Selection for Network Traffic features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01396v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01396v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yash Sharma, Anshul Arora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Copious mobile operating systems exist in the market, but Android remains the
user's choice. Meanwhile, its growing popularity has also attracted malware
developers. Researchers have proposed various static solutions for Android
malware detection. However, stealthier malware evade static analysis. This
raises the need for a robust Android malware detection system capable of
dealing with advanced threats and overcoming the shortcomings of static
analysis.
  Hence, this work proposes a dynamic analysis-based Android malware detection
system, CorrNetDroid, that works over network traffic flows. Many traffic
features exhibit overlapping ranges in normal and malware datasets. Therefore,
we first rank the features using two statistical measures, crRelevance and
Normalized Mean Residue Similarity (NMRS), to assess feature-class and
feature-feature correlations. Thereafter, we introduce a novel
correlation-based feature selection algorithm that applies NMRS on crRelevance
rankings to identify the optimal feature subset for Android malware detection.
  Experimental results highlight that our model effectively reduces the feature
set while detecting Android malware with 99.50 percent accuracy when
considering only two network traffic features. Furthermore, our experiments
demonstrate that the NMRS-based algorithm on crRelevance rankings outperforms
statistical tests such as chi-square, ANOVA, Mann-Whitney U test, and
Kruskal-Wallis test. In addition, our model surpasses various state-of-the-art
Android malware detection techniques in terms of detection accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiantao Lin, Xin Yang, Meixi Chen, Yingjie Xu, Dongyu Yan, Leyi Wu, Xinli Xu, Lie XU, Shunsi Zhang, Ying-Cong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have achieved great success in generating 2D images.
However, the quality and generalizability of 3D content generation remain
limited. State-of-the-art methods often require large-scale 3D assets for
training, which are challenging to collect. In this work, we introduce
Kiss3DGen (Keep It Simple and Straightforward in 3D Generation), an efficient
framework for generating, editing, and enhancing 3D objects by repurposing a
well-trained 2D image diffusion model for 3D generation. Specifically, we
fine-tune a diffusion model to generate ''3D Bundle Image'', a tiled
representation composed of multi-view images and their corresponding normal
maps. The normal maps are then used to reconstruct a 3D mesh, and the
multi-view images provide texture mapping, resulting in a complete 3D model.
This simple method effectively transforms the 3D generation problem into a 2D
image generation task, maximizing the utilization of knowledge in pretrained
diffusion models. Furthermore, we demonstrate that our Kiss3DGen model is
compatible with various diffusion model techniques, enabling advanced features
such as 3D editing, mesh and texture enhancement, etc. Through extensive
experiments, we demonstrate the effectiveness of our approach, showcasing its
ability to produce high-quality 3D models efficiently.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first three authors contributed equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Streaming Piano Transcription Based on Consistent Onset and Offset
  Decoding with Sustain Pedal Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weixing Wei, Jiahao Zhao, Yulun Wu, Kazuyoshi Yoshii
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes a streaming audio-to-MIDI piano transcription approach
that aims to sequentially translate a music signal into a sequence of note
onset and offset events. The sequence-to-sequence nature of this task may call
for the computationally-intensive transformer model for better performance,
which has recently been used for offline transcription benchmarks and could be
extended for streaming transcription with causal attention mechanisms. We
assume that the performance limitation of this naive approach lies in the
decoder. Although time-frequency features useful for onset detection are
considerably different from those for offset detection, the single decoder is
trained to output a mixed sequence of onset and offset events without guarantee
of the correspondence between the onset and offset events of the same note. To
overcome this limitation, we propose a streaming encoder-decoder model that
uses a convolutional encoder aggregating local acoustic features, followed by
an autoregressive Transformer decoder detecting a variable number of onset
events and another decoder detecting the offset events for the active pitches
with validation of the sustain pedal at each time frame. Experiments using the
MAESTRO dataset showed that the proposed streaming method performed comparably
with or even better than the state-of-the-art offline methods while
significantly reducing the computational cost.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ISMIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HOP: Heterogeneous Topology-based Multimodal Entanglement for Co-Speech
  Gesture Generation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01175v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01175v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongye Cheng, Tianyu Wang, Guangsi Shi, Zexing Zhao, Yanwei Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Co-speech gestures are crucial non-verbal cues that enhance speech clarity
and expressiveness in human communication, which have attracted increasing
attention in multimodal research. While the existing methods have made strides
in gesture accuracy, challenges remain in generating diverse and coherent
gestures, as most approaches assume independence among multimodal inputs and
lack explicit modeling of their interactions. In this work, we propose a novel
multimodal learning method named HOP for co-speech gesture generation that
captures the heterogeneous entanglement between gesture motion, audio rhythm,
and text semantics, enabling the generation of coordinated gestures. By
leveraging spatiotemporal graph modeling, we achieve the alignment of audio and
action. Moreover, to enhance modality coherence, we build the audio-text
semantic representation based on a reprogramming module, which is beneficial
for cross-modality adaptation. Our approach enables the trimodal system to
learn each other's features and represent them in the form of topological
entanglement. Extensive experiments demonstrate that HOP achieves
state-of-the-art performance, offering more natural and expressive co-speech
gesture generation. More information, codes, and demos are available here:
https://star-uu-wang.github.io/HOP/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025. See https://star-uu-wang.github.io/HOP/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese
  Recipe Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18459v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18459v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuki Imajuku, Yoko Yamakata, Kiyoharu Aizawa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on food image understanding using recipe data has been a
long-standing focus due to the diversity and complexity of the data. Moreover,
food is inextricably linked to people's lives, making it a vital research area
for practical applications such as dietary management. Recent advancements in
Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities, not only in their vast knowledge but also in their ability to
handle languages naturally. While English is predominantly used, they can also
support multiple languages including Japanese. This suggests that MLLMs are
expected to significantly improve performance in food image understanding
tasks. We fine-tuned open MLLMs LLaVA-1.5 and Phi-3 Vision on a Japanese recipe
dataset and benchmarked their performance against the closed model GPT-4o. We
then evaluated the content of generated recipes, including ingredients and
cooking procedures, using 5,000 evaluation samples that comprehensively cover
Japanese food culture. Our evaluation demonstrates that the open models trained
on recipe data outperform GPT-4o, the current state-of-the-art model, in
ingredient generation. Our model achieved F1 score of 0.531, surpassing
GPT-4o's F1 score of 0.481, indicating a higher level of accuracy. Furthermore,
our model exhibited comparable performance to GPT-4o in generating cooking
procedure text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 5 figures. We found errors in the calculation of evaluation
  metrics, which were corrected in this version with
  $\color{blue}{\text{modifications highlighted in blue}}$. Please also see the
  Appendix</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-02T00:00:00Z">2025-03-02</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can We Find the Code? An Empirical Study of Google Scholar's Code
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01031v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01031v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shi-Shun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Academic codes associated with research papers are valuable resources for
scholars. In specialized fields outside computer science, code availability is
often limited, making effective code retrieval essential. Google Scholar is a
crucial academic search tool. If a code published in the paper is not
retrievable via Google Scholar, its accessibility and impact are significantly
reduced. This study takes the term "accelerated degradation" combined with
"reliability" as an example, and finds that, for papers published by Elsevier,
only GitHub links included in abstracts are comprehensively retrieved by Google
Scholar. When such links appear within the main body of a paper, even in the
"Data Availability" section, they may be ignored and become unsearchable. These
findings highlight the importance of strategically placing GitHub links in
abstracts to enhance code discoverability on Google Scholar.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Semantic Search Pipeline for Causality-driven Adhoc Information
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01003v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01003v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dhairya Dalal, Sharmi Dev Gupta, Bentolhoda Binaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a unsupervised semantic search pipeline for the Causality-driven
Adhoc Information Retrieval (CAIR-2021) shared task. The CAIR shared task
expands traditional information retrieval to support the retrieval of documents
containing the likely causes of a query event. A successful system must be able
to distinguish between topical documents and documents containing causal
descriptions of events that are causally related to the query event. Our
approach involves aggregating results from multiple query strategies over a
semantic and lexical index. The proposed approach leads the CAIR-2021
leaderboard and outperformed both traditional IR and pure semantic
embedding-based approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards An Efficient LLM Training Paradigm for CTR Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01001v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01001v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Allen Lin, Renqin Cai, Yun He, Hanchao Yu, Jing Qian, Rui Li, Qifan Wang, James Caverlee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated tremendous potential as the
next-generation ranking-based recommendation system. Many recent works have
shown that LLMs can significantly outperform conventional click-through-rate
(CTR) prediction approaches. Despite such promising results, the computational
inefficiency inherent in the current training paradigm makes it particularly
challenging to train LLMs for ranking-based recommendation tasks on large
datasets. To train LLMs for CTR prediction, most existing studies adopt the
prevalent ''sliding-window'' paradigm. Given a sequence of $m$ user
interactions, a unique training prompt is constructed for each interaction by
designating it as the prediction target along with its preceding $n$
interactions serving as context. In turn, the sliding-window paradigm results
in an overall complexity of $O(mn^2)$ that scales linearly with the length of
user interactions. Consequently, a direct adoption to train LLMs with such
strategy can result in prohibitively high training costs as the length of
interactions grows. To alleviate the computational inefficiency, we propose a
novel training paradigm, namely Dynamic Target Isolation (DTI), that
structurally parallelizes the training of $k$ (where $k >> 1$) target
interactions. Furthermore, we identify two major bottlenecks - hidden-state
leakage and positional bias overfitting - that limit DTI to only scale up to a
small value of $k$ (e.g., 5) then propose a computationally light solution to
effectively tackle each. Through extensive experiments on three widely adopted
public CTR datasets, we empirically show that DTI reduces training time by an
average of $\textbf{92%}$ (e.g., from $70.5$ hrs to $5.31$ hrs), without
compromising CTR prediction performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Federated Conversational Recommender System <span class="chip">ECIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Allen Lin, Jianling Wang, Ziwei Zhu, James Caverlee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Recommender Systems (CRSs) have become increasingly popular as
a powerful tool for providing personalized recommendation experiences. By
directly engaging with users in a conversational manner to learn their current
and fine-grained preferences, a CRS can quickly derive recommendations that are
relevant and justifiable. However, existing conversational recommendation
systems (CRSs) typically rely on a centralized training and deployment process,
which involves collecting and storing explicitly-communicated user preferences
in a centralized repository. These fine-grained user preferences are completely
human-interpretable and can easily be used to infer sensitive information
(e.g., financial status, political stands, and health information) about the
user, if leaked or breached. To address the user privacy concerns in CRS, we
first define a set of privacy protection guidelines for preserving user privacy
under the conversational recommendation setting. Based on these guidelines, we
propose a novel federated conversational recommendation framework that
effectively reduces the risk of exposing user privacy by (i) de-centralizing
both the historical interests estimation stage and the interactive preference
elicitation stage and (ii) strictly bounding privacy leakage by enforcing
user-level differential privacy with meticulously selected privacy budgets.
Through extensive experiments, we show that the proposed framework not only
satisfies these user privacy protection guidelines, but also enables the system
to achieve competitive recommendation performance even when compared to the
state-of-the-art non-private conversational recommendation approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Systematic Literature <span class="highlight-title">Review</span> on Clinical Trial Eligibility Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00863v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00863v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Talha Sharif, Abdul Rehman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinical trial eligibility matching is a critical yet often labor-intensive
and error-prone step in medical research, as it ensures that participants meet
precise criteria for safe and reliable study outcomes. Recent advances in
Natural Language Processing (NLP) have shown promise in automating and
improving this process by rapidly analyzing large volumes of unstructured
clinical text and structured electronic health record (EHR) data. In this
paper, we present a systematic overview of current NLP methodologies applied to
clinical trial eligibility screening, focusing on data sources, annotation
practices, machine learning approaches, and real-world implementation
challenges. A comprehensive literature search (spanning Google Scholar,
Mendeley, and PubMed from 2015 to 2024) yielded high-quality studies, each
demonstrating the potential of techniques such as rule-based systems, named
entity recognition, contextual embeddings, and ontology-based normalization to
enhance patient matching accuracy. While results indicate substantial
improvements in screening efficiency and precision, limitations persist
regarding data completeness, annotation consistency, and model scalability
across diverse clinical domains. The review highlights how explainable AI and
standardized ontologies can bolster clinician trust and broaden adoption.
Looking ahead, further research into advanced semantic and temporal
representations, expanded data integration, and rigorous prospective
evaluations is necessary to fully realize the transformative potential of NLP
in clinical trial recruitment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00781v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00781v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umar Ali Khan, Ekram Khan, Fiza Khan, Athar Ali Moinuddin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have proven immensely beneficial in education by
capturing vast amounts of literature-based information, allowing them to
generate context without relying on external sources. In this paper, we propose
a generative AI-powered GATE question-answering framework (GATE stands for
Graduate Aptitude Test in Engineering) that leverages LLMs to explain GATE
solutions and support students in their exam preparation. We conducted
extensive benchmarking to select the optimal embedding model and LLM,
evaluating our framework based on criteria such as latency, faithfulness, and
relevance, with additional validation through human evaluation. Our chatbot
integrates state-of-the-art embedding models and LLMs to deliver accurate,
context-aware responses. Through rigorous experimentation, we identified
configurations that balance performance and computational efficiency, ensuring
a reliable chatbot to serve students' needs. Additionally, we discuss the
challenges faced in data processing and modeling and implemented solutions. Our
work explores the application of Retrieval-Augmented Generation (RAG) for GATE
Q/A explanation tasks, and our findings demonstrate significant improvements in
retrieval accuracy and response quality. This research offers practical
insights for developing effective AI-driven educational tools while
highlighting areas for future enhancement in usability and scalability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OrdRankBen: A Novel Ranking Benchmark for Ordinal Relevance in NLP 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Wang, Lingfei Qian, Xueqing Peng, Jimin Huang, Dongji Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The evaluation of ranking tasks remains a significant challenge in natural
language processing (NLP), particularly due to the lack of direct labels for
results in real-world scenarios. Benchmark datasets play a crucial role in
providing standardized testbeds that ensure fair comparisons, enhance
reproducibility, and enable progress tracking, facilitating rigorous assessment
and continuous improvement of ranking models. Existing NLP ranking benchmarks
typically use binary relevance labels or continuous relevance scores,
neglecting ordinal relevance scores. However, binary labels oversimplify
relevance distinctions, while continuous scores lack a clear ordinal structure,
making it challenging to capture nuanced ranking differences effectively. To
address these challenges, we introduce OrdRankBen, a novel benchmark designed
to capture multi-granularity relevance distinctions. Unlike conventional
benchmarks, OrdRankBen incorporates structured ordinal labels, enabling more
precise ranking evaluations. Given the absence of suitable datasets for ordinal
relevance ranking in NLP, we constructed two datasets with distinct ordinal
label distributions. We further evaluate various models for three model types,
ranking-based language models, general large language models, and
ranking-focused large language models on these datasets. Experimental results
show that ordinal relevance modeling provides a more precise evaluation of
ranking models, improving their ability to distinguish multi-granularity
differences among ranked items-crucial for tasks that demand fine-grained
relevance differentiation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality
  Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10594v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10594v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is an effective technique that enables
large language models (LLMs) to utilize external knowledge sources for
generation. However, current RAG systems are solely based on text, rendering it
impossible to utilize vision information like layout and images that play
crucial roles in real-world multi-modality documents. In this paper, we
introduce VisRAG, which tackles this issue by establishing a vision-language
model (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the
document to obtain text, the document is directly embedded using a VLM as an
image and then retrieved to enhance the generation of a VLM. Compared to
traditional text-based RAG, VisRAG maximizes the retention and utilization of
the data information in the original documents, eliminating the information
loss introduced during the parsing process. We collect both open-source and
synthetic data to train the retriever in VisRAG and explore a variety of
generation methods. Experiments demonstrate that VisRAG outperforms traditional
RAG in both the retrieval and generation stages, achieving a 20--40% end-to-end
performance gain over traditional text-based RAG pipeline. Further analysis
reveals that VisRAG is efficient in utilizing training data and demonstrates
strong generalization capability, positioning it as a promising solution for
RAG on multi-modality documents. Our code and data are available at
https://github.com/openbmb/visrag.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FedBiP: Heterogeneous One-Shot Federated Learning with Personalized
  Latent Diffusion Models <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04810v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04810v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haokun Chen, Hang Li, Yao Zhang, Jinhe Bi, Gengyuan Zhang, Yueqi Zhang, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One-Shot Federated Learning (OSFL), a special decentralized machine learning
paradigm, has recently gained significant attention. OSFL requires only a
single round of client data or model upload, which reduces communication costs
and mitigates privacy threats compared to traditional FL. Despite these
promising prospects, existing methods face challenges due to client data
heterogeneity and limited data quantity when applied to real-world OSFL
systems. Recently, Latent Diffusion Models (LDM) have shown remarkable
advancements in synthesizing high-quality images through pretraining on
large-scale datasets, thereby presenting a potential solution to overcome these
issues. However, directly applying pretrained LDM to heterogeneous OSFL results
in significant distribution shifts in synthetic data, leading to performance
degradation in classification models trained on such data. This issue is
particularly pronounced in rare domains, such as medical imaging, which are
underrepresented in LDM's pretraining data. To address this challenge, we
propose Federated Bi-Level Personalization (FedBiP), which personalizes the
pretrained LDM at both instance-level and concept-level. Hereby, FedBiP
synthesizes images following the client's local data distribution without
compromising the privacy regulations. FedBiP is also the first approach to
simultaneously address feature space heterogeneity and client data scarcity in
OSFL. Our method is validated through extensive experiments on three OSFL
benchmarks with feature space heterogeneity, as well as on challenging medical
and satellite image datasets with label heterogeneity. The results demonstrate
the effectiveness of FedBiP, which substantially outperforms other OSFL
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event
  Condition For Foley Sound 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11915v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11915v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junwon Lee, Jaekwon Im, Dabin Kim, Juhan Nam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foley sound synthesis is crucial for multimedia production, enhancing user
experience by synchronizing audio and video both temporally and semantically.
Recent studies on automating this labor-intensive process through
video-to-sound generation face significant challenges. Systems lacking explicit
temporal features suffer from poor alignment and controllability, while
timestamp-based models require costly and subjective human annotation. We
propose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an
intuitive condition with semantic timbre prompts (audio or text). RMS, a
frame-level intensity envelope closely related to audio semantics, acts as a
temporal event feature to guide audio generation from video. The
annotation-free self-supervised learning framework consists of two stages,
Video2RMS and RMS2Sound, incorporating novel ideas including RMS discretization
and RMS-ControlNet with a pretrained text-to-audio model. Our extensive
evaluation shows that Video-Foley achieves state-of-the-art performance in
audio-visual alignment and controllability for sound timing, intensity, timbre,
and nuance. Source code, model weights and demos are available on our companion
website. (https://jnwnlee.github.io/video-foley-demo)
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Audio-Visual Instance Segmentation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.18709v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.18709v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruohao Guo, Xianghua Ying, Yaru Chen, Dantong Niu, Guangyao Li, Liao Qu, Yanyu Qi, Jinxing Zhou, Bowei Xing, Wenzhen Yue, Ji Shi, Qixun Wang, Peiliang Zhang, Buwen Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a new multi-modal task, termed audio-visual
instance segmentation (AVIS), which aims to simultaneously identify, segment
and track individual sounding object instances in audible videos. To facilitate
this research, we introduce a high-quality benchmark named AVISeg, containing
over 90K instance masks from 26 semantic categories in 926 long videos.
Additionally, we propose a strong baseline model for this task. Our model first
localizes sound source within each frame, and condenses object-specific
contexts into concise tokens. Then it builds long-range audio-visual
dependencies between these tokens using window-based attention, and tracks
sounding objects among the entire video sequences. Extensive experiments reveal
that our method performs best on AVISeg, surpassing the existing methods from
related tasks. We further conduct the evaluation on several multi-modal large
models. Unfortunately, they exhibits subpar performance on instance-level sound
source localization and temporal perception. We expect that AVIS will inspire
the community towards a more comprehensive multi-modal understanding. Dataset
and code is available at https://github.com/ruohaoguo/avis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Long-Text Alignment for Text-to-Image Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11817v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11817v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luping Liu, Chao Du, Tianyu Pang, Zehan Wang, Chongxuan Li, Dong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of text-to-image (T2I) diffusion models has enabled
them to generate unprecedented results from given texts. However, as text
inputs become longer, existing encoding methods like CLIP face limitations, and
aligning the generated images with long texts becomes challenging. To tackle
these issues, we propose LongAlign, which includes a segment-level encoding
method for processing long texts and a decomposed preference optimization
method for effective alignment training. For segment-level encoding, long texts
are divided into multiple segments and processed separately. This method
overcomes the maximum input length limits of pretrained encoding models. For
preference optimization, we provide decomposed CLIP-based preference models to
fine-tune diffusion models. Specifically, to utilize CLIP-based preference
models for T2I alignment, we delve into their scoring mechanisms and find that
the preference scores can be decomposed into two components: a text-relevant
part that measures T2I alignment and a text-irrelevant part that assesses other
visual aspects of human preference. Additionally, we find that the
text-irrelevant part contributes to a common overfitting problem during
fine-tuning. To address this, we propose a reweighting strategy that assigns
different weights to these two components, thereby reducing overfitting and
enhancing alignment. After fine-tuning $512 \times 512$ Stable Diffusion (SD)
v1.5 for about 20 hours using our method, the fine-tuned SD outperforms
stronger foundation models in T2I alignment, such as PixArt-$\alpha$ and
Kandinsky v2.2. The code is available at
https://github.com/luping-liu/LongAlign.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-01T00:00:00Z">2025-03-01</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PinLanding: Content-First Keyword Landing Page Generation via
  Multi-Modal AI for Web-Scale Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faye Zhang, Jasmine Wan, Qianyu Cheng, Jinfeng Rao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online platforms like Pinterest hosting vast content collections
traditionally rely on manual curation or user-generated search logs to create
keyword landing pages (KLPs) -- topic-centered collection pages that serve as
entry points for content discovery. While manual curation ensures quality, it
doesn't scale to millions of collections, and search log approaches result in
limited topic coverage and imprecise content matching. In this paper, we
present PinLanding, a novel content-first architecture that transforms the way
platforms create topical collections. Instead of deriving topics from user
behavior, our system employs a multi-stage pipeline combining vision-language
model (VLM) for attribute extraction, large language model (LLM) for topic
generation, and a CLIP-based dual-encoder architecture for precise content
matching. Our model achieves 99.7% Recall@10 on Fashion200K benchmark,
demonstrating strong attribute understanding capabilities. In production
deployment for search engine optimization with 4.2 million shopping landing
pages, the system achieves a 4X increase in topic coverage and 14.29%
improvement in collection attribute precision over the traditional search
log-based approach via human evaluation. The architecture can be generalized
beyond search traffic to power various user experiences, including content
discovery and recommendations, providing a scalable solution to transform
unstructured content into curated topical collections across any content
domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Qilin: A Multimodal Information Retrieval <span class="highlight-title">Dataset</span> with APP-level User
  Sessions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00501v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00501v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia Chen, Qian Dong, Haitao Li, Xiaohui He, Yan Gao, Shaosheng Cao, Yi Wu, Ping Yang, Chen Xu, Yao Hu, Qingyao Ai, Yiqun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User-generated content (UGC) communities, especially those featuring
multimodal content, improve user experiences by integrating visual and textual
information into results (or items). The challenge of improving user
experiences in complex systems with search and recommendation (S\&R) services
has drawn significant attention from both academia and industry these years.
However, the lack of high-quality datasets has limited the research progress on
multimodal S\&R. To address the growing need for developing better S\&R
services, we present a novel multimodal information retrieval dataset in this
paper, namely Qilin. The dataset is collected from Xiaohongshu, a popular
social platform with over 300 million monthly active users and an average
search penetration rate of over 70\%. In contrast to existing datasets,
\textsf{Qilin} offers a comprehensive collection of user sessions with
heterogeneous results like image-text notes, video notes, commercial notes, and
direct answers, facilitating the development of advanced multimodal neural
retrieval models across diverse task settings. To better model user
satisfaction and support the analysis of heterogeneous user behaviors, we also
collect extensive APP-level contextual signals and genuine user feedback.
Notably, Qilin contains user-favored answers and their referred results for
search requests triggering the Deep Query Answering (DQA) module. This allows
not only the training \& evaluation of a Retrieval-augmented Generation (RAG)
pipeline, but also the exploration of how such a module would affect users'
search behavior. Through comprehensive analysis and experiments, we provide
interesting findings and insights for further improving S\&R systems. We hope
that \textsf{Qilin} will significantly contribute to the advancement of
multimodal content platforms with S\&R services in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bayesian Active Learning for Multi-Criteria Comparative Judgement in
  Educational Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00479v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00479v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andy Gray, Alma Rahat, Tom Crick, Stephen Lindsay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Comparative Judgement (CJ) provides an alternative assessment approach by
evaluating work holistically rather than breaking it into discrete criteria.
This method leverages human ability to make nuanced comparisons, yielding more
reliable and valid assessments. CJ aligns with real-world evaluations, where
overall quality emerges from the interplay of various elements. However,
rubrics remain widely used in education, offering structured criteria for
grading and detailed feedback. This creates a gap between CJ's holistic ranking
and the need for criterion-based performance breakdowns.
  This paper addresses this gap using a Bayesian approach. We build on Bayesian
CJ (BCJ) by Gray et al., which directly models preferences instead of using
likelihoods over total scores, allowing for expected ranks with uncertainty
estimation. Their entropy-based active learning method selects the most
informative pairwise comparisons for assessors. We extend BCJ to handle
multiple independent learning outcome (LO) components, defined by a rubric,
enabling both holistic and component-wise predictive rankings with uncertainty
estimates. Additionally, we propose a method to aggregate entropies and
identify the most informative comparison for assessors. Experiments on
synthetic and real data demonstrate our method's effectiveness. Finally, we
address a key limitation of BCJ, which is the inability to quantify assessor
agreement. We show how to derive agreement levels, enhancing transparency in
assessment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ U-NIAH: Unified RAG and LLM Evaluation for Long Context
  Needle-In-A-Haystack 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00353v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00353v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunfan Gao, Yun Xiong, Wenlong Wu, Zijing Huang, Bohan Li, Haofen Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have expanded their
context windows to unprecedented lengths, sparking debates about the necessity
of Retrieval-Augmented Generation (RAG). To address the fragmented evaluation
paradigms and limited cases in existing Needle-in-a-Haystack (NIAH), this paper
introduces U-NIAH, a unified framework that systematically compares LLMs and
RAG methods in controlled long context settings. Our framework extends beyond
traditional NIAH by incorporating multi-needle, long-needle, and
needle-in-needle configurations, along with different retrieval settings, while
leveraging the synthetic Starlight Academy dataset-a fictional magical
universe-to eliminate biases from pre-trained knowledge. Through extensive
experiments, we investigate three research questions: (1) performance
trade-offs between LLMs and RAG, (2) error patterns in RAG, and (3) RAG's
limitations in complex settings. Our findings show that RAG significantly
enhances smaller LLMs by mitigating the "lost-in-the-middle" effect and
improving robustness, achieving an 82.58% win-rate over LLMs. However, we
observe that retrieval noise and reverse chunk ordering degrade performance,
while surprisingly, advanced reasoning LLMs exhibit reduced RAG compatibility
due to sensitivity to semantic distractors. We identify typical error patterns
including omission due to noise, hallucination under high noise critical
condition, and self-doubt behaviors. Our work not only highlights the
complementary roles of RAG and LLMs, but also provides actionable insights for
optimizing deployments. Code: https://github.com/Tongji-KGLLM/U-NIAH.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pseudo-Knowledge Graph: Meta-Path Guided Retrieval and In-Graph Text for
  RAG-Equipped LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Yang, Haoyang Wu, Tao Wang, Jia Yang, Hao Ma, Guojie Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of Large Language Models (LLMs) has revolutionized natural
language processing. However, these models face challenges in retrieving
precise information from vast datasets. Retrieval-Augmented Generation (RAG)
was developed to combining LLMs with external information retrieval systems to
enhance the accuracy and context of responses. Despite improvements, RAG still
struggles with comprehensive retrieval in high-volume, low-information-density
databases and lacks relational awareness, leading to fragmented answers.
  To address this, this paper introduces the Pseudo-Knowledge Graph (PKG)
framework, designed to overcome these limitations by integrating Meta-path
Retrieval, In-graph Text and Vector Retrieval into LLMs. By preserving natural
language text and leveraging various retrieval techniques, the PKG offers a
richer knowledge representation and improves accuracy in information retrieval.
Extensive evaluations using Open Compass and MultiHop-RAG benchmarks
demonstrate the framework's effectiveness in managing large volumes of data and
complex relationships.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NeuroLit Navigator: A Neurosymbolic Approach to Scholarly Article
  Searches for Systematic <span class="highlight-title">Review</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vedant Khandelwal, Kaushik Roy, Valerie Lookingbill, Ritvik Garimella, Harshul Surana, Heather Heckman, Amit Sheth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The introduction of Large Language Models (LLMs) has significantly impacted
various fields, including education, for example, by enabling the creation of
personalized learning materials. However, their use in Systematic Reviews (SRs)
reveals limitations such as restricted access to specialized vocabularies, lack
of domain-specific reasoning, and a tendency to generate inaccurate
information. Existing SR tools often rely on traditional NLP methods and fail
to address these issues adequately. To overcome these challenges, we developed
the ``NeuroLit Navigator,'' a system that combines domain-specific LLMs with
structured knowledge sources like Medical Subject Headings (MeSH) and the
Unified Medical Language System (UMLS). This integration enhances query
formulation, expands search vocabularies, and deepens search scopes, enabling
more precise searches. Deployed in multiple universities and tested by over a
dozen librarians, the NeuroLit Navigator has reduced the time required for
initial literature searches by 90\%. Despite this efficiency, the initial set
of articles retrieved can vary in relevance and quality. Nonetheless, the
system has greatly improved the reproducibility of search results,
demonstrating its potential to support librarians in the SR process.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixture of Structural-and-Textual Retrieval over Text-rich Graph
  Knowledge Bases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20317v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20317v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongjia Lei, Haoyu Han, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka, Mahantesh M Halappanavar, Jiliang Tang, Yu Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for
answering queries by providing textual and structural knowledge. However,
current retrieval methods often retrieve these two types of knowledge in
isolation without considering their mutual reinforcement and some hybrid
methods even bypass structural retrieval entirely after neighboring
aggregation. To fill in this gap, we propose a Mixture of
Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge
via a Planning-Reasoning-Organizing framework. In the Planning stage, MoR
generates textual planning graphs delineating the logic for answering queries.
Following planning graphs, in the Reasoning stage, MoR interweaves structural
traversal and textual matching to obtain candidates from TG-KBs. In the
Organizing stage, MoR further reranks fetched candidates based on their
structural trajectory. Extensive experiments demonstrate the superiority of MoR
in harmonizing structural and textual retrieval with insights, including uneven
retrieving performance across different query logics and the benefits of
integrating structural trajectories for candidate reranking. Our code is
available at https://github.com/Yoega/MoR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ICPE: An Item Cluster-Wise Pareto-Efficient Framework for Recommendation
  Debiasing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2109.12887v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2109.12887v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yule Wang, Xin Xin, Yue Ding, Yunzhe Li, Dong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender system based on historical user-item interactions is of vital
importance for web-based services. However, the observed data used to train the
recommender model suffers from severe bias issues. Practically, the item
frequency distribution of the dataset is a highly skewed power-law
distribution. Interactions of a small fraction of head items account for almost
the whole training data. The normal training paradigm from such biased data
tends to repetitively generate recommendations from the head items, which
further exacerbates the biases and affects the exploration of potentially
interesting items from the niche set. In this work, we innovatively explore the
central theme of recommendation debiasing from an item cluster-wise
multi-objective optimization perspective. Aiming to balance the learning on
various item clusters that differ in popularity during the training process, we
propose a model-agnostic framework namely Item Cluster-Wise Pareto-Efficient
Recommendation (ICPE). In detail, we define our item cluster-wise optimization
target as the recommender model should balance all item clusters that differ in
popularity, thus we set the model learning on each item cluster as a unique
optimization objective. To achieve this goal, we first explore items'
popularity levels from a novel causal reasoning perspective. Then, we devise
popularity discrepancy-based bisecting clustering to separate the item
clusters. Next, we adaptively find the overall harmonious gradient direction
for cluster-wise optimization objectives from a Pareto-efficient solver.
Finally, in the prediction stage, we perform counterfactual inference to
further eliminate the impact of global propensity. Extensive experimental
results verify the superiorities of ICPE on overall recommendation performance
and biases elimination.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.20207v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.20207v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongming Tan, Shaoxiong Zhan, Hai Lin, Hai-Tao Zheng, Wai Kin Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In dense retrieval, embedding long texts into dense vectors can result in
information loss, leading to inaccurate query-text matching. Additionally,
low-quality texts with excessive noise or sparse key information are unlikely
to align well with relevant queries. Recent studies mainly focus on improving
the sentence embedding model or retrieval process. In this work, we introduce a
novel text augmentation framework for dense retrieval. This framework
transforms raw documents into information-dense text formats, which supplement
the original texts to effectively address the aforementioned issues without
modifying embedding or retrieval methodologies. Two text representations are
generated via large language models (LLMs) zero-shot prompting: question-answer
pairs and element-driven events. We term this approach QAEA-DR: unifying
question-answer generation and event extraction in a text augmentation
framework for dense retrieval. To further enhance the quality of generated
texts, a scoring-based evaluation and regeneration mechanism is introduced in
LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,
supported by both theoretical analysis and empirical experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Search and Society: Reimagining Information Access for Radical Futures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17901v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17901v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhaskar Mitra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval (IR) research must understand and contend with the
social implications of the technology it produces. Instead of adopting a
reactionary strategy of trying to mitigate potential social harms from emerging
technologies, the community should aim to proactively set the research agenda
for the kinds of systems we should build inspired by diverse explicitly stated
sociotechnical imaginaries. The sociotechnical imaginaries that underpin the
design and development of information access technologies needs to be
explicitly articulated, and we need to develop theories of change in context of
these diverse perspectives. Our guiding future imaginaries must be informed by
other academic fields, such as human-computer interaction, information
sciences, media studies, design, science and technology studies, social
sciences, humanities, democratic theory, and critical theory, as well as legal
and policy experts, civil rights and social justice activists, and artists,
among others. In this perspective paper, we motivate why the community must
consider this radical shift in how we do research and what we work on, and
sketch a path forward towards this transformation.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Perceptual Visual Quality Assessment: Principles, Methods, and Future
  Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Zhou, Hadi Amirpour, Christian Timmerer, Guangtao Zhai, Patrick Le Callet, Alan C. Bovik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As multimedia services such as video streaming, video conferencing, virtual
reality (VR), and online gaming continue to expand, ensuring high perceptual
visual quality becomes a priority to maintain user satisfaction and
competitiveness. However, multimedia content undergoes various distortions
during acquisition, compression, transmission, and storage, resulting in the
degradation of experienced quality. Thus, perceptual visual quality assessment
(PVQA), which focuses on evaluating the quality of multimedia content based on
human perception, is essential for optimizing user experiences in advanced
communication systems. Several challenges are involved in the PVQA process,
including diverse characteristics of multimedia content such as image, video,
VR, point cloud, mesh, multimodality, etc., and complex distortion scenarios as
well as viewing conditions. In this paper, we first present an overview of PVQA
principles and methods. This includes both subjective methods, where users
directly rate their experiences, and objective methods, where algorithms
predict human perception based on measurable factors such as bitrate, frame
rate, and compression levels. Based on the basics of PVQA, quality predictors
for different multimedia data are then introduced. In addition to traditional
images and videos, immersive multimedia and generative artificial intelligence
(GenAI) content are also discussed. Finally, the paper concludes with a
discussion on the future directions of PVQA research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A tutorial and review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unbiased Video Scene Graph Generation via Visual and Semantic Dual
  Debiasing <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanjun Li, Zhaoyang Li, Honghui Chen, Lizhi Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Scene Graph Generation (VidSGG) aims to capture dynamic relationships
among entities by sequentially analyzing video frames and integrating visual
and semantic information. However, VidSGG is challenged by significant biases
that skew predictions. To mitigate these biases, we propose a VIsual and
Semantic Awareness (VISA) framework for unbiased VidSGG. VISA addresses visual
bias through memory-enhanced temporal integration that enhances object
representations and concurrently reduces semantic bias by iteratively
integrating object features with comprehensive semantic information derived
from triplet relationships. This visual-semantics dual debiasing approach
results in more unbiased representations of complex scene dynamics. Extensive
experiments demonstrate the effectiveness of our method, where VISA outperforms
existing unbiased VidSGG approaches by a substantial margin (e.g., +13.1%
improvement in mR@20 and mR@50 for the SGCLS task under Semi Constraint).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures, CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PodAgent: A Comprehensive Framework for Podcast Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00455v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00455v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujia Xiao, Lei He, Haohan Guo, Fenglong Xie, Tan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing Existing automatic audio generation methods struggle to generate
podcast-like audio programs effectively. The key challenges lie in in-depth
content generation, appropriate and expressive voice production. This paper
proposed PodAgent, a comprehensive framework for creating audio programs.
PodAgent 1) generates informative topic-discussion content by designing a
Host-Guest-Writer multi-agent collaboration system, 2) builds a voice pool for
suitable voice-role matching and 3) utilizes LLM-enhanced speech synthesis
method to generate expressive conversational speech. Given the absence of
standardized evaluation criteria for podcast-like audio generation, we
developed comprehensive assessment guidelines to effectively evaluate the
model's performance. Experimental results demonstrate PodAgent's effectiveness,
significantly surpassing direct GPT-4 generation in topic-discussion dialogue
content, achieving an 87.4% voice-matching accuracy, and producing more
expressive speech through LLM-guided synthesis. Demo page:
https://podcast-agent.github.io/demo/. Source code:
https://github.com/yujxx/PodAgent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIRROR: Multi-Modal Pathological <span class="highlight-title">Self-Supervised</span> Representation Learning
  via Modality Alignment and Retention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00374v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00374v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Wang, Jianan Fan, Dingxin Zhang, Dongnan Liu, Yong Xia, Heng Huang, Weidong Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Histopathology and transcriptomics are fundamental modalities in oncology,
encapsulating the morphological and molecular aspects of the disease.
Multi-modal self-supervised learning has demonstrated remarkable potential in
learning pathological representations by integrating diverse data sources.
Conventional multi-modal integration methods primarily emphasize modality
alignment, while paying insufficient attention to retaining the
modality-specific structures. However, unlike conventional scenarios where
multi-modal inputs share highly overlapping features, histopathology and
transcriptomics exhibit pronounced heterogeneity, offering orthogonal yet
complementary insights. Histopathology provides morphological and spatial
context, elucidating tissue architecture and cellular topology, whereas
transcriptomics delineates molecular signatures through gene expression
patterns. This inherent disparity introduces a major challenge in aligning them
while maintaining modality-specific fidelity. To address these challenges, we
present MIRROR, a novel multi-modal representation learning method designed to
foster both modality alignment and retention. MIRROR employs dedicated encoders
to extract comprehensive features for each modality, which is further
complemented by a modality alignment module to achieve seamless integration
between phenotype patterns and molecular profiles. Furthermore, a modality
retention module safeguards unique attributes from each modality, while a style
clustering module mitigates redundancy and enhances disease-relevant
information by modeling and aligning consistent pathological signatures within
a clustering space. Extensive evaluations on TCGA cohorts for cancer subtyping
and survival analysis highlight MIRROR's superior performance, demonstrating
its effectiveness in constructing comprehensive oncological feature
representations and benefiting the cancer diagnosis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-28T00:00:00Z">2025-02-28</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">20</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Passage Query Methods for Retrieval and Reranking in Conversational
  Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00238v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00238v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Victor De Lima, Grace Hui Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents our approach to the TREC Interactive Knowledge Assistance
Track (iKAT), which focuses on improving conversational information-seeking
(CIS) systems. While recent advancements in CIS have improved conversational
agents' ability to assist users, significant challenges remain in understanding
context and retrieving relevant documents across domains and dialogue turns. To
address these issues, we extend the Generate-Retrieve-Generate pipeline by
developing passage queries (PQs) that align with the target document's expected
format to improve query-document matching during retrieval. We propose two
variations of this approach: Weighted Reranking and Short and Long Passages.
Each method leverages a Meta Llama model for context understanding and
generating queries and responses. Passage ranking evaluation results show that
the Short and Long Passages approach outperformed the organizers' baselines,
performed best among Llama-based systems in the track, and achieved results
comparable to GPT-4-based systems. These results indicate that the method
effectively balances efficiency and performance. Findings suggest that PQs
improve semantic alignment with target documents and demonstrate their
potential to improve multi-turn dialogue systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 3 figures. In Proceedings of the Thirty-Third Text Retrieval
  Conference (TREC 2024), November 18-22, 2024, Rockville, MD, USA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DeepRetrieval: Powerful Query Generation for Information Retrieval with
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00223v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00223v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengcheng Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval systems are crucial for enabling effective access to
large document collections. Recent approaches have leveraged Large Language
Models (LLMs) to enhance retrieval performance through query augmentation, but
often rely on expensive supervised learning or distillation techniques that
require significant computational resources and hand-labeled data. In this
paper, we introduce DeepRetrieval, a novel reinforcement learning-based
approach that trains LLMs to perform query augmentation directly through trial
and error, without requiring supervised data. By using the retrieval recall as
a reward signal, our system learns to generate effective queries that maximize
document retrieval performance. Our preliminary results demonstrate that
DeepRetrieval significantly outperforms existing state-of-the-art methods,
including the recent LEADS system, achieving 60.82\% recall on publication
search and 70.84\% recall on trial search tasks while using a smaller model (3B
vs. 7B parameters) and requiring no supervision data. These results suggest
that our reinforcement learning approach offers a more efficient and effective
paradigm for information retrieval, potentially changing the landscape of
document retrieval systems. code is available at
https://github.com/pat-jj/DeepRetrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot and Efficient Clarification Need Prediction in Conversational
  Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lili Lu, Chuan Meng, Federico Ravenda, Mohammad Aliannejadi, Fabio Crestani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clarification need prediction (CNP) is a key task in conversational search,
aiming to predict whether to ask a clarifying question or give an answer to the
current user query. However, current research on CNP suffers from the issues of
limited CNP training data and low efficiency. In this paper, we propose a
zero-shot and efficient CNP framework (Zef-CNP), in which we first prompt large
language models (LLMs) in a zero-shot manner to generate two sets of synthetic
queries: ambiguous and specific (unambiguous) queries. We then use the
generated queries to train efficient CNP models. Zef-CNP eliminates the need
for human-annotated clarification-need labels during training and avoids the
use of LLMs with high query latency at query time. To further improve the
generation quality of synthetic queries, we devise a topic-, information-need-,
and query-aware chain-of-thought (CoT) prompting strategy (TIQ-CoT). Moreover,
we enhance TIQ-CoT with counterfactual query generation (CoQu), which guides
LLMs first to generate a specific/ambiguous query and then sequentially
generate its corresponding ambiguous/specific query. Experimental results show
that Zef-CNP achieves superior CNP effectiveness and efficiency compared with
zero- and few-shot LLM-based CNP predictors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Joint Modeling in Recommendations: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.21195v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.21195v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Zhao, Yichao Wang, Bo Chen, Jingtong Gao, Yuhao Wang, Xiaopeng Li, Pengyue Jia, Qidong Liu, Huifeng Guo, Ruiming Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In today's digital landscape, Deep Recommender Systems (DRS) play a crucial
role in navigating and customizing online content for individual preferences.
However, conventional methods, which mainly depend on single recommendation
task, scenario, data modality and user behavior, are increasingly seen as
insufficient due to their inability to accurately reflect users' complex and
changing preferences. This gap underscores the need for joint modeling
approaches, which are central to overcoming these limitations by integrating
diverse tasks, scenarios, modalities, and behaviors in the recommendation
process, thus promising significant enhancements in recommendation precision,
efficiency, and customization. In this paper, we comprehensively survey the
joint modeling methods in recommendations. We begin by defining the scope of
joint modeling through four distinct dimensions: multi-task, multi-scenario,
multi-modal, and multi-behavior modeling. Subsequently, we examine these
methods in depth, identifying and summarizing their underlying paradigms based
on the latest advancements and potential research trajectories. Ultimately, we
highlight several promising avenues for future exploration in joint modeling
for recommendations and provide a concise conclusion to our findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2302.03525</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Large Language Models for ESG Activity Detection in Financial
  Texts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.21112v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.21112v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mattia Birti, Francesco Osborne, Andrea Maurino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of Environmental, Social, and Governance (ESG) factors into
corporate decision-making is a fundamental aspect of sustainable finance.
However, ensuring that business practices align with evolving regulatory
frameworks remains a persistent challenge. AI-driven solutions for
automatically assessing the alignment of sustainability reports and
non-financial disclosures with specific ESG activities could greatly support
this process. Yet, this task remains complex due to the limitations of
general-purpose Large Language Models (LLMs) in domain-specific contexts and
the scarcity of structured, high-quality datasets. In this paper, we
investigate the ability of current-generation LLMs to identify text related to
environmental activities. Furthermore, we demonstrate that their performance
can be significantly enhanced through fine-tuning on a combination of original
and synthetically generated data. To this end, we introduce ESG-Activities, a
benchmark dataset containing 1,325 labelled text segments classified according
to the EU ESG taxonomy. Our experimental results show that fine-tuning on
ESG-Activities significantly enhances classification accuracy, with open models
such as Llama 7B and Gemma 7B outperforming large proprietary solutions in
specific configurations. These findings have important implications for
financial analysts, policymakers, and AI researchers seeking to enhance ESG
transparency and compliance through advanced natural language processing
techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast 3D point clouds retrieval for Large-scale 3D Place Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.21067v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.21067v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chahine-Nicolas Zede, Laurent Carrafa, Valérie Gouet-Brunet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval in 3D point clouds is a challenging task that consists in
retrieving the most similar point clouds to a given query within a reference of
3D points. Current methods focus on comparing descriptors of point clouds in
order to identify similar ones. Due to the complexity of this latter step, here
we focus on the acceleration of the retrieval by adapting the Differentiable
Search Index (DSI), a transformer-based approach initially designed for text
information retrieval, for 3D point clouds retrieval. Our approach generates 1D
identifiers based on the point descriptors, enabling direct retrieval in
constant time. To adapt DSI to 3D data, we integrate Vision Transformers to map
descriptors to these identifiers while incorporating positional and semantic
encoding. The approach is evaluated for place recognition on a public benchmark
comparing its retrieval capabilities against state-of-the-art methods, in terms
of quality and speed of returned point clouds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 1 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extending Dense Passage Retrieval with Temporal Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.21024v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.21024v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdelrahman Abdallah, Bhawna Piryani, Jonas Wallat, Avishek Anand, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal awareness is crucial in many information retrieval tasks,
particularly in scenarios where the relevance of documents depends on their
alignment with the query's temporal context. Traditional retrieval methods such
as BM25 and Dense Passage Retrieval (DPR) excel at capturing lexical and
semantic relevance but fall short in addressing time-sensitive queries. To
bridge this gap, we introduce the temporal retrieval model that integrates
explicit temporal signals by incorporating query timestamps and document dates
into the representation space. Our approach ensures that retrieved passages are
not only topically relevant but also temporally aligned with user intent. We
evaluate our approach on two large-scale benchmark datasets, ArchivalQA and
ChroniclingAmericaQA, achieving substantial performance gains over standard
retrieval baselines. In particular, our model improves Top-1 retrieval accuracy
by 6.63% and NDCG@10 by 3.79% on ArchivalQA, while yielding a 9.56% boost in
Top-1 retrieval accuracy and 4.68% in NDCG@10 on ChroniclingAmericaQA.
Additionally, we introduce a time-sensitive negative sampling strategy, which
refines the model's ability to distinguish between temporally relevant and
irrelevant documents during training. Our findings highlight the importance of
explicitly modeling time in retrieval systems and set a new standard for
handling temporally grounded queries.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The RAG Paradox: A Black-Box Attack Exploiting Unintentional
  Vulnerabilities in Retrieval-Augmented Generation Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20995v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20995v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chanwoo Choi, Jinsoo Kim, Sukmin Cho, Soyeong Jeong, Buru Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing adoption of retrieval-augmented generation (RAG) systems,
recent studies have introduced attack methods aimed at degrading their
performance. However, these methods rely on unrealistic white-box assumptions,
such as attackers having access to RAG systems' internal processes. To address
this issue, we introduce a realistic black-box attack scenario based on the RAG
paradox, where RAG systems inadvertently expose vulnerabilities while
attempting to enhance trustworthiness. Because RAG systems reference external
documents during response generation, our attack targets these sources without
requiring internal access. Our approach first identifies the external sources
disclosed by RAG systems and then automatically generates poisoned documents
with misinformation designed to match these sources. Finally, these poisoned
documents are newly published on the disclosed sources, disrupting the RAG
system's response generation process. Both offline and online experiments
confirm that this attack significantly reduces RAG performance without
requiring internal access. Furthermore, from an insider perspective within the
RAG system, we propose a re-ranking method that acts as a fundamental
safeguard, offering minimal protection against unforeseen attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Variations in Relevance Judgments and the Shelf Life of Test Collections 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20937v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20937v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Parry, Maik Fröbe, Harrisen Scells, Ferdinand Schlatt, Guglielmo Faggioli, Saber Zerhoudi, Sean MacAvaney, Eugene Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fundamental property of Cranfield-style evaluations, that system rankings
are stable even when assessors disagree on individual relevance decisions, was
validated on traditional test collections. However, the paradigm shift towards
neural retrieval models affected the characteristics of modern test
collections, e.g., documents are short, judged with four grades of relevance,
and information needs have no descriptions or narratives. Under these changes,
it is unclear whether assessor disagreement remains negligible for system
comparisons. We investigate this aspect under the additional condition that the
few modern test collections are heavily re-used. Given more possible query
interpretations due to less formalized information needs, an ''expiration
date'' for test collections might be needed if top-effectiveness requires
overfitting to a single interpretation of relevance. We run a reproducibility
study and re-annotate the relevance judgments of the 2019 TREC Deep Learning
track. We can reproduce prior work in the neural retrieval setting, showing
that assessor disagreement does not affect system rankings. However, we observe
that some models substantially degrade with our new relevance judgments, and
some have already reached the effectiveness of humans as rankers, providing
evidence that test collections can expire.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 tables, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WebFAQ: A Multilingual Collection of Natural Q&A <span class="highlight-title">Dataset</span>s for Dense
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Dinzinger, Laura Caspari, Kanishka Ghosh Dastidar, Jelena Mitrović, Michael Granitzer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present WebFAQ, a large-scale collection of open-domain question answering
datasets derived from FAQ-style schema.org annotations. In total, the data
collection consists of 96 million natural question-answer (QA) pairs across 75
languages, including 47 million (49%) non-English samples. WebFAQ further
serves as the foundation for 20 monolingual retrieval benchmarks with a total
size of 11.2 million QA pairs (5.9 million non-English). These datasets are
carefully curated through refined filtering and near-duplicate detection,
yielding high-quality resources for training and evaluating multilingual dense
retrieval models. To empirically confirm WebFAQ's efficacy, we use the
collected QAs to fine-tune an in-domain pretrained XLM-RoBERTa model. Through
this process of dataset-specific fine-tuning, the model achieves significant
retrieval performance gains, which generalize - beyond WebFAQ - to other
multilingual retrieval benchmarks evaluated in zero-shot setting. Last but not
least, we utilize WebFAQ to construct a set of QA-aligned bilingual corpora
spanning over 1000 language pairs using state-of-the-art bitext mining and
automated LLM-assessed translation evaluation. Due to our advanced, automated
method of bitext dataset generation, the resulting bilingual corpora
demonstrate higher translation quality compared to similar datasets. WebFAQ and
all associated resources are publicly available on GitHub and HuggingFace.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoTMR: Chain-of-Thought Multi-Scale Reasoning for Training-Free
  Zero-Shot Composed Image Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zelong Sun, Dong Jing, Zhiwu Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images by
integrating information from a composed query (reference image and modification
text) without training samples. Existing methods primarily combine caption
models and large language models (LLMs) to generate target captions based on
composed queries but face various issues such as incompatibility, visual
information loss, and insufficient reasoning. In this work, we propose CoTMR, a
training-free framework crafted for ZS-CIR with novel Chain-of-thought (CoT)
and Multi-scale Reasoning. Instead of relying on caption models for modality
transformation, CoTMR employs the Large Vision-Language Model (LVLM) to achieve
unified understanding and reasoning for composed queries. To enhance the
reasoning reliability, we devise CIRCoT, which guides the LVLM through a
step-by-step inference process using predefined subtasks. Considering that
existing approaches focus solely on global-level reasoning, our CoTMR
incorporates multi-scale reasoning to achieve more comprehensive inference via
fine-grained predictions about the presence or absence of key elements at the
object scale. Further, we design a Multi-Grained Scoring (MGS) mechanism, which
integrates CLIP similarity scores of the above reasoning outputs with candidate
images to realize precise retrieval. Extensive experiments demonstrate that our
CoTMR not only drastically outperforms previous methods across four prominent
benchmarks but also offers appealing interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable Overload-Aware Graph-Based Index Construction for
  10-Billion-Scale Vector Similarity Search <span class="chip">WWW'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Shi, Yiping Sun, Jiaolong Du, Xiaocheng Zhong, Zhiyong Wang, Yao Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Approximate Nearest Neighbor Search (ANNS) is essential for modern
data-driven applications that require efficient retrieval of top-k results from
massive vector databases. Although existing graph-based ANNS algorithms achieve
a high recall rate on billion-scale datasets, their slow construction speed and
limited scalability hinder their applicability to large-scale industrial
scenarios. In this paper, we introduce SOGAIC, the first Scalable
Overload-Aware Graph-Based ANNS Index Construction system tailored for
ultra-large-scale vector databases: 1) We propose a dynamic data partitioning
algorithm with overload constraints that adaptively introduces overlaps among
subsets; 2) To enable efficient distributed subgraph construction, we employ a
load-balancing task scheduling framework combined with an agglomerative merging
strategy; 3) Extensive experiments on various datasets demonstrate a reduction
of 47.3% in average construction time compared to existing methods. The
proposed method has also been successfully deployed in a real-world industrial
search engine, managing over 10 billion daily updated vectors and serving
hundreds of millions of users.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unleashing the Potential of Two-Tower Models: Diffusion-Based
  Cross-Interaction for Large-Scale Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihan Wang, Fei Xiong, Zhexin Han, Qi Song, Kaiqiao Zhan, Ben Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Two-tower models are widely adopted in the industrial-scale matching stage
across a broad range of application domains, such as content recommendations,
advertisement systems, and search engines. This model efficiently handles
large-scale candidate item screening by separating user and item
representations. However, the decoupling network also leads to a neglect of
potential information interaction between the user and item representations.
Current state-of-the-art (SOTA) approaches include adding a shallow fully
connected layer(i.e., COLD), which is limited by performance and can only be
used in the ranking stage. For performance considerations, another approach
attempts to capture historical positive interaction information from the other
tower by regarding them as the input features(i.e., DAT). Later research showed
that the gains achieved by this method are still limited because of lacking the
guidance on the next user intent. To address the aforementioned challenges, we
propose a "cross-interaction decoupling architecture" within our matching
paradigm. This user-tower architecture leverages a diffusion module to
reconstruct the next positive intention representation and employs a
mixed-attention module to facilitate comprehensive cross-interaction. During
the next positive intention generation, we further enhance the accuracy of its
reconstruction by explicitly extracting the temporal drift within user behavior
sequences. Experiments on two real-world datasets and one industrial dataset
demonstrate that our method outperforms the SOTA two-tower models
significantly, and our diffusion approach outperforms other generative models
in reconstructing item representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LexRAG: Benchmarking Retrieval-Augmented Generation in Multi-Turn Legal
  Consultation Conversation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20640v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20640v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haitao Li, Yifan Chen, Yiran Hu, Qingyao Ai, Junjie Chen, Xiaoyu Yang, Jianhui Yang, Yueyue Wu, Zeyang Liu, Yiqun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has proven highly effective in improving
large language models (LLMs) across various domains. However, there is no
benchmark specifically designed to assess the effectiveness of RAG in the legal
domain, which restricts progress in this area. To fill this gap, we propose
LexRAG, the first benchmark to evaluate RAG systems for multi-turn legal
consultations. LexRAG consists of 1,013 multi-turn dialogue samples and 17,228
candidate legal articles. Each sample is annotated by legal experts and
consists of five rounds of progressive questioning. LexRAG includes two key
tasks: (1) Conversational knowledge retrieval, requiring accurate retrieval of
relevant legal articles based on multi-turn context. (2) Response generation,
focusing on producing legally sound answers. To ensure reliable
reproducibility, we develop LexiT, a legal RAG toolkit that provides a
comprehensive implementation of RAG system components tailored for the legal
domain. Additionally, we introduce an LLM-as-a-judge evaluation pipeline to
enable detailed and effective assessment. Through experimental analysis of
various LLMs and retrieval methods, we reveal the key limitations of existing
RAG systems in handling legal consultation conversations. LexRAG establishes a
new benchmark for the practical application of RAG systems in the legal domain,
with its code and data available at https://github.com/CSHaitao/LexRAG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02642v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02642v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijie Chen, Bernal Jiménez Gutiérrez, Yu Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval (IR) systems have played a vital role in modern digital
life and have cemented their continued usefulness in this new era of generative
AI via retrieval-augmented generation. With strong language processing
capabilities and remarkable versatility, large language models (LLMs) have
become popular choices for zero-shot re-ranking in IR systems. So far,
LLM-based re-ranking methods rely on strong generative capabilities, which
restricts their use to either specialized or powerful proprietary models. Given
these restrictions, we ask: is autoregressive generation necessary and optimal
for LLMs to perform re-ranking? We hypothesize that there are abundant signals
relevant to re-ranking within LLMs that might not be used to their full
potential via generation. To more directly leverage such signals, we propose
in-context re-ranking (ICR), a novel method that leverages the change in
attention pattern caused by the search query for accurate and efficient
re-ranking. To mitigate the intrinsic biases in LLMs, we propose a calibration
method using a content-free query. Due to the absence of generation, ICR only
requires two ($O(1)$) forward passes to re-rank $N$ documents, making it
substantially more efficient than generative re-ranking methods that require at
least $O(N)$ forward passes. Our novel design also enables ICR to be applied to
any LLM without specialized training while guaranteeing a well-formed ranking.
Extensive experiments with two popular open-weight LLMs on standard single-hop
and multi-hop information retrieval benchmarks show that ICR outperforms
RankGPT while cutting the latency by more than 60% in practice. Through
detailed analyses, we show that ICR's performance is specially strong on tasks
that require more complex re-ranking signals. Our findings call for further
exploration on novel ways of utilizing open-weight LLMs beyond text generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear
  Travelling Salesman Model <span class="chip">KDD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12064v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12064v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weixian Waylon Li, Yftah Ziser, Yifei Xie, Shay B. Cohen, Tiejun Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods
like RankNet and LambdaMART, often fall short by solely focusing on pairwise
comparisons, leading to sub-optimal global rankings. Conversely, deep learning
based listwise methods, while aiming to optimise entire lists, require complex
tuning and yield only marginal improvements over robust pairwise models. To
overcome these limitations, we introduce Travelling Salesman Problem Rank
(TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the
ranking problem as a Travelling Salesman Problem (TSP), a well-known
combinatorial optimisation challenge that has been extensively studied for its
numerous solution algorithms and applications. This approach enables the
modelling of pairwise relationships and leverages combinatorial optimisation to
determine the listwise ranking. This approach can be directly integrated as an
additional component into embeddings generated by existing backbone models to
enhance ranking performance. Our extensive experiments across three backbone
models on diverse tasks, including stock ranking, information retrieval, and
historical events ordering, demonstrate that TSPRank significantly outperforms
both pure pairwise and listwise methods. Our qualitative analysis reveals that
TSPRank's main advantage over existing methods is its ability to harness global
information better while ranking. TSPRank's robustness and superior performance
across different domains highlight its potential as a versatile and effective
LETOR solution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACM SIGKDD 2025 Research Track. The code and preprocessed
  data are available at https://github.com/waylonli/TSPRank-KDD2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LoRec: Large Language Model for Robust Sequential Recommendation against
  Poisoning Attacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.17723v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.17723v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems stand out for their ability to capture users'
dynamic interests and the patterns of item-to-item transitions. However, the
inherent openness of sequential recommender systems renders them vulnerable to
poisoning attacks, where fraudulent users are injected into the training data
to manipulate learned patterns. Traditional defense strategies predominantly
depend on predefined assumptions or rules extracted from specific known
attacks, limiting their generalizability to unknown attack types. To solve the
above problems, considering the rich open-world knowledge encapsulated in Large
Language Models (LLMs), our research initially focuses on the capabilities of
LLMs in the detection of unknown fraudulent activities within recommender
systems, a strategy we denote as LLM4Dec. Empirical evaluations demonstrate the
substantial capability of LLMs in identifying unknown fraudsters, leveraging
their expansive, open-world knowledge.
  Building upon this, we propose the integration of LLMs into defense
strategies to extend their effectiveness beyond the confines of known attacks.
We propose LoRec, an advanced framework that employs LLM-Enhanced Calibration
to strengthen the robustness of sequential recommender systems against
poisoning attacks. LoRec integrates an LLM-enhanced CalibraTor (LCT) that
refines the training process of sequential recommender systems with knowledge
derived from LLMs, applying a user-wise reweighting to diminish the impact of
fraudsters injected by attacks. By incorporating LLMs' open-world knowledge,
the LCT effectively converts the limited, specific priors or rules into a more
general pattern of fraudsters, offering improved defenses against poisoning
attacks. Our comprehensive experiments validate that LoRec, as a general
framework, significantly strengthens the robustness of sequential recommender
systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Eliciting In-context Retrieval and Reasoning for Long-context Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.08248v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.08248v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifu Qiu, Varun Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in long-context language models (LCLMs) promise to
transform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With
their expanded context windows, LCLMs can process entire knowledge bases and
perform retrieval and reasoning directly -- a capability we define as
In-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like
LOFT often overestimate LCLM performance by providing overly simplified
contexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs
in more realistic scenarios by including confounding passages retrieved with
strong retrievers. We then propose three methods to enhance LCLM performance:
(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which
uses attention heads to filter and de-noise long contexts during decoding, and
(3) joint retrieval head training alongside the generation head. Our evaluation
of five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with
our best approach applied to Mistral-7B: +17 and +15 points by Exact Match on
LOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised
fine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks
despite being a much smaller model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ColPali: Efficient Document Retrieval with Vision Language Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01449v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01449v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Faysse, Hugues Sibille, Tony Wu, Bilel Omrani, Gautier Viaud, Céline Hudelot, Pierre Colombo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Documents are visually rich structures that convey information through text,
but also figures, page layouts, tables, or even fonts. Since modern retrieval
systems mainly rely on the textual information they extract from document pages
to index documents -often through lengthy and brittle processes-, they struggle
to exploit key visual cues efficiently. This limits their capabilities in many
practical document retrieval applications such as Retrieval Augmented
Generation (RAG). To benchmark current systems on visually rich document
retrieval, we introduce the Visual Document Retrieval Benchmark ViDoRe,
composed of various page-level retrieval tasks spanning multiple domains,
languages, and practical settings. The inherent complexity and performance
shortcomings of modern systems motivate a new concept; doing document retrieval
by directly embedding the images of the document pages. We release ColPali, a
Vision Language Model trained to produce high-quality multi-vector embeddings
from images of document pages. Combined with a late interaction matching
mechanism, ColPali largely outperforms modern document retrieval pipelines
while being drastically simpler, faster and end-to-end trainable. We release
models, data, code and benchmarks under open licenses at https://hf.co/vidore.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Theory for Token-Level Harmonization in Retrieval-Augmented Generation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00944v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00944v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance
large language models (LLMs). Studies show that while RAG provides valuable
external information (benefit), it may also mislead LLMs (detriment) with noisy
or incorrect retrieved texts. Although many existing methods attempt to
preserve benefit and avoid detriment, they lack a theoretical explanation for
RAG. The benefit and detriment in the next token prediction of RAG remain a
black box that cannot be quantified or compared in an explainable manner, so
existing methods are data-driven, need additional utility evaluators or
post-hoc. This paper takes the first step towards providing a theory to explain
and trade off the benefit and detriment in RAG. First, we model RAG as the
fusion between distribution of LLMs knowledge and distribution of retrieved
texts. Then, we formalize the trade-off between the value of external knowledge
(benefit) and its potential risk of misleading LLMs (detriment) in next token
prediction of RAG by distribution difference in this fusion. Finally, we prove
that the actual effect of RAG on the token, which is the comparison between
benefit and detriment, can be predicted without any training or accessing the
utility of retrieval. Based on our theory, we propose a practical novel method,
Tok-RAG, which achieves collaborative generation between the pure LLM and RAG
at token level to preserve benefit and avoid detriment. Experiments in
real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the
effectiveness of our method and support our theoretical findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffBrush:Just Painting the Art by Your Hands 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaming Chu, Lei Jin, Tao Wang, Junliang Xing, Jian Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of image generation and editing algorithms in recent
years has enabled ordinary user to produce realistic images. However, the
current AI painting ecosystem predominantly relies on text-driven diffusion
models (T2I), which pose challenges in accurately capturing user requirements.
Furthermore, achieving compatibility with other modalities incurs substantial
training costs. To this end, we introduce DiffBrush, which is compatible with
T2I models and allows users to draw and edit images. By manipulating and
adapting the internal representation of the diffusion model, DiffBrush guides
the model-generated images to converge towards the user's hand-drawn sketches
for user's specific needs without additional training. DiffBrush achieves
control over the color, semantic, and instance of objects in images by
continuously guiding the latent and instance-level attention map during the
denoising process of the diffusion model. Besides, we propose a latent
regeneration, which refines the randomly sampled noise in the diffusion model,
obtaining a better image generation layout. Finally, users only need to roughly
draw the mask of the instance (acceptable colors) on the canvas, DiffBrush can
naturally generate the corresponding instance at the corresponding location.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EyEar: Learning Audio Synchronized Human Gaze Trajectory Based on
  Physics-Informed Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20858v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20858v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochuan Liu, Xin Cheng, Yuchong Sun, Xiaoxue Wu, Ruihua Song, Hao Sun, Denghao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Imitating how humans move their gaze in a visual scene is a vital research
problem for both visual understanding and psychology, kindling crucial
applications such as building alive virtual characters. Previous studies aim to
predict gaze trajectories when humans are free-viewing an image, searching for
required targets, or looking for clues to answer questions in an image. While
these tasks focus on visual-centric scenarios, humans move their gaze also
along with audio signal inputs in more common scenarios. To fill this gap, we
introduce a new task that predicts human gaze trajectories in a visual scene
with synchronized audio inputs and provide a new dataset containing 20k gaze
points from 8 subjects. To effectively integrate audio information and simulate
the dynamic process of human gaze motion, we propose a novel learning framework
called EyEar (Eye moving while Ear listening) based on physics-informed
dynamics, which considers three key factors to predict gazes: eye inherent
motion tendency, vision salient attraction, and audio semantic attraction. We
also propose a probability density score to overcome the high individual
variability of gaze trajectories, thereby improving the stabilization of
optimization and the reliability of the evaluation. Experimental results show
that EyEar outperforms all the baselines in the context of all evaluation
metrics, thanks to the proposed components in the learning model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HAIC: Improving Human Action Understanding and Generation with Better
  Captions for Multi-modal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20811v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20811v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jianlong Wu, Di Zhang, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent Multi-modal Large Language Models (MLLMs) have made great progress in
video understanding. However, their performance on videos involving human
actions is still limited by the lack of high-quality data. To address this, we
introduce a two-stage data annotation pipeline. First, we design strategies to
accumulate videos featuring clear human actions from the Internet. Second,
videos are annotated in a standardized caption format that uses human
attributes to distinguish individuals and chronologically details their actions
and interactions. Through this pipeline, we curate two datasets, namely
HAICTrain and HAICBench. \textbf{HAICTrain} comprises 126K video-caption pairs
generated by Gemini-Pro and verified for training purposes. Meanwhile,
\textbf{HAICBench} includes 500 manually annotated video-caption pairs and
1,400 QA pairs, for a comprehensive evaluation of human action understanding.
Experimental results demonstrate that training with HAICTrain not only
significantly enhances human understanding abilities across 4 benchmarks, but
can also improve text-to-video generation results. Both the HAICTrain and
HAICBench are released at https://huggingface.co/datasets/KuaishouHAIC/HAIC.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-27T00:00:00Z">2025-02-27</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CS-PaperSum: A Large-Scale <span class="highlight-title">Dataset</span> of AI-Generated Summaries for
  Scientific Papers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Javin Liu, Aryan Vats, Zihao He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid expansion of scientific literature in computer science presents
challenges in tracking research trends and extracting key insights. Existing
datasets provide metadata but lack structured summaries that capture core
contributions and methodologies. We introduce CS-PaperSum, a large-scale
dataset of 91,919 papers from 31 top-tier computer science conferences,
enriched with AI-generated structured summaries using ChatGPT. To assess
summary quality, we conduct embedding alignment analysis and keyword overlap
analysis, demonstrating strong preservation of key concepts. We further present
a case study on AI research trends, highlighting shifts in methodologies and
interdisciplinary crossovers, including the rise of self-supervised learning,
retrieval-augmented generation, and multimodal AI. Our dataset enables
automated literature analysis, research trend forecasting, and AI-driven
scientific discovery, providing a valuable resource for researchers,
policymakers, and scientific information retrieval systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NANO<span class="highlight-title">GPT</span>: A Query-Driven Large Language Model Retrieval-Augmented
  Generation System for Nanotechnology Research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20541v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20541v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Achuth Chandrasekhar, Omid Barati Farimani, Olabode T. Ajenifujah, Janghoon Ock, Amir Barati Farimani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the development and application of a Large Language Model
Retrieval-Augmented Generation (LLM-RAG) system tailored for nanotechnology
research. The system leverages the capabilities of a sophisticated language
model to serve as an intelligent research assistant, enhancing the efficiency
and comprehensiveness of literature reviews in the nanotechnology domain.
Central to this LLM-RAG system is its advanced query backend retrieval
mechanism, which integrates data from multiple reputable sources. The system
retrieves relevant literature by utilizing Google Scholar's advanced search,
and scraping open-access papers from Elsevier, Springer Nature, and ACS
Publications. This multifaceted approach ensures a broad and diverse collection
of up-to-date scholarly articles and papers. The proposed system demonstrates
significant potential in aiding researchers by providing a streamlined,
accurate, and exhaustive literature retrieval process, thereby accelerating
research advancements in nanotechnology. The effectiveness of the LLM-RAG
system is validated through rigorous testing, illustrating its capability to
significantly reduce the time and effort required for comprehensive literature
reviews, while maintaining high accuracy, query relevance and outperforming
standard, publicly available LLMS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>61 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LangProBe: a Language Programs Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20315v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20315v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shangyin Tan, Lakshya A Agrawal, Arnav Singhvi, Liheng Lai, Michael J Ryan, Dan Klein, Omar Khattab, Koushik Sen, Matei Zaharia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Composing language models (LMs) into multi-step language programs and
automatically optimizing their modular prompts is now a mainstream paradigm for
building AI systems, but the tradeoffs in this space have only scarcely been
studied before. We introduce LangProBe, the first large-scale benchmark for
evaluating the architectures and optimization strategies for language programs,
with over 2000 combinations of tasks, architectures, optimizers, and choices of
LMs. Using LangProBe, we are the first to study the impact of program
architectures and optimizers (and their compositions together and with
different models) on tradeoffs of quality and cost. We find that optimized
language programs offer strong cost--quality Pareto improvement over raw calls
to models, but simultaneously demonstrate that human judgment (or empirical
decisions) about which compositions to pursue is still necessary for best
performance. We will open source the code and evaluation data for LangProBe.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Collaborative Filtering-Based Course Recommendations by
  Exploiting Time-to-Event Information with Survival Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Gharahighehi, Achilleas Ghinis, Michela Venturini, Frederik Cornillie, Celine Vens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Massive Open Online Courses (MOOCs) are emerging as a popular alternative to
traditional education, offering learners the flexibility to access a wide range
of courses from various disciplines, anytime and anywhere. Despite this
accessibility, a significant number of enrollments in MOOCs result in dropouts.
To enhance learner engagement, it is crucial to recommend courses that align
with their preferences and needs. Course Recommender Systems (RSs) can play an
important role in this by modeling learners' preferences based on their
previous interactions within the MOOC platform. Time-to-dropout and
time-to-completion in MOOCs, like other time-to-event prediction tasks, can be
effectively modeled using survival analysis (SA) methods. In this study, we
apply SA methods to improve collaborative filtering recommendation performance
by considering time-to-event in the context of MOOCs. Our proposed approach
demonstrates superior performance compared to collaborative filtering methods
trained based on learners' interactions with MOOCs, as evidenced by two
performance measures on three publicly available datasets. The findings
underscore the potential of integrating SA methods with RSs to enhance
personalization in MOOCs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Granite Embedding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20204v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20204v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parul Awasthy, Aashka Trivedi, Yulong Li, Mihaela Bornea, David Cox, Abraham Daniels, Martin Franz, Gabe Goodhart, Bhavani Iyer, Vishwajeet Kumar, Luis Lastras, Scott McCarley, Rudra Murthy, Vignesh P, Sara Rosenthal, Salim Roukos, Jaydeep Sen, Sukriti Sharma, Avirup Sil, Kate Soule, Arafat Sultan, Radu Florian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Granite Embedding models, a family of encoder-based
embedding models designed for retrieval tasks, spanning dense-retrieval and
sparse retrieval architectures, with both English and Multilingual
capabilities. This report provides the technical details of training these
highly effective 12 layer embedding models, along with their efficient 6 layer
distilled counterparts. Extensive evaluations show that the models, developed
with techniques like retrieval oriented pretraining, contrastive finetuning,
knowledge distillation, and model merging significantly outperform publicly
available models of similar sizes on both internal IBM retrieval and search
tasks, and have equivalent performance on widely used information retrieval
benchmarks, while being trained on high-quality data suitable for enterprise
use. We publicly release all our Granite Embedding models under the Apache 2.0
license, allowing both research and commercial use at
https://huggingface.co/collections/ibm-granite.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bisecting K-Means in RAG for Enhancing Question-Answering Tasks
  Performance in Telecommunications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20188v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20188v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedro Sousa, Cláudio Klautau Mello, Frank B. Morte, Luis F. Solis Navarro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Question-answering tasks in the telecom domain are still reasonably
unexplored in the literature, primarily due to the field's rapid changes and
evolving standards. This work presents a novel Retrieval-Augmented Generation
framework explicitly designed for the telecommunication domain, focusing on
datasets composed of 3GPP documents. The framework introduces the use of the
Bisecting K-Means clustering technique to organize the embedding vectors by
contents, facilitating more efficient information retrieval. By leveraging this
clustering technique, the system pre-selects a subset of clusters that are most
similar to the user's query, enhancing the relevance of the retrieved
information. Aiming for models with lower computational cost for inference, the
framework was tested using Small Language Models, demonstrating improved
performance with an accuracy of 66.12% on phi-2 and 72.13% on phi-3 fine-tuned
models, and reduced training time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 8 figures, accepted at GLOBECOM WORKSHOPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReCon: Enhancing True Correspondence Discrimination through Relation
  Consistency for Robust Noisy Correspondence Learning <span class="chip">CVPR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19962v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19962v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quanxing Zha, Xin Liu, Shu-Juan Peng, Yiu-ming Cheung, Xing Xu, Nannan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Can we accurately identify the true correspondences from multimodal datasets
containing mismatched data pairs? Existing methods primarily emphasize the
similarity matching between the representations of objects across modalities,
potentially neglecting the crucial relation consistency within modalities that
are particularly important for distinguishing the true and false
correspondences. Such an omission often runs the risk of misidentifying
negatives as positives, thus leading to unanticipated performance degradation.
To address this problem, we propose a general Relation Consistency learning
framework, namely ReCon, to accurately discriminate the true correspondences
among the multimodal data and thus effectively mitigate the adverse impact
caused by mismatches. Specifically, ReCon leverages a novel relation
consistency learning to ensure the dual-alignment, respectively of, the
cross-modal relation consistency between different modalities and the
intra-modal relation consistency within modalities. Thanks to such dual
constrains on relations, ReCon significantly enhances its effectiveness for
true correspondence discrimination and therefore reliably filters out the
mismatched pairs to mitigate the risks of wrong supervisions. Extensive
experiments on three widely-used benchmark datasets, including Flickr30K,
MS-COCO, and Conceptual Captions, are conducted to demonstrate the
effectiveness and superiority of ReCon compared with other SOTAs. The code is
available at: https://github.com/qxzha/ReCon.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures, Accepted by CVPR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Few-Shot Multilingual Open-Domain QA from 5 Examples <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fan Jiang, Tom Drummond, Trevor Cohn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent approaches to multilingual open-domain question answering (MLODQA)
have achieved promising results given abundant language-specific training data.
However, the considerable annotation cost limits the application of these
methods for underrepresented languages. We introduce a \emph{few-shot learning}
approach to synthesise large-scale multilingual data from large language models
(LLMs). Our method begins with large-scale self-supervised pre-training using
WikiData, followed by training on high-quality synthetic multilingual data
generated by prompting LLMs with few-shot supervision. The final model,
\textsc{FsModQA}, significantly outperforms existing few-shot and supervised
baselines in MLODQA and cross-lingual and monolingual retrieval. We further
show our method can be extended for effective zero-shot adaptation to new
languages through a \emph{cross-lingual prompting} strategy with only
English-supervised data, making it a general and applicable solution for MLODQA
tasks without costly large-scale annotation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by TACL; pre-MIT Press publication version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Teaching Dense Retrieval Models to Specialize with Listwise Distillation
  and LLM Data Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manveer Singh Tamber, Suleman Kazi, Vivek Sourabh, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While the current state-of-the-art dense retrieval models exhibit strong
out-of-domain generalization, they might fail to capture nuanced
domain-specific knowledge. In principle, fine-tuning these models for
specialized retrieval tasks should yield higher effectiveness than relying on a
one-size-fits-all model, but in practice, results can disappoint. We show that
standard fine-tuning methods using an InfoNCE loss can unexpectedly degrade
effectiveness rather than improve it, even for domain-specific scenarios. This
holds true even when applying widely adopted techniques such as hard-negative
mining and negative de-noising. To address this, we explore a training strategy
that uses listwise distillation from a teacher cross-encoder, leveraging rich
relevance signals to fine-tune the retriever. We further explore synthetic
query generation using large language models. Through listwise distillation and
training with a diverse set of queries ranging from natural user searches and
factual claims to keyword-based queries, we achieve consistent effectiveness
gains across multiple datasets. Our results also reveal that synthetic queries
can rival human-written queries in training utility. However, we also identify
limitations, particularly in the effectiveness of cross-encoder teachers as a
bottleneck. We release our code and scripts to encourage further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Dataset</span> and Framework for Learning State-invariant Object
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06470v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06470v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohan Sarkar, Avinash Kak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We add one more invariance - the state invariance - to the more commonly used
other invariances for learning object representations for recognition and
retrieval. By state invariance, we mean robust with respect to changes in the
structural form of the objects, such as when an umbrella is folded, or when an
item of clothing is tossed on the floor. In this work, we present a novel
dataset, ObjectsWithStateChange, which captures state and pose variations in
the object images recorded from arbitrary viewpoints. We believe that this
dataset will facilitate research in fine-grained object recognition and
retrieval of 3D objects that are capable of state changes. The goal of such
research would be to train models capable of learning discriminative object
embeddings that remain invariant to state changes while also staying invariant
to transformations induced by changes in viewpoint, pose, illumination, etc. A
major challenge in this regard is that instances of different objects (both
within and across different categories) under various state changes may share
similar visual characteristics and therefore may be close to one another in the
learned embedding space, which would make it more difficult to discriminate
between them. To address this, we propose a curriculum learning strategy that
progressively selects object pairs with smaller inter-object distances in the
learned embedding space during the training phase. This approach gradually
samples harder-to-distinguish examples of visually similar objects, both within
and across different categories. Our ablation related to the role played by
curriculum learning indicates an improvement in object recognition accuracy of
7.9% and retrieval mAP of 9.2% over the state-of-the-art on our new dataset, as
well as three other challenging multi-view datasets such as ModelNet40,
ObjectPI, and FG3D.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recommendations by Concise User Profiles from <span class="highlight-title">Review</span> Text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.01314v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.01314v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ghazaleh Haratinezhad Torbati, Anna Tigunova, Andrew Yates, Gerhard Weikum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems perform well for popular items and users with ample
interactions (likes, ratings etc.). This work addresses the difficult and
underexplored case of users who have very sparse interactions but post
informative review texts. This setting naturally calls for encoding
user-specific text with large language models (LLM). However, feeding the full
text of all reviews through an LLM has a weak signal-to-noise ratio and incurs
high costs of processed tokens. This paper addresses these two issues. It
presents a light-weight framework, called CUP, which first computes concise
user profiles and feeds only these into the training of transformer-based
recommenders. For user profiles, we devise various techniques to select the
most informative cues from noisy reviews. Experiments, with book reviews data,
show that fine-tuning a small language model with judiciously constructed
profiles achieves the best performance, even in comparison to LLM-generated
rankings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-modal Food Recommendation using Clustering and <span class="highlight-title">Self-supervised</span>
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18962v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18962v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Zhang, Xin Zhou, Qianwen Meng, Fanglin Zhu, Yonghui Xu, Zhiqi Shen, Lizhen Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Food recommendation systems serve as pivotal components in the realm of
digital lifestyle services, designed to assist users in discovering recipes and
food items that resonate with their unique dietary predilections. Typically,
multi-modal descriptions offer an exhaustive profile for each recipe, thereby
ensuring recommendations that are both personalized and accurate. Our
preliminary investigation of two datasets indicates that pre-trained
multi-modal dense representations might precipitate a deterioration in
performance compared to ID features when encapsulating interactive
relationships. This observation implies that ID features possess a relative
superiority in modeling interactive collaborative signals. Consequently,
contemporary cutting-edge methodologies augment ID features with multi-modal
information as supplementary features, overlooking the latent semantic
relations between recipes. To rectify this, we present CLUSSL, a novel food
recommendation framework that employs clustering and self-supervised learning.
Specifically, CLUSSL formulates a modality-specific graph tailored to each
modality with discrete/continuous features, thereby transforming semantic
features into structural representation. Furthermore, CLUSSL procures recipe
representations pertinent to different modalities via graph convolutional
operations. A self-supervised learning objective is proposed to foster
independence between recipe representations derived from different unimodal
graphs. Comprehensive experiments on real-world datasets substantiate that
CLUSSL consistently surpasses state-of-the-art recommendation benchmarks in
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Establishing a Foundation for Tetun Text Ad-Hoc Retrieval: Stemming,
  Indexing, Retrieval, and Ranking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.11758v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.11758v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel de Jesus, Sérgio Nunes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Searching for information on the internet and digital platforms to satisfy an
information need requires effective retrieval solutions. However, such
solutions are not yet available for Tetun, making it challenging to find
relevant documents for text-based search queries in this language. To address
these challenges, this study investigates Tetun text retrieval with a focus on
the ad-hoc retrieval task. It begins by developing essential language resources
-- including a list of stopwords, a stemmer, and a test collection -- which
serve as foundational components for solutions tailored to Tetun text
retrieval. Various strategies are then explored using both document titles and
content to evaluate retrieval effectiveness. The results show that retrieving
document titles, after removing hyphens and apostrophes without applying
stemming, significantly improves retrieval performance compared to the
baseline. Efficiency increases by 31.37%, while effectiveness achieves an
average gain of 9.40% in MAP@10 and 30.35% in nDCG@10 with DFR BM25. Beyond the
top-10 cutoff point, Hiemstra LM demonstrates strong performance across various
retrieval strategies and evaluation metrics. Contributions of this work include
the development of Labadain-Stopwords (a list of 160 Tetun stopwords),
Labadain-Stemmer (a Tetun stemmer with three variants), and
Labadain-Avaliad\'or (a Tetun test collection containing 59 topics, 33,550
documents, and 5,900 qrels).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Refine the title and improve the content (version 2)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoPureData: Automated Filtering of Undesirable Web Data to Update LLM
  Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19271v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19271v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Praneeth Vadlapati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Up-to-date and reliable language models are consistently sought after and are
essential in various applications. Typically, models are trained on a fixed
dataset and then deployed globally. However, the knowledge of the models
becomes outdated. Enabling automatic updation of AI knowledge using web data
involves significant concerns regarding the model's safety and quality due to a
threat from unsafe and undesirable text across the web. The purity of new data
was essential for updating knowledge of language models to maintain their
reliability. This paper proposes AutoPureData, a system that automatically
collects and purifies web data. The system loaded a sample of web data.
Utilizing existing trusted AI models, it successfully eliminated unsafe text
with an accuracy of 97% and undesirable text with an accuracy of 86%,
demonstrating the system's effectiveness in purifying the data. The system
ensures that only meaningful and safe text can be used to update LLM knowledge.
The pure text was then optimized and stored in a vector database for future
querying. It was found that LLM can fetch new data from the vector DB. The LLM
writes the RAG query in English, even if the user's query is in another
language, proving that the system can perform cross-lingual retrieval. This
paper proposes a method to maintain the accuracy and relevance of up-to-date
language models by ensuring that only purified data was used to update LLM
knowledge. This work contributes to updating knowledge of chatbots using
meaningful and safe text, enhancing their utility across various industries,
and potentially reducing the risks associated with outputs caused by unsafe or
impure data. Code is available at github.com/Pro-GenAI/AutoPureData.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Final version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM-QE: Improving Query Expansion by Aligning Large Language Models with
  Ranking Preferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17057v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17057v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sijia Yao, Pengcheng Huang, Zhenghao Liu, Yu Gu, Yukun Yan, Shi Yu, Ge Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query expansion plays a crucial role in information retrieval, which aims to
bridge the semantic gap between queries and documents to improve matching
performance. This paper introduces LLM-QE, a novel approach that leverages
Large Language Models (LLMs) to generate document-based query expansions,
thereby enhancing dense retrieval models. Unlike traditional methods, LLM-QE
designs both rank-based and answer-based rewards and uses these reward models
to optimize LLMs to align with the ranking preferences of both retrievers and
LLMs, thus mitigating the hallucination of LLMs during query expansion. Our
experiments on the zero-shot dense retrieval model, Contriever, demonstrate the
effectiveness of LLM-QE, achieving an improvement of over 8%. Furthermore, by
incorporating answer-based reward modeling, LLM-QE generates more relevant and
precise information related to the documents, rather than simply producing
redundant tokens to maximize rank-based rewards. Notably, LLM-QE also improves
the training process of dense retrievers, achieving a more than 5% improvement
after fine-tuning. All codes are available at https://github.com/NEUIR/LLM-QE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 5 tables, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World
  Spatial Reasoning Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18470v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18470v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dazhou Yu, Riyang Bao, Gengchen Mai, Liang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatial reasoning remains a challenge for Large Language Models (LLMs), which
struggle with spatial data retrieval and reasoning. We propose Spatial
Retrieval-Augmented Generation (Spatial-RAG), a framework that extends RAG to
spatial tasks by integrating sparse spatial retrieval (spatial databases) and
dense semantic retrieval (LLM-based similarity). A multi-objective ranking
strategy balances spatial constraints and semantic relevance, while an
LLM-guided generator ensures coherent responses. Experiments on a real-world
tourism dataset show that Spatial-RAG significantly improves spatial question
answering, bridging the gap between LLMs and spatial intelligence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Image Fusion for Cross-Domain Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15694v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15694v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wangyu Wu, Siqi Song, Xianglin Qiu, Xiaowei Huang, Fei Ma, Jimin Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Sequential Recommendation (CDSR) aims to predict future user
interactions based on historical interactions across multiple domains. The key
challenge in CDSR is effectively capturing cross-domain user preferences by
fully leveraging both intra-sequence and inter-sequence item interactions. In
this paper, we propose a novel method, Image Fusion for Cross-Domain Sequential
Recommendation (IFCDSR), which incorporates item image information to better
capture visual preferences. Our approach integrates a frozen CLIP model to
generate image embeddings, enriching original item embeddings with visual data
from both intra-sequence and inter-sequence interactions. Additionally, we
employ a multiple attention layer to capture cross-domain interests, enabling
joint learning of single-domain and cross-domain user preferences. To validate
the effectiveness of IFCDSR, we re-partitioned four e-commerce datasets and
conducted extensive experiments. Results demonstrate that IFCDSR significantly
outperforms existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ I see what you mean: Co-Speech Gestures for Reference Resolution in
  Multimodal Dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.00071v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.00071v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Esam Ghaleb, Bulat Khaertdinov, Aslı Özyürek, Raquel Fernández
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In face-to-face interaction, we use multiple modalities, including speech and
gestures, to communicate information and resolve references to objects.
However, how representational co-speech gestures refer to objects remains
understudied from a computational perspective. In this work, we address this
gap by introducing a multimodal reference resolution task centred on
representational gestures, while simultaneously tackling the challenge of
learning robust gesture embeddings. We propose a self-supervised pre-training
approach to gesture representation learning that grounds body movements in
spoken language. Our experiments show that the learned embeddings align with
expert annotations and have significant predictive power. Moreover, reference
resolution accuracy further improves when (1) using multimodal gesture
representations, even when speech is unavailable at inference time, and (2)
leveraging dialogue history. Overall, our findings highlight the complementary
roles of gesture and speech in reference resolution, offering a step towards
more naturalistic models of human-machine interaction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Image Referenced Sketch Colorization Based on Animation Creation
  Workflow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19937v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19937v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dingkun Yan, Xinrui Wang, Zhuoru Li, Suguru Saito, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sketch colorization plays an important role in animation and digital
illustration production tasks. However, existing methods still meet problems in
that text-guided methods fail to provide accurate color and style reference,
hint-guided methods still involve manual operation, and image-referenced
methods are prone to cause artifacts. To address these limitations, we propose
a diffusion-based framework inspired by real-world animation production
workflows. Our approach leverages the sketch as the spatial guidance and an RGB
image as the color reference, and separately extracts foreground and background
from the reference image with spatial masks. Particularly, we introduce a split
cross-attention mechanism with LoRA (Low-Rank Adaptation) modules. They are
trained separately with foreground and background regions to control the
corresponding embeddings for keys and values in cross-attention. This design
allows the diffusion model to integrate information from foreground and
background independently, preventing interference and eliminating the spatial
artifacts. During inference, we design switchable inference modes for diverse
use scenarios by changing modules activated in the framework. Extensive
qualitative and quantitative experiments, along with user studies, demonstrate
our advantages over existing methods in generating high-qualigy artifact-free
results with geometric mismatched references. Ablation studies further confirm
the effectiveness of each component. Codes are available at https://github.com/
tellurion-kanata/colorizeDiffusion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Bridger: Towards Training-free Missing Multi-modality
  Completion <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19834v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19834v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanzhou Ke, Shengfeng He, Xiao Li Wang, Bo Wang, Guoqing Chao, Yuanyang Zhang, Yi Xie, HeXing Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous successful approaches to missing modality completion rely on
carefully designed fusion techniques and extensive pre-training on complete
data, which can limit their generalizability in out-of-domain (OOD) scenarios.
In this study, we pose a new challenge: can we develop a missing modality
completion model that is both resource-efficient and robust to OOD
generalization? To address this, we present a training-free framework for
missing modality completion that leverages large multimodal models (LMMs). Our
approach, termed the "Knowledge Bridger", is modality-agnostic and integrates
generation and ranking of missing modalities. By defining domain-specific
priors, our method automatically extracts structured information from available
modalities to construct knowledge graphs. These extracted graphs connect the
missing modality generation and ranking modules through the LMM, resulting in
high-quality imputations of missing modalities. Experimental results across
both general and medical domains show that our approach consistently
outperforms competing methods, including in OOD generalization. Additionally,
our knowledge-driven generation and ranking techniques demonstrate superiority
over variants that directly employ LMMs for generation and ranking, offering
insights that may be valuable for applications in other domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MetaDesigner: Advancing Artistic Typography Through AI-Driven,
  User-Centric, and Multilingual WordArt Synthesis <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19859v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19859v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Qi He, Wangmeng Xiang, Hanyuan Chen, Jin-Peng Lan, Xianhui Lin, Kang Zhu, Bin Luo, Yifeng Geng, Xuansong Xie, Alexander G. Hauptmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MetaDesigner introduces a transformative framework for artistic typography
synthesis, powered by Large Language Models (LLMs) and grounded in a
user-centric design paradigm. Its foundation is a multi-agent system comprising
the Pipeline, Glyph, and Texture agents, which collectively orchestrate the
creation of customizable WordArt, ranging from semantic enhancements to
intricate textural elements. A central feedback mechanism leverages insights
from both multimodal models and user evaluations, enabling iterative refinement
of design parameters. Through this iterative process, MetaDesigner dynamically
adjusts hyperparameters to align with user-defined stylistic and thematic
preferences, consistently delivering WordArt that excels in visual quality and
contextual resonance. Empirical evaluations underscore the system's versatility
and effectiveness across diverse WordArt applications, yielding outputs that
are both aesthetically compelling and context-sensitive.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025, Project:
  https://modelscope.cn/studios/WordArt/WordArt</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2025-03-07T05:27:22.474656048Z">
            2025-03-07 05:27:22 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
